<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5.6 RuleFit | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="5.6 RuleFit | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5.6 RuleFit | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2023-03-02" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="rules.html"/>
<link rel="next" href="other-interpretable.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>

<style>

#cta-button-desktop:hover, #cta-button-device:hover {
  background-color:   #ffc266; 
  border-color:   #ffc266; 
  box-shadow: none;
}
#cta-button-desktop, #cta-button-device{
  color: white;
  background-color:  #ffa31a;
  text-shadow:1px 1px 0 #444;
  text-decoration: none;
  border: 2px solid  #ffa31a;
  border-radius: 10px;
  position: fixed;
  padding: 5px 10px;
  z-index: 10;
  }

#cta-button-device {
  box-shadow: 0px 10px 10px -5px rgba(194,180,190,1);
  display:none;
  right: 20px;
  bottom: 20px;
  font-size: 20px;
 }

#cta-button-desktop {
  box-shadow: 0px 20px 20px -10px rgba(194,180,190,1);
  display:display;
  padding: 8px 16px;
  right: 40px;
  bottom: 40px;
  font-size: 25px;
}

@media (max-width : 450px) {
  #cta-button-device {display:block;}
  #cta-button-desktop {display:none;}
}


</style>






<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a href="preface-by-the-author.html"><i class="fa fa-check"></i><b>1</b> Preface by the Author</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>2.1</b> Story Time</a>
<ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>2.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="2.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>2.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>3.1</b> Importance of Interpretability</a></li>
<li class="chapter" data-level="3.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>3.2</b> Taxonomy of Interpretability Methods</a></li>
<li class="chapter" data-level="3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>3.3</b> Scope of Interpretability</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>3.3.1</b> Algorithm Transparency</a></li>
<li class="chapter" data-level="3.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>3.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="3.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>3.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="3.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>3.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="3.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>3.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluation-of-interpretability.html"><a href="evaluation-of-interpretability.html"><i class="fa fa-check"></i><b>3.4</b> Evaluation of Interpretability</a></li>
<li class="chapter" data-level="3.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>3.5</b> Properties of Explanations</a></li>
<li class="chapter" data-level="3.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>3.6</b> Human-friendly Explanations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>3.6.1</b> What Is an Explanation?</a></li>
<li class="chapter" data-level="3.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>3.6.2</b> What Is a Good Explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Datasets</a>
<ul>
<li class="chapter" data-level="4.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>4.1</b> Bike Rentals (Regression)</a></li>
<li class="chapter" data-level="4.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>4.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="4.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>4.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.1</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>5.1.2</b> Example</a></li>
<li class="chapter" data-level="5.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>5.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="5.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>5.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="5.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>5.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="5.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>5.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="5.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>5.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="5.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>5.1.8</b> Advantages</a></li>
<li class="chapter" data-level="5.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>5.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>5.2</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="logistic.html"><a href="logistic.html#what-is-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.2.1</b> What is Wrong with Linear Regression for Classification?</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>5.2.2</b> Theory</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>5.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>5.2.4</b> Example</a></li>
<li class="chapter" data-level="5.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>5.2.5</b> Advantages and Disadvantages</a></li>
<li class="chapter" data-level="5.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>5.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>5.3</b> GLM, GAM and more</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>5.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="5.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>5.3.2</b> Interactions</a></li>
<li class="chapter" data-level="5.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>5.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="5.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>5.3.4</b> Advantages</a></li>
<li class="chapter" data-level="5.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>5.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>5.3.6</b> Software</a></li>
<li class="chapter" data-level="5.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>5.3.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>5.4</b> Decision Tree</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>5.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>5.4.2</b> Example</a></li>
<li class="chapter" data-level="5.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>5.4.3</b> Advantages</a></li>
<li class="chapter" data-level="5.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>5.4.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>5.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>5.5</b> Decision Rules</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>5.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="5.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>5.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="5.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>5.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="5.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>5.6</b> RuleFit</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>5.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="5.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>5.6.2</b> Theory</a></li>
<li class="chapter" data-level="5.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>5.6.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>5.7</b> Other Interpretable Models</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.7.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="5.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>5.7.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-Agnostic Methods</a></li>
<li class="chapter" data-level="7" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>7</b> Example-Based Explanations</a></li>
<li class="chapter" data-level="8" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>8</b> Global Model-Agnostic Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>8.1</b> Partial Dependence Plot (PDP)</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="pdp.html"><a href="pdp.html#pdp-based-feature-importance"><i class="fa fa-check"></i><b>8.1.1</b> PDP-based Feature Importance</a></li>
<li class="chapter" data-level="8.1.2" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>8.1.2</b> Examples</a></li>
<li class="chapter" data-level="8.1.3" data-path="pdp.html"><a href="pdp.html#advantages-5"><i class="fa fa-check"></i><b>8.1.3</b> Advantages</a></li>
<li class="chapter" data-level="8.1.4" data-path="pdp.html"><a href="pdp.html#disadvantages-5"><i class="fa fa-check"></i><b>8.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.1.5" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>8.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>8.2</b> Accumulated Local Effects (ALE) Plot</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>8.2.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="8.2.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>8.2.2</b> Theory</a></li>
<li class="chapter" data-level="8.2.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>8.2.3</b> Estimation</a></li>
<li class="chapter" data-level="8.2.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>8.2.4</b> Examples</a></li>
<li class="chapter" data-level="8.2.5" data-path="ale.html"><a href="ale.html#advantages-6"><i class="fa fa-check"></i><b>8.2.5</b> Advantages</a></li>
<li class="chapter" data-level="8.2.6" data-path="ale.html"><a href="ale.html#disadvantages-6"><i class="fa fa-check"></i><b>8.2.6</b> Disadvantages</a></li>
<li class="chapter" data-level="8.2.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>8.2.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>8.3</b> Feature Interaction</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>8.3.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="8.3.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>8.3.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="8.3.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>8.3.3</b> Examples</a></li>
<li class="chapter" data-level="8.3.4" data-path="interaction.html"><a href="interaction.html#advantages-7"><i class="fa fa-check"></i><b>8.3.4</b> Advantages</a></li>
<li class="chapter" data-level="8.3.5" data-path="interaction.html"><a href="interaction.html#disadvantages-7"><i class="fa fa-check"></i><b>8.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.3.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>8.3.6</b> Implementations</a></li>
<li class="chapter" data-level="8.3.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>8.3.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>8.4</b> Functional Decomposition</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-i"><i class="fa fa-check"></i><b>8.4.1</b> How not to Compute the Components I</a></li>
<li class="chapter" data-level="8.4.2" data-path="decomposition.html"><a href="decomposition.html#functional-decomposition"><i class="fa fa-check"></i><b>8.4.2</b> Functional Decomposition</a></li>
<li class="chapter" data-level="8.4.3" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-ii"><i class="fa fa-check"></i><b>8.4.3</b> How not to Compute the Components II</a></li>
<li class="chapter" data-level="8.4.4" data-path="decomposition.html"><a href="decomposition.html#functional-anova"><i class="fa fa-check"></i><b>8.4.4</b> Functional ANOVA</a></li>
<li class="chapter" data-level="8.4.5" data-path="decomposition.html"><a href="decomposition.html#generalized-functional-anova-for-dependent-features"><i class="fa fa-check"></i><b>8.4.5</b> Generalized Functional ANOVA for Dependent Features</a></li>
<li class="chapter" data-level="8.4.6" data-path="decomposition.html"><a href="decomposition.html#accumulated-local-effect-plots"><i class="fa fa-check"></i><b>8.4.6</b> Accumulated Local Effect Plots</a></li>
<li class="chapter" data-level="8.4.7" data-path="decomposition.html"><a href="decomposition.html#statistical-regression-models"><i class="fa fa-check"></i><b>8.4.7</b> Statistical Regression Models</a></li>
<li class="chapter" data-level="8.4.8" data-path="decomposition.html"><a href="decomposition.html#bonus-partial-dependence-plot"><i class="fa fa-check"></i><b>8.4.8</b> Bonus: Partial Dependence Plot</a></li>
<li class="chapter" data-level="8.4.9" data-path="decomposition.html"><a href="decomposition.html#advantages-8"><i class="fa fa-check"></i><b>8.4.9</b> Advantages</a></li>
<li class="chapter" data-level="8.4.10" data-path="decomposition.html"><a href="decomposition.html#disadvantages-8"><i class="fa fa-check"></i><b>8.4.10</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>8.5</b> Permutation Feature Importance</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-3"><i class="fa fa-check"></i><b>8.5.1</b> Theory</a></li>
<li class="chapter" data-level="8.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>8.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="8.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>8.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="8.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-9"><i class="fa fa-check"></i><b>8.5.4</b> Advantages</a></li>
<li class="chapter" data-level="8.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-9"><i class="fa fa-check"></i><b>8.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.5.6" data-path="feature-importance.html"><a href="feature-importance.html#alternatives-1"><i class="fa fa-check"></i><b>8.5.6</b> Alternatives</a></li>
<li class="chapter" data-level="8.5.7" data-path="feature-importance.html"><a href="feature-importance.html#software-3"><i class="fa fa-check"></i><b>8.5.7</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>8.6</b> Global Surrogate</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="global.html"><a href="global.html#theory-4"><i class="fa fa-check"></i><b>8.6.1</b> Theory</a></li>
<li class="chapter" data-level="8.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>8.6.2</b> Example</a></li>
<li class="chapter" data-level="8.6.3" data-path="global.html"><a href="global.html#advantages-10"><i class="fa fa-check"></i><b>8.6.3</b> Advantages</a></li>
<li class="chapter" data-level="8.6.4" data-path="global.html"><a href="global.html#disadvantages-10"><i class="fa fa-check"></i><b>8.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.6.5" data-path="global.html"><a href="global.html#software-4"><i class="fa fa-check"></i><b>8.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>8.7</b> Prototypes and Criticisms</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="proto.html"><a href="proto.html#theory-5"><i class="fa fa-check"></i><b>8.7.1</b> Theory</a></li>
<li class="chapter" data-level="8.7.2" data-path="proto.html"><a href="proto.html#examples-3"><i class="fa fa-check"></i><b>8.7.2</b> Examples</a></li>
<li class="chapter" data-level="8.7.3" data-path="proto.html"><a href="proto.html#advantages-11"><i class="fa fa-check"></i><b>8.7.3</b> Advantages</a></li>
<li class="chapter" data-level="8.7.4" data-path="proto.html"><a href="proto.html#disadvantages-11"><i class="fa fa-check"></i><b>8.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.7.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>8.7.5</b> Code and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>9</b> Local Model-Agnostic Methods</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>9.1</b> Individual Conditional Expectation (ICE)</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ice.html"><a href="ice.html#examples-4"><i class="fa fa-check"></i><b>9.1.1</b> Examples</a></li>
<li class="chapter" data-level="9.1.2" data-path="ice.html"><a href="ice.html#advantages-12"><i class="fa fa-check"></i><b>9.1.2</b> Advantages</a></li>
<li class="chapter" data-level="9.1.3" data-path="ice.html"><a href="ice.html#disadvantages-12"><i class="fa fa-check"></i><b>9.1.3</b> Disadvantages</a></li>
<li class="chapter" data-level="9.1.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>9.1.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>9.2</b> Local Surrogate (LIME)</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>9.2.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>9.2.2</b> LIME for Text</a></li>
<li class="chapter" data-level="9.2.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>9.2.3</b> LIME for Images</a></li>
<li class="chapter" data-level="9.2.4" data-path="lime.html"><a href="lime.html#advantages-13"><i class="fa fa-check"></i><b>9.2.4</b> Advantages</a></li>
<li class="chapter" data-level="9.2.5" data-path="lime.html"><a href="lime.html#disadvantages-13"><i class="fa fa-check"></i><b>9.2.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>9.3</b> Counterfactual Explanations</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>9.3.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="9.3.2" data-path="counterfactual.html"><a href="counterfactual.html#example-8"><i class="fa fa-check"></i><b>9.3.2</b> Example</a></li>
<li class="chapter" data-level="9.3.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-14"><i class="fa fa-check"></i><b>9.3.3</b> Advantages</a></li>
<li class="chapter" data-level="9.3.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-14"><i class="fa fa-check"></i><b>9.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="9.3.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>9.3.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>9.4</b> Scoped Rules (Anchors)</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>9.4.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="9.4.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>9.4.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="9.4.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>9.4.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="9.4.4" data-path="anchors.html"><a href="anchors.html#advantages-15"><i class="fa fa-check"></i><b>9.4.4</b> Advantages</a></li>
<li class="chapter" data-level="9.4.5" data-path="anchors.html"><a href="anchors.html#disadvantages-15"><i class="fa fa-check"></i><b>9.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="9.4.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>9.4.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9.5</b> Shapley Values</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>9.5.1</b> General Idea</a></li>
<li class="chapter" data-level="9.5.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>9.5.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="9.5.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>9.5.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="9.5.4" data-path="shapley.html"><a href="shapley.html#advantages-16"><i class="fa fa-check"></i><b>9.5.4</b> Advantages</a></li>
<li class="chapter" data-level="9.5.5" data-path="shapley.html"><a href="shapley.html#disadvantages-16"><i class="fa fa-check"></i><b>9.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="9.5.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>9.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>9.6</b> SHAP (SHapley Additive exPlanations)</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>9.6.1</b> Definition</a></li>
<li class="chapter" data-level="9.6.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>9.6.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="9.6.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>9.6.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="9.6.4" data-path="shap.html"><a href="shap.html#examples-5"><i class="fa fa-check"></i><b>9.6.4</b> Examples</a></li>
<li class="chapter" data-level="9.6.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>9.6.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="9.6.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>9.6.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="9.6.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>9.6.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="9.6.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>9.6.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="9.6.9" data-path="shap.html"><a href="shap.html#clustering-shapley-values"><i class="fa fa-check"></i><b>9.6.9</b> Clustering Shapley Values</a></li>
<li class="chapter" data-level="9.6.10" data-path="shap.html"><a href="shap.html#advantages-17"><i class="fa fa-check"></i><b>9.6.10</b> Advantages</a></li>
<li class="chapter" data-level="9.6.11" data-path="shap.html"><a href="shap.html#disadvantages-17"><i class="fa fa-check"></i><b>9.6.11</b> Disadvantages</a></li>
<li class="chapter" data-level="9.6.12" data-path="shap.html"><a href="shap.html#software-5"><i class="fa fa-check"></i><b>9.6.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>10</b> Neural Network Interpretation</a>
<ul>
<li class="chapter" data-level="10.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>10.1</b> Learned Features</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>10.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="10.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>10.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="10.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-18"><i class="fa fa-check"></i><b>10.1.3</b> Advantages</a></li>
<li class="chapter" data-level="10.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-18"><i class="fa fa-check"></i><b>10.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="10.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>10.1.5</b> Software and Further Material</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html"><i class="fa fa-check"></i><b>10.2</b> Pixel Attribution (Saliency Maps)</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="pixel-attribution.html"><a href="pixel-attribution.html#vanilla-gradient-saliency-maps"><i class="fa fa-check"></i><b>10.2.1</b> Vanilla Gradient (Saliency Maps)</a></li>
<li class="chapter" data-level="10.2.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html#deconvnet"><i class="fa fa-check"></i><b>10.2.2</b> DeconvNet</a></li>
<li class="chapter" data-level="10.2.3" data-path="pixel-attribution.html"><a href="pixel-attribution.html#grad-cam"><i class="fa fa-check"></i><b>10.2.3</b> Grad-CAM</a></li>
<li class="chapter" data-level="10.2.4" data-path="pixel-attribution.html"><a href="pixel-attribution.html#guided-grad-cam"><i class="fa fa-check"></i><b>10.2.4</b> Guided Grad-CAM</a></li>
<li class="chapter" data-level="10.2.5" data-path="pixel-attribution.html"><a href="pixel-attribution.html#smoothgrad"><i class="fa fa-check"></i><b>10.2.5</b> SmoothGrad</a></li>
<li class="chapter" data-level="10.2.6" data-path="pixel-attribution.html"><a href="pixel-attribution.html#examples-6"><i class="fa fa-check"></i><b>10.2.6</b> Examples</a></li>
<li class="chapter" data-level="10.2.7" data-path="pixel-attribution.html"><a href="pixel-attribution.html#advantages-19"><i class="fa fa-check"></i><b>10.2.7</b> Advantages</a></li>
<li class="chapter" data-level="10.2.8" data-path="pixel-attribution.html"><a href="pixel-attribution.html#disadvantages-19"><i class="fa fa-check"></i><b>10.2.8</b> Disadvantages</a></li>
<li class="chapter" data-level="10.2.9" data-path="pixel-attribution.html"><a href="pixel-attribution.html#software-6"><i class="fa fa-check"></i><b>10.2.9</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html"><i class="fa fa-check"></i><b>10.3</b> Detecting Concepts</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="detecting-concepts.html"><a href="detecting-concepts.html#tcav-testing-with-concept-activation-vectors"><i class="fa fa-check"></i><b>10.3.1</b> TCAV: Testing with Concept Activation Vectors</a></li>
<li class="chapter" data-level="10.3.2" data-path="detecting-concepts.html"><a href="detecting-concepts.html#example-9"><i class="fa fa-check"></i><b>10.3.2</b> Example</a></li>
<li class="chapter" data-level="10.3.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html#advantages-20"><i class="fa fa-check"></i><b>10.3.3</b> Advantages</a></li>
<li class="chapter" data-level="10.3.4" data-path="detecting-concepts.html"><a href="detecting-concepts.html#disadvantages-20"><i class="fa fa-check"></i><b>10.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="10.3.5" data-path="detecting-concepts.html"><a href="detecting-concepts.html#bonus-other-concept-based-approaches"><i class="fa fa-check"></i><b>10.3.5</b> Bonus: Other Concept-based Approaches</a></li>
<li class="chapter" data-level="10.3.6" data-path="detecting-concepts.html"><a href="detecting-concepts.html#software-7"><i class="fa fa-check"></i><b>10.3.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>10.4</b> Adversarial Examples</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>10.4.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="10.4.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>10.4.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>10.5</b> Influential Instances</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>10.5.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="10.5.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>10.5.2</b> Influence Functions</a></li>
<li class="chapter" data-level="10.5.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="10.5.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="10.5.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>10.5.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>11</b> A Look into the Crystal Ball</a>
<ul>
<li class="chapter" data-level="11.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>11.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="11.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>11.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>12</b> Contribute to the Book</a></li>
<li class="chapter" data-level="13" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>13</b> Citing this Book</a></li>
<li class="chapter" data-level="14" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>14</b> Translations</a></li>
<li class="chapter" data-level="15" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>15</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a>
<ul>
<li class="chapter" data-level="" data-path="r-packages-used.html"><a href="r-packages-used.html"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li> 
<li><a href="https://christophmolnar.com/impressum/" target="_blank">Impressum</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<a id="cta-button-desktop" href="https://bit.ly/3K3AV1y" rel="noopener noreferrer" target="blank"> Buy Book </a>

<a id="cta-button-device" href="https://leanpub.com/interpretable-machine-learning" rel="noopener noreferrer" target="blank">Buy</a>

<div id="rulefit" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> RuleFit<a href="rulefit.html#rulefit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The RuleFit algorithm by Friedman and Popescu (2008)<a href="#fn25" class="footnote-ref" id="fnref25"><sup>25</sup></a> learns sparse linear models that include automatically detected interaction effects in the form of decision rules.</p>
<p>The linear regression model does not account for interactions between features.
Would it not be convenient to have a model that is as simple and interpretable as linear models, but also integrates feature interactions?
RuleFit fills this gap.
RuleFit learns a sparse linear model with the original features and also a number of new features that are decision rules.
These new features capture interactions between the original features.
RuleFit automatically generates these features from decision trees.
Each path through a tree can be transformed into a decision rule by combining the split decisions into a rule.
The node predictions are discarded and only the splits are used in the decision rules:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rulefit-split"></span>
<img src="images/rulefit.jpg" alt="4 rules can be generated from a tree with 3 terminal nodes." width="\textwidth" />
<p class="caption">
FIGURE 5.21: 4 rules can be generated from a tree with 3 terminal nodes.
</p>
</div>
<p>Where do those decision trees come from?
The trees are trained to predict the outcome of interest.
This ensures that the splits are meaningful for the prediction task.
Any algorithm that generates a lot of trees can be used for RuleFit, for example a random forest.
Each tree is decomposed into decision rules that are used as additional features in a sparse linear regression model (Lasso).</p>
<p>The RuleFit paper uses the Boston housing data to illustrate this:
The goal is to predict the median house value of a Boston neighborhood.
One of the rules generated by RuleFit is:
IF <code>number of rooms &gt; 6.64</code> AND <code>concentration of nitric oxide &lt;0.67</code> THEN 1 ELSE 0.</p>
<p>RuleFit also comes with a feature importance measure that helps to identify linear terms and rules that are important for the predictions.
Feature importance is calculated from the weights of the regression model.
The importance measure can be aggregated for the original features (which are used in their “raw” form and possibly in many decision rules).</p>
<p>RuleFit also introduces partial dependence plots to show the average change in prediction by changing a feature.
The partial dependence plot is a model-agnostic method that can be used with any model, and is explained in the <a href="pdp.html#pdp">book chapter on partial dependence plots</a>.</p>
<div id="interpretation-and-example" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Interpretation and Example<a href="rulefit.html#interpretation-and-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Since RuleFit estimates a linear model in the end, the interpretation is the same as for “normal” <a href="limo.html#limo">linear models</a>.
The only difference is that the model has new features derived from decision rules.
Decision rules are binary features:
A value of 1 means that all conditions of the rule are met, otherwise the value is 0.
For linear terms in RuleFit, the interpretation is the same as in linear regression models:
If the feature increases by one unit, the predicted outcome changes by the corresponding feature weight.</p>
<p>In this example, we use RuleFit to predict the number of <a href="bike-data.html#bike-data">rented bicycles</a> on a given day.
The table shows five of the rules that were generated by RuleFit, along with their Lasso weights and importances.
The calculation is explained later in the chapter.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Description
</th>
<th style="text-align:right;">
Weight
</th>
<th style="text-align:right;">
Importance
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
days_since_2011 &gt; 111 &amp; weathersit in (“GOOD”, “MISTY”)
</td>
<td style="text-align:right;">
795
</td>
<td style="text-align:right;">
303
</td>
</tr>
<tr>
<td style="text-align:left;">
37.25 &lt;= hum &lt;= 90
</td>
<td style="text-align:right;">
-20
</td>
<td style="text-align:right;">
278
</td>
</tr>
<tr>
<td style="text-align:left;">
temp &gt; 13 &amp; days_since_2011 &gt; 554
</td>
<td style="text-align:right;">
676
</td>
<td style="text-align:right;">
239
</td>
</tr>
<tr>
<td style="text-align:left;">
4 &lt;= windspeed &lt;= 24
</td>
<td style="text-align:right;">
-41
</td>
<td style="text-align:right;">
204
</td>
</tr>
<tr>
<td style="text-align:left;">
days_since_2011 &gt; 428 &amp; temp &gt; 5
</td>
<td style="text-align:right;">
356
</td>
<td style="text-align:right;">
174
</td>
</tr>
</tbody>
</table>
<p>The most important rule was: “days_since_2011 &gt; 111 &amp; weathersit in (”GOOD”, “MISTY”)” and the corresponding weight is 795.
The interpretation is:
If days_since_2011 &gt; 111 &amp; weathersit in (“GOOD”, “MISTY”), then the predicted number of bikes increases by 795, when all other feature values remain fixed.
In total, 278 such rules were created from the original 8 features.
Quite a lot!
But thanks to Lasso, only 59 of the 278 have a weight different from 0.</p>
<p>Computing the global feature importances reveals that temperature and time trend are the most important features:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rulefit-importance"></span>
<img src="images/rulefit-importance-1.jpeg" alt="Feature importance measures for a RuleFit model predicting bike counts. The most important features for the predictions were temperature and time trend." width="\textwidth" />
<p class="caption">
FIGURE 5.22: Feature importance measures for a RuleFit model predicting bike counts. The most important features for the predictions were temperature and time trend.
</p>
</div>
<p>The feature importance measurement includes the importance of the raw feature term and all the decision rules in which the feature appears.</p>
<p><strong>Interpretation template</strong></p>
<p>The interpretation is analogous to linear models:
The predicted outcome changes by <span class="math inline">\(\beta_j\)</span> if feature <span class="math inline">\(x_j\)</span> changes by one unit, provided all other features remain unchanged.
The weight interpretation of a decision rule is a special case:
If all conditions of a decision rule <span class="math inline">\(r_k\)</span> apply, the predicted outcome changes by <span class="math inline">\(\alpha_k\)</span> (the learned weight of rule <span class="math inline">\(r_k\)</span> in the linear model).</p>
<p>For classification (using logistic regression instead of linear regression):
If all conditions of the decision rule <span class="math inline">\(r_k\)</span> apply, the odds for event vs. no-event changes by a factor of <span class="math inline">\(\alpha_k\)</span>.</p>
</div>
<div id="theory-1" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Theory<a href="rulefit.html#theory-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let us dive deeper into the technical details of the RuleFit algorithm.
RuleFit consists of two components:
The first component creates “rules” from decision trees and the second component fits a linear model with the original features and the new rules as input (hence the name “RuleFit”).</p>
<p><strong>Step 1: Rule generation</strong></p>
<p>What does a rule look like?
The rules generated by the algorithm have a simple form.
For example:
IF <code>x2 &lt; 3</code> AND <code>x5 &lt; 7</code> THEN 1 ELSE 0.
The rules are constructed by decomposing decision trees:
Any path to a node in a tree can be converted to a decision rule.
The trees used for the rules are fitted to predict the target outcome.
Therefore the splits and resulting rules are optimized to predict the outcome you are interested in.
You simply chain the binary decisions that lead to a certain node with “AND”, and voilà, you have a rule.
It is desirable to generate a lot of diverse and meaningful rules.
Gradient boosting is used to fit an ensemble of decision trees by regressing or classifying y with your original features X.
Each resulting tree is converted into multiple rules.
Not only boosted trees, but any tree ensemble algorithm can be used to generate the trees for RuleFit.
A tree ensemble can be described with this general formula:</p>
<p><span class="math display">\[\hat{f}(x) = a_0+\sum_{m=1}^M a_m \hat{f}_m(X)\]</span></p>
<p>M is the number of trees and <span class="math inline">\(\hat{f}_m(x)\)</span> is the prediction function of the m-th tree.
The <span class="math inline">\(a\)</span>’s are the weights.
Bagged ensembles, random forest, AdaBoost and MART produce tree ensembles and can be used for RuleFit.</p>
<p>We create the rules from all trees of the ensemble.
Each rule <span class="math inline">\(r_m\)</span> takes the form of:</p>
<p><span class="math display">\[r_m(x)=\prod_{j\in\text{T}_m}I(x_j\in{}s_{jm})\]</span></p>
<p>where <span class="math inline">\(\text{T}_{m}\)</span> is the set of features used in the m-th tree, I is the indicator function that is 1 when feature <span class="math inline">\(x_j\)</span> is in the specified subset of values s for the j-th feature (as specified by the tree splits) and 0 otherwise.
For numerical features, <span class="math inline">\(s_{jm}\)</span> is an interval in the value range of the feature.
The interval looks like one of the two cases:</p>
<p><span class="math display">\[x_{s_{jm},\text{lower}}&lt;x_j\]</span></p>
<p><span class="math display">\[x_j&lt;x_{s_{jm},upper}\]</span></p>
<p>Further splits in that feature possibly lead to more complicated intervals.
For categorical features the subset s contains some specific categories of the feature.</p>
<p>A made up example for the bike rental dataset:</p>
<p><span class="math display">\[\begin{align*}
r_{17}(x) &amp; = I(x_{\text{temp}}&lt;15) \cdot I(x_{\text{weather}}\in\{\text{good},\text{cloudy}\}) \\
            &amp; \cdot I(10\leq x_{\text{windspeed}}&lt;20)
\end{align*}\]</span></p>
<p>This rule returns 1 if all three conditions are met, otherwise 0.
RuleFit extracts all possible rules from a tree, not only from the leaf nodes.
So another rule that would be created is:</p>
<p><span class="math display">\[r_{18}(x)=I(x_{\text{temp}}&lt;15)\cdot I(x_{\text{weather}}\in\{\text{good},\text{cloudy}\})\]</span></p>
<p>Altogether, the number of rules created from an ensemble of M trees with <span class="math inline">\(t_m\)</span> terminal nodes each is:</p>
<p><span class="math display">\[K=\sum_{m=1}^M2(t_m-1)\]</span></p>
<p>A trick introduced by the RuleFit authors is to learn trees with random depth so that many diverse rules with different lengths are generated.
Note that we discard the predicted value in each node and only keep the conditions that lead us to a node and then we create a rule from it.
The weighting of the decision rules is done in step 2 of RuleFit.</p>
<p>Another way to see step 1:
RuleFit generates a new set of features from your original features.
These features are binary and can represent quite complex interactions of your original features.
The rules are chosen to maximize the prediction task.
The rules are automatically generated from the covariates matrix X.
You can simply see the rules as new features based on your original features.</p>
<p><strong>Step 2: Sparse linear model</strong></p>
<p>You get MANY rules in step 1.
Since the first step can be seen as only a feature transformation, you are still not done with fitting a model.
Also, you want to reduce the number of rules.
In addition to the rules, all your “raw” features from your original dataset will also be used in the sparse linear model.
Every rule and every original feature becomes a feature in the linear model and gets a weight estimate.
The original raw features are added because trees fail at representing simple linear relationships between y and x.
Before we train a sparse linear model, we winsorize the original features so that they are more robust against outliers:</p>
<p><span class="math display">\[l_j^*(x_j)=min(\delta_j^+,max(\delta_j^-,x_j))\]</span></p>
<p>where <span class="math inline">\(\delta_j^-\)</span> and <span class="math inline">\(\delta_j^+\)</span> are the <span class="math inline">\(\delta\)</span> quantiles of the data distribution of feature <span class="math inline">\(x_j\)</span>.
A choice of 0.05 for <span class="math inline">\(\delta\)</span> means that any value of feature <span class="math inline">\(x_j\)</span> that is in the 5% lowest or 5% highest values will be set to the quantiles at 5% or 95% respectively.
As a rule of thumb, you can choose <span class="math inline">\(\delta\)</span> = 0.025.
In addition, the linear terms have to be normalized so that they have the same prior importance as a typical decision rule:</p>
<p><span class="math display">\[l_j(x_j)=0.4\cdot{}l^*_j(x_j)/std(l^*_j(x_j))\]</span></p>
<p>The <span class="math inline">\(0.4\)</span> is the average standard deviation of rules with a uniform support distribution of <span class="math inline">\(s_k\sim{}U(0,1)\)</span>.</p>
<p>We combine both types of features to generate a new feature matrix and train a sparse linear model with Lasso, with the following structure:</p>
<p><span class="math display">\[\hat{f}(x)=\hat{\beta}_0+\sum_{k=1}^K\hat{\alpha}_k{}r_k(x)+\sum_{j=1}^p\hat{\beta}_j{}l_j(x_j)\]</span></p>
<p>where <span class="math inline">\(\hat{\alpha}\)</span> is the estimated weight vector for the rule features and <span class="math inline">\(\hat{\beta}\)</span> the weight vector for the original features.
Since RuleFit uses Lasso, the loss function gets the additional constraint that forces some of the weights to get a zero estimate:</p>
<p><span class="math display">\[\begin{align*}
(\{\hat{\alpha}\}_1^K,\{\hat{\beta}\}_0^p) &amp; = &amp; argmin_{\{\hat{\alpha}\}_1^K,\{\hat{\beta}\}_0^p}\sum_{i=1}^n L(y^{(i)},f(x^{(i)}))  \\
&amp; + &amp; \lambda\cdot\left(\sum_{k=1}^K|\alpha_k| + \sum_{j=1}^p|\beta_j|\right)
\end{align*}\]</span></p>
<p>The result is a linear model that has linear effects for all of the original features and for the rules.
The interpretation is the same as for linear models, the only difference is that some features are now binary rules.</p>
<p><strong>Step 3 (optional): Feature importance</strong></p>
<p>For the linear terms of the original features, the feature importance is measured with the standardized predictor:</p>
<p><span class="math display">\[I_j=|\hat{\beta}_j|\cdot std(l_j(x_j))\]</span></p>
<p>where <span class="math inline">\(\beta_j\)</span> is the weight from the Lasso model and <span class="math inline">\(std(l_j(x_j))\)</span> is the standard deviation of the linear term over the data.</p>
<p>For the decision rule terms, the importance is calculated with the following formula:</p>
<p><span class="math display">\[I_k=|\hat{\alpha}_k|\cdot\sqrt{s_k(1-s_k)}\]</span></p>
<p>where <span class="math inline">\(\hat{\alpha}_k\)</span> is the associated Lasso weight of the decision rule and <span class="math inline">\(s_k\)</span> is the support of the feature in the data, which is the percentage of data points to which the decision rule applies (where <span class="math inline">\(r_k(x)=1\)</span>):</p>
<p><span class="math display">\[s_k=\frac{1}{n}\sum_{i=1}^n r_k(x^{(i)})\]</span></p>
<p>A feature occurs as a linear term and possibly also within many decision rules.
How do we measure the total importance of a feature?
The importance <span class="math inline">\(J_j(x)\)</span> of a feature can be measured for each individual prediction:</p>
<p><span class="math display">\[J_j(x)=I_j(x)+\sum_{x_j\in{}r_k}I_k(x)/m_k\]</span></p>
<p>where <span class="math inline">\(I_l\)</span> is the importance of the linear term and <span class="math inline">\(I_k\)</span> the importance of the decision rules in which <span class="math inline">\(x_j\)</span> appears, and <span class="math inline">\(m_k\)</span> is the number of features constituting the rule <span class="math inline">\(r_k\)</span>.
Adding the feature importance from all instances gives us the global feature importance:</p>
<p><span class="math display">\[J_j(X)=\sum_{i=1}^n{}J_j(x^{(i)})\]</span></p>
<p>It is possible to select a subset of instances and calculate the feature importance for this group.</p>
</div>
<div id="advantages-4" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Advantages<a href="rulefit.html#advantages-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>RuleFit automatically adds <strong>feature interactions</strong> to linear models.
Therefore, it solves the problem of linear models that you have to add interaction terms manually and it helps a bit with the issue of modeling nonlinear relationships.</p>
<p>RuleFit can handle both classification and regression tasks.</p>
<p>The rules created are easy to interpret, because they are binary decision rules.
Either the rule applies to an instance or not.
Good interpretability is only guaranteed if the number of conditions within a rule is not too large.
A rule with 1 to 3 conditions seems reasonable to me.
This means a maximum depth of 3 for the trees in the tree ensemble.</p>
<p>Even if there are many rules in the model, they do not apply to every instance.
For an individual instance only a handful of rules apply (= have a non-zero weights).
This improves local interpretability.</p>
<p>RuleFit proposes a bunch of useful diagnostic tools.
These tools are model-agnostic, so you can find them in the model-agnostic section of the book: <a href="feature-importance.html#feature-importance">feature importance</a>, <a href="pdp.html#pdp">partial dependence plots</a> and <a href="interaction.html#interaction">feature interactions</a>.</p>
</div>
<div id="disadvantages-4" class="section level3 hasAnchor" number="5.6.4">
<h3><span class="header-section-number">5.6.4</span> Disadvantages<a href="rulefit.html#disadvantages-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sometimes RuleFit creates many rules that get a non-zero weight in the Lasso model.
The interpretability degrades with increasing number of features in the model.
A promising solution is to force feature effects to be monotonic, meaning that an increase of a feature has to lead to an increase of the prediction.</p>
<p>An anecdotal drawback: The papers claim a good performance of RuleFit – often close to the predictive performance of random forests! – but in the few cases where I tried it personally, the performance was disappointing.
Just try it out for your problem and see how it performs.</p>
<p>The end product of the RuleFit procedure is a linear model with additional fancy features (the decision rules).
But since it is a linear model, the weight interpretation is still unintuitive.
It comes with the same “footnote” as a usual linear regression model:
“… given all features are fixed.”
It gets a bit more tricky when you have overlapping rules.
For example, one decision rule (feature) for the bicycle prediction could be: “temp &gt; 10” and another rule could be “temp &gt; 15 &amp; weather=‘GOOD’”.
If the weather is good and the temperature is above 15 degrees, the temperature is automatically greater then 10.
In the cases where the second rule applies, the first rule applies as well.
The interpretation of the estimated weight for the second rule is:
“Assuming all other features remain fixed, the predicted number of bikes increases by <span class="math inline">\(\beta_2\)</span> when the weather is good and temperature above 15 degrees.”.
But, now it becomes really clear that the ‘all other feature fixed’ is problematic, because if rule 2 applies, also rule 1 applies and the interpretation is nonsensical.</p>
</div>
<div id="software-and-alternative" class="section level3 hasAnchor" number="5.6.5">
<h3><span class="header-section-number">5.6.5</span> Software and Alternative<a href="rulefit.html#software-and-alternative" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The RuleFit algorithm is implemented in R by Fokkema and Christoffersen (2017)<a href="#fn26" class="footnote-ref" id="fnref26"><sup>26</sup></a> and you can find a <a href="https://github.com/christophM/rulefit">Python version on GitHub</a>.</p>
<p>A very similar framework is <a href="https://github.com/scikit-learn-contrib/skope-rules">skope-rules</a>, a Python module that also extracts rules from ensembles.
It differs in the way it learns the final rules:
First, skope-rules remove low-performing rules, based on recall and precision thresholds.
Then, duplicate and similar rules are removed by performing a selection based on the diversity of logical terms (variable + larger/smaller operator) and performance (F1-score) of the rules.
This final step does not rely on using Lasso, but considers only the out-of-bag F1-score and the logical terms which form the rules.</p>
<p>The <a href="https://github.com/csinva/imodels">imodels package</a> also contains implementations of other rule sets, such as Bayesian rule sets, Boosted rule sets, and SLIPPER rule sets as a Python package with a unified scikit-learn interface.</p>

<div style="page-break-after: always;"></div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="25">
<li id="fn25"><p>Friedman, Jerome H, and Bogdan E Popescu. “Predictive learning via rule ensembles.” The Annals of Applied Statistics. JSTOR, 916–54. (2008).<a href="rulefit.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>Fokkema, Marjolein, and Benjamin Christoffersen. “Pre: Prediction rule ensembles”. <a href="https://CRAN.R-project.org/package=pre" class="uri">https://CRAN.R-project.org/package=pre</a> (2017).<a href="rulefit.html#fnref26" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="rules.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="other-interpretable.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": true,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/manuscript/04.7-interpretable-rulefit.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
