<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Explainable machine learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable.">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="Explainable machine learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable." />
  <meta name="github-repo" content="christophM/xai-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Explainable machine learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisons more explainable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2017-07-12">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="outline.html">
<link rel="next" href="definitions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-0.8/htmlwidgets.js"></script>
<script src="libs/datatables-binding-0.2/datatables.js"></script>
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.12/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.12/js/jquery.dataTables.min.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Explainable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="who-should-read-this-book.html"><a href="who-should-read-this-book.html"><i class="fa fa-check"></i><b>1.1</b> Who should read this book</a></li>
<li class="chapter" data-level="1.2" data-path="outline.html"><a href="outline.html"><i class="fa fa-check"></i><b>1.2</b> Outline</a></li>
<li class="chapter" data-level="1.3" data-path="what-is-machine-learning-and-why-is-it-important.html"><a href="what-is-machine-learning-and-why-is-it-important.html"><i class="fa fa-check"></i><b>1.3</b> What is machine learning and why is it important?</a></li>
<li class="chapter" data-level="1.4" data-path="definitions.html"><a href="definitions.html"><i class="fa fa-check"></i><b>1.4</b> Definitions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="explainability.html"><a href="explainability.html"><i class="fa fa-check"></i><b>2</b> Explainability</a><ul>
<li class="chapter" data-level="2.1" data-path="what-is-explainability.html"><a href="what-is-explainability.html"><i class="fa fa-check"></i><b>2.1</b> What is explainability</a></li>
<li class="chapter" data-level="2.2" data-path="when-is-explainability-important.html"><a href="when-is-explainability-important.html"><i class="fa fa-check"></i><b>2.2</b> When is explainability important?</a></li>
<li class="chapter" data-level="2.3" data-path="the-bigger-picture.html"><a href="the-bigger-picture.html"><i class="fa fa-check"></i><b>2.3</b> The bigger picture</a></li>
<li class="chapter" data-level="2.4" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html"><i class="fa fa-check"></i><b>2.4</b> Scope of explainability</a><ul>
<li class="chapter" data-level="2.4.1" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.4.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.4.2" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-holistic-model-explainability"><i class="fa fa-check"></i><b>2.4.2</b> Global, holistic model explainability</a></li>
<li class="chapter" data-level="2.4.3" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#global-model-explainability-on-a-modular-level"><i class="fa fa-check"></i><b>2.4.3</b> Global model explainability on a modular level</a></li>
<li class="chapter" data-level="2.4.4" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decision-for-a-single-instance"><i class="fa fa-check"></i><b>2.4.4</b> Explain the decision for a single instance</a></li>
<li class="chapter" data-level="2.4.5" data-path="scope-of-explainability.html"><a href="scope-of-explainability.html#explain-the-decisions-for-a-group-of-instances"><i class="fa fa-check"></i><b>2.4.5</b> Explain the decisions for a group of instances</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html"><i class="fa fa-check"></i><b>2.5</b> Evaluating explainability</a><ul>
<li class="chapter" data-level="2.5.1" data-path="evaluating-explainability.html"><a href="evaluating-explainability.html#approaches-for-evaluation-of-the-explanation-quality"><i class="fa fa-check"></i><b>2.5.1</b> Approaches for evaluation of the explanation quality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>3</b> Simple, interpretable models</a><ul>
<li class="chapter" data-level="3.1" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>3.1</b> Terminology</a></li>
<li class="chapter" data-level="3.2" data-path="the-dataset-speed-dating.html"><a href="the-dataset-speed-dating.html"><i class="fa fa-check"></i><b>3.2</b> The dataset: speed dating</a></li>
<li class="chapter" data-level="3.3" data-path="TubeSpam.html"><a href="TubeSpam.html"><i class="fa fa-check"></i><b>3.3</b> TubeSpam dataset: Spam classification on YouTube comments</a></li>
<li class="chapter" data-level="3.4" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i><b>3.4</b> Overview</a></li>
<li class="chapter" data-level="3.5" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>3.5</b> Linear models</a><ul>
<li class="chapter" data-level="3.5.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>3.5.1</b> Interpretation</a></li>
<li class="chapter" data-level="3.5.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>3.5.2</b> Interpretation example</a></li>
<li class="chapter" data-level="3.5.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>3.5.3</b> Interpretation templates</a></li>
<li class="chapter" data-level="3.5.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>3.5.4</b> Visual parameter interpretation</a></li>
<li class="chapter" data-level="3.5.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>3.5.5</b> Explaining single predictions</a></li>
<li class="chapter" data-level="3.5.6" data-path="limo.html"><a href="limo.html#coding-categorical-variables"><i class="fa fa-check"></i><b>3.5.6</b> Coding categorical variables:</a></li>
<li class="chapter" data-level="3.5.7" data-path="limo.html"><a href="limo.html#assuring-sparsity-in-linear-models"><i class="fa fa-check"></i><b>3.5.7</b> Assuring sparsity in linear models</a></li>
<li class="chapter" data-level="3.5.8" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>3.5.8</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="3.5.9" data-path="limo.html"><a href="limo.html#towards-complexer-relationships-within-linear-model-class"><i class="fa fa-check"></i><b>3.5.9</b> Towards complexer relationships within linear model class</a></li>
<li class="chapter" data-level="3.5.10" data-path="limo.html"><a href="limo.html#linear-models-beyond-gaussian-regression"><i class="fa fa-check"></i><b>3.5.10</b> Linear models beyond gaussian regression</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>3.6</b> Decision trees</a><ul>
<li class="chapter" data-level="3.6.1" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-1"><i class="fa fa-check"></i><b>3.6.1</b> Interpretation</a></li>
<li class="chapter" data-level="3.6.2" data-path="decision-trees.html"><a href="decision-trees.html#interpretation-example-1"><i class="fa fa-check"></i><b>3.6.2</b> Interpretation example</a></li>
<li class="chapter" data-level="3.6.3" data-path="decision-trees.html"><a href="decision-trees.html#advantages"><i class="fa fa-check"></i><b>3.6.3</b> Advantages</a></li>
<li class="chapter" data-level="3.6.4" data-path="decision-trees.html"><a href="decision-trees.html#disadvantages"><i class="fa fa-check"></i><b>3.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="other-simple-explainable-models.html"><a href="other-simple-explainable-models.html"><i class="fa fa-check"></i><b>3.7</b> Other simple, explainable models</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="model-agnostic-explanations.html"><a href="model-agnostic-explanations.html"><i class="fa fa-check"></i><b>4</b> Model-agnostic explanations</a><ul>
<li class="chapter" data-level="4.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html"><i class="fa fa-check"></i><b>4.1</b> Global: Explain the behaviour of a model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#global-surrogate-models"><i class="fa fa-check"></i><b>4.1.1</b> Global surrogate models</a></li>
<li class="chapter" data-level="4.1.2" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#partial-dependence-plot"><i class="fa fa-check"></i><b>4.1.2</b> Partial dependence plot</a></li>
<li class="chapter" data-level="4.1.3" data-path="global-explain-the-behaviour-of-a-model.html"><a href="global-explain-the-behaviour-of-a-model.html#feature-importance"><i class="fa fa-check"></i><b>4.1.3</b> Feature importance</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html"><i class="fa fa-check"></i><b>4.2</b> Local: Explain a single decisions</a><ul>
<li class="chapter" data-level="4.2.1" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#individual-conditional-expectation-ice-plot"><i class="fa fa-check"></i><b>4.2.1</b> Individual Conditional Expectation (ICE) plot</a></li>
<li class="chapter" data-level="4.2.2" data-path="local-explain-a-single-decisions.html"><a href="local-explain-a-single-decisions.html#local-surrogate-models-lime"><i class="fa fa-check"></i><b>4.2.2</b> Local surrogate models (LIME)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="model-agnostic-why-not-use-them-on-the-data-itself.html"><a href="model-agnostic-why-not-use-them-on-the-data-itself.html"><i class="fa fa-check"></i><b>4.3</b> Model-agnostic: Why not use them on the data itself?</a></li>
<li class="chapter" data-level="4.4" data-path="explanation-types.html"><a href="explanation-types.html"><i class="fa fa-check"></i><b>4.4</b> Explanation types</a><ul>
<li class="chapter" data-level="4.4.1" data-path="explanation-types.html"><a href="explanation-types.html#structured-output"><i class="fa fa-check"></i><b>4.4.1</b> Structured output</a></li>
<li class="chapter" data-level="4.4.2" data-path="explanation-types.html"><a href="explanation-types.html#viz-explanation"><i class="fa fa-check"></i><b>4.4.2</b> Visualization</a></li>
<li class="chapter" data-level="4.4.3" data-path="explanation-types.html"><a href="explanation-types.html#natural-language-narratives"><i class="fa fa-check"></i><b>4.4.3</b> Natural language (narratives)</a></li>
<li class="chapter" data-level="4.4.4" data-path="explanation-types.html"><a href="explanation-types.html#examples-and-prototypes"><i class="fa fa-check"></i><b>4.4.4</b> Examples and prototypes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>5</b> References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explainable machine learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="what-is-machine-learning-and-why-is-it-important" class="section level2">
<h2><span class="header-section-number">1.3</span> What is machine learning and why is it important?</h2>
<p>So what is machine learning? In general we speak of predictive models, that take some input vector (features) and map it to an output. If the output is a categorical variable people often name it classification and if it is a numerical variable, then regression. Machine learning is a set of algorithms that can learn these mappings from training data, which are pairs of input features and output variable. The machine learning algorithm learns a model by changing parameters (like linear weights) or learning structures (like trees). The algorithm is guided by a score or loss function that is minimized. A fully trained machine learning model can then be used to make predictions for new instances.</p>
<p>Recommendation of products, identifying street signs, counting people on the street, assessing a personâ€™s credit worthiness, detecting fraud: All these examples have in common that they can, and are increasingly, realized with machine learning models. The tasks are different, but the approach is the same: Step 1 is to collect data. This can be images with and without street signs plus the information which sign is visible or the personal data from loan applicants together with the information if they repaid their loan or not. Step 2: Feed this information into a machine learning algorithm, which produces a sign detector model or a credit worthiness model. This model can then be used in Step 3: Integrate the model into the product or process, like an self-driving car or a loan application process.</p>
<p>There are a lot of tasks in which machines exceed humans. Even if the machine is as good as a human at a task, or slightly worse, there remains big advantages, and that is speed, reproducibility and scale. A machine learning model that has been implemented once, can do a task much faster than humans, will reliably produce the same results from the same input and can be copied endlessly.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="outline.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="definitions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/xai-book/edit/master/01-introduction.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
