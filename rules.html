<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>10&nbsp; Decision Rules ‚Äì Interpretable Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./rulefit.html" rel="next">
<link href="./tree.html" rel="prev">
<link href="./images/favicon.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/cookie-consent/cookie-consent.js"></script>
<link href="site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5e169a3c071d6ad0320cbd7522dabfb3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V7RTNZBGE2"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-V7RTNZBGE2', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<!-- Add this to your header.html -->
<style>
.book-purchase-links {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.5rem;
    background: linear-gradient(to bottom right, #ffffff, #f8f9fa);
    border-radius: 12px;
    margin: 1.5rem 0;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    border: double 1px transparent;
    background-image: linear-gradient(to bottom right, #ffffff, #f8f9fa),
                     linear-gradient(to bottom right, #3b82f6, #60a5fa);
    background-origin: border-box;
    background-clip: padding-box, border-box;
}

.purchase-header {
    text-align: center;
    margin-bottom: -1rem;
    margin-top: -1rem;
    color: #2b3442;
}

.purchase-header h3 {
    margin: 0 0 0.5rem 0;
    font-size: 1.5rem;
    font-weight: 700;
}

.purchase-header p {
    margin: 0;
    font-size: 0.9rem;
    color: #6c757d;
}

.book-cover {
    width: 80%;
    height: auto;
    border-radius: 8px;
    margin: 0 auto 1rem auto;
    transition: transform 0.3s ease;
}

.book-cover:hover {
    transform: scale(1.1);
}

.purchase-link {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    text-decoration: none;
    color: #2b3442;
    border-radius: 8px;
    transition: all 0.2s ease;
    background: white;
    border: 1px solid #e9ecef;
    font-weight: 500;
}

.purchase-link:hover {
    background-color: #f8f9fa;
    transform: translateY(-2px);
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    text-decoration: none;
}

.purchase-link.primary {
    background-color: #0066cc;
    color: white;
    border: none;
}

.purchase-link.primary:hover {
    background-color: #0052a3;
}

.purchase-link svg {
    width: 20px;
    height: 20px;
    flex-shrink: 0;
}

.price-tag {
    margin-left: auto;
    font-weight: 600;
    color: inherit;
}

.social-proof {
    text-align: center;
    font-size: 0.85rem;
    color: #6c757d;
    margin-top: 0.5rem;
}

.limited-offer {
    background: #fff3cd;
    color: #856404;
    padding: 0.5rem;
    border-radius: 6px;
    font-size: 0.85rem;
    text-align: center;
    margin-bottom: 1rem;
}

@media (max-width: 768px) {
    .book-purchase-links {
        padding: 1rem;
    }
    
    .book-cover {
        width: 60%;
    }
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const purchaseLinksContainer = document.getElementById('book-purchase-links');
    if (!purchaseLinksContainer) return;

    const purchaseOptions = [
        {
            type: 'Paperback',
            primary: true,
            url: 'https://bookgoodies.com/a/3911578032',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>'
        },
        {
            type: 'E-Book & PDF',
            url: 'https://leanpub.com/interpretable-machine-learning',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path><path d="M12 6v8"></path><path d="M8 10h8"></path></svg>'
        }
    ];

    // Create header section
    const header = document.createElement('div');
    header.className = 'purchase-header';
    header.innerHTML = `
        <h3>Buy Book</h3>
    `;
    purchaseLinksContainer.appendChild(header);

    // Create limited time offer banner
    // const limitedOffer = document.createElement('div');
    // limitedOffer.className = 'limited-offer';
    // limitedOffer.textContent = 'üéâ Special Launch Price - Limited Time Only!';
    // purchaseLinksContainer.appendChild(limitedOffer);

    // Create and append book cover
    const bookCover = document.createElement('img');
    //bookCover.src = 'images/mockup-floating.png';
    bookCover.src = './images/cover-sidepanel.jpg';
    bookCover.alt = 'Book Cover';
    bookCover.className = 'book-cover';
    purchaseLinksContainer.appendChild(bookCover);

    // Create and append purchase links
    purchaseOptions.forEach(option => {
        const link = document.createElement('a');
        link.href = option.url;
        link.className = `purchase-link ${option.primary ? 'primary' : ''}`;
        link.innerHTML = `
            ${option.icon}
            ${option.type}
        `;
        purchaseLinksContainer.appendChild(link);
    });

    // Add social proof
    // const socialProof = document.createElement('div');
    // socialProof.className = 'social-proof';
    // socialProof.textContent = 'üë• Join thousands of satisfied readers!';
    // purchaseLinksContainer.appendChild(socialProof);
});
</script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./limo.html">Interpretable Models</a></li><li class="breadcrumb-item"><a href="./rules.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Interpretable Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/christophM/interpretable-ml-book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./goals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Goals of Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Methods Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data and Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Interpretable Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./limo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./extend-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">GLM, GAM and more</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Tree</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rules.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rulefit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">RuleFit</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Local Modal-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ceteris-paribus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ceteris Paribus Plots</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Individual Conditional Expectation (ICE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LIME</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./counterfactual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anchors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Scoped Rules (Anchors)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shapley.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Shapley Values</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">SHAP</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Global Model-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pdp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Partial Dependence Plot (PDP)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Accumulated Local Effects (ALE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interaction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Feature Interaction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Permutation Feature Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lofo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Leave One Feature Out (LOFO) Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./global.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Surrogate Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Prototypes and Criticisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Neural Network Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cnn-features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Learned Features</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pixel-attribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Saliency Maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./detecting-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Detecting Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adversarial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Adversarial Examples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./influential.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Influential Instances</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Beyond the Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Evaluation of Interpretability Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./storytime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Story Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">The Future of Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./translations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Translations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cite.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Citing this Book</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Acknowledgments</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what-is-machine-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Machine Learning Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./math-terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Math Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">R packages used</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learn-rules-from-a-single-feature-oner" id="toc-learn-rules-from-a-single-feature-oner" class="nav-link active" data-scroll-target="#learn-rules-from-a-single-feature-oner">Learn rules from a single feature (OneR)</a></li>
  <li><a href="#sequential-covering" id="toc-sequential-covering" class="nav-link" data-scroll-target="#sequential-covering">Sequential covering</a></li>
  <li><a href="#bayesian-rule-lists" id="toc-bayesian-rule-lists" class="nav-link" data-scroll-target="#bayesian-rule-lists">Bayesian Rule Lists</a></li>
  <li><a href="#strengths" id="toc-strengths" class="nav-link" data-scroll-target="#strengths">Strengths</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#software-and-alternatives" id="toc-software-and-alternatives" class="nav-link" data-scroll-target="#software-and-alternatives">Software and alternatives</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/rules.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<div id="book-purchase-links" class="book-purchase-links">

</div>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./limo.html">Interpretable Models</a></li><li class="breadcrumb-item"><a href="./rules.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="rules" class="quarto-section-identifier"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A decision rule is a simple IF-THEN statement consisting of a condition (also called antecedent) and a prediction. For example: IF it rains today AND if it is April (condition), THEN it will rain tomorrow (prediction). A single decision rule or a combination of several rules can be used to make predictions.</p>
<!-- *Keywords: decision rules, decision sets, decision lists, association rules, IF-THEN rules* -->
<p>Decision rules follow a general structure: IF the conditions are met THEN make a certain prediction. Decision rules are probably the most interpretable prediction models: Their IF-THEN structure semantically resembles natural language and the way we think, provided that the condition is built from intelligible features, the length of the condition is short (small number of <code>feature=value</code> pairs combined with an AND) and there are not too many rules. In programming, it‚Äôs very natural to write IF-THEN rules. New in machine learning is that the decision rules are learned through an algorithm.</p>
<p>Imagine using an algorithm to learn decision rules for predicting the value of a house (<code>low</code>, <code>ok</code> or <code>high</code>). One decision rule learned by this model could be: If a house is bigger than 100 square meters and has a garden, then its value is high. More formally: IF <code>size&gt;100 AND garden=1</code> THEN <code>value=high</code>.</p>
<p>Let‚Äôs break down the decision rule:</p>
<ul>
<li><code>size&gt;100</code> is the first condition in the IF-part.</li>
<li><code>garden=1</code> is the second condition in the IF-part.</li>
<li>The two conditions are connected with an ‚ÄòAND‚Äô to create a new condition. Both must be true for the rule to apply.</li>
<li>The predicted outcome (THEN-part) is <code>value=high</code>.</li>
</ul>
<p>A decision rule uses at least one <code>feature=value</code> statement in the condition, with no upper limit on how many more can be added with an ‚ÄòAND‚Äô. An exception is the default rule that has no explicit IF-part and that applies when no other rule applies, but more about this later.</p>
<p>The usefulness of a decision rule is usually summarized in two numbers: support and accuracy.</p>
<p><strong>Support or coverage of a rule</strong>: The percentage of instances to which the condition of a rule applies is called the support. Take for example the rule <code>size=big AND location=good THEN value=high</code> for predicting house values. Suppose 100 of 1,000 houses are big and in a good location, then the support of the rule is 10%. The prediction (THEN-part) is not important for the calculation of support.</p>
<p><strong>Accuracy or confidence of a rule</strong>: The accuracy of a rule is a measure of how accurate the rule is in predicting the correct class for the instances to which the condition of the rule applies. For example: Let‚Äôs say of the 100 houses, where the rule <code>size=big AND location=good THEN value=high</code> applies, 85 have <code>value=high</code>, 14 have <code>value=ok</code> and 1 has <code>value=low</code>, then the accuracy of the rule is 85%.</p>
<p>Usually, there is a trade-off between accuracy and support: By adding more features to the condition, we can achieve higher accuracy, but lose support.</p>
<p>To create a good classifier for predicting the value of a house, you might need to learn not only one rule but maybe 10 or 20. Then things can get more complicated, and you can run into one of the following problems:</p>
<ul>
<li>Rules can overlap: What if I want to predict the value of a house and two or more rules apply and they give me contradictory predictions?</li>
<li>No rule applies: What if I want to predict the value of a house and none of the rules apply?</li>
</ul>
<p>There are two main strategies for combining multiple rules: Decision lists (ordered) and decision sets (unordered). Both strategies imply different solutions to the problem of overlapping rules.</p>
<p>A <strong>decision list</strong> introduces an order to the decision rules. If the condition of the first rule is true for an instance, we use the prediction of the first rule. If not, we go to the next rule and check if it applies, and so on. Decision lists solve the problem of overlapping rules by only returning the prediction of the first rule in the list that applies.</p>
<p>A <strong>decision set</strong> resembles a democracy of the rules, except that some rules might have a higher voting power. In a set, the rules are either mutually exclusive, or there is a strategy for resolving conflicts, such as majority voting, which may be weighted by the individual rule accuracies or other quality measures. Interpretability suffers potentially when several rules apply.</p>
<p>Both decision lists and sets can suffer from the problem that no rule applies to an instance. This can be resolved by introducing a default rule. The default rule is the rule that applies when no other rule applies. The prediction of the default rule is often the most frequent class of the data points that are not covered by other rules. If a set or list of rules covers the entire feature space, we call it exhaustive. By adding a default rule, a set or list automatically becomes exhaustive.</p>
<p>There are many ways to learn rules from data, and this book is far from covering them all. This chapter shows you three of them. The algorithms are chosen to cover a wide range of general ideas for learning rules, so all three of them represent very different approaches.</p>
<ol type="1">
<li><strong>OneR</strong> learns rules from a single feature. OneR is characterized by its simplicity, interpretability and its use as a benchmark.</li>
<li><strong>Sequential covering</strong> is a general procedure that iteratively learns rules and removes the data points that are covered by the new rule. This procedure is used by many rule learning algorithms.</li>
<li><strong>Bayesian Rule Lists</strong> combine pre-mined frequent patterns into a decision list using Bayesian statistics. Using pre-mined patterns is a common approach used by many rule learning algorithms.</li>
</ol>
<p>Let‚Äôs start with the simplest approach: Using the single best feature to learn rules.</p>
<section id="learn-rules-from-a-single-feature-oner" class="level2">
<h2 class="anchored" data-anchor-id="learn-rules-from-a-single-feature-oner">Learn rules from a single feature (OneR)</h2>
<p>The OneR algorithm <span class="citation" data-cites="holte1993very">(<a href="references.html#ref-holte1993very" role="doc-biblioref">Holte 1993</a>)</span> is one of the simplest rule induction algorithms. From all the features, OneR selects the one that carries the most information about the outcome of interest and creates decision rules from this feature.</p>
<p>Despite the name OneR, which stands for ‚ÄúOne Rule,‚Äù the algorithm generates more than one rule: It‚Äôs actually one rule per unique feature value of the selected best feature. A more fitting name would be OneFeatureRule.</p>
<p>The algorithm is simple and fast:</p>
<ol type="1">
<li>Discretize the continuous features by choosing appropriate intervals.</li>
<li>For each feature:
<ul>
<li>Create a cross table between the feature values and the (categorical) outcome.</li>
<li>For each value of the feature, create a rule which predicts the most frequent class of the instances that have this particular feature value (can be read from the cross table).</li>
<li>Calculate the total error of the rules for the feature.</li>
</ul></li>
<li>Select the feature with the smallest total error.</li>
</ol>
<p>OneR always covers all instances of the dataset, since it uses all levels of the selected feature. Missing values can be either treated as an additional feature value or be imputed beforehand.</p>
<p>A OneR model is a decision tree with only one split. The split is not necessarily binary as in CART, but depends on the number of unique feature values.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Use OneR as baseline
</div>
</div>
<div class="callout-body-container callout-body">
<p>OneR makes for a great baseline to compare more complex models against.</p>
</div>
</div>
<p>Let‚Äôs look at an example of how the best feature is chosen by OneR. <a href="#tbl-oner-freq-table1" class="quarto-xref">Table&nbsp;<span>10.1</span></a> shows an artificial dataset about houses with information about their value, location, size, and whether pets are allowed. We are interested in learning a simple model to predict the value of a house.</p>
<div class="cell">
<div id="tbl-oner-freq-table1" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-oner-freq-table1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.1: Artificial dataset for house value.
</figcaption>
<div aria-describedby="tbl-oner-freq-table1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">location</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">size</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">pets</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">good</td>
<td style="text-align: left;">small</td>
<td style="text-align: left;">yes</td>
<td style="text-align: left;">high</td>
</tr>
<tr class="even">
<td style="text-align: left;">good</td>
<td style="text-align: left;">big</td>
<td style="text-align: left;">no</td>
<td style="text-align: left;">high</td>
</tr>
<tr class="odd">
<td style="text-align: left;">good</td>
<td style="text-align: left;">big</td>
<td style="text-align: left;">no</td>
<td style="text-align: left;">high</td>
</tr>
<tr class="even">
<td style="text-align: left;">bad</td>
<td style="text-align: left;">medium</td>
<td style="text-align: left;">no</td>
<td style="text-align: left;">ok</td>
</tr>
<tr class="odd">
<td style="text-align: left;">good</td>
<td style="text-align: left;">medium</td>
<td style="text-align: left;">only cats</td>
<td style="text-align: left;">ok</td>
</tr>
<tr class="even">
<td style="text-align: left;">good</td>
<td style="text-align: left;">small</td>
<td style="text-align: left;">only cats</td>
<td style="text-align: left;">ok</td>
</tr>
<tr class="odd">
<td style="text-align: left;">bad</td>
<td style="text-align: left;">medium</td>
<td style="text-align: left;">yes</td>
<td style="text-align: left;">ok</td>
</tr>
<tr class="even">
<td style="text-align: left;">bad</td>
<td style="text-align: left;">small</td>
<td style="text-align: left;">yes</td>
<td style="text-align: left;">low</td>
</tr>
<tr class="odd">
<td style="text-align: left;">bad</td>
<td style="text-align: left;">medium</td>
<td style="text-align: left;">yes</td>
<td style="text-align: left;">low</td>
</tr>
<tr class="even">
<td style="text-align: left;">bad</td>
<td style="text-align: left;">small</td>
<td style="text-align: left;">no</td>
<td style="text-align: left;">low</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>OneR constructs rules based on the cross-tables between each feature and the outcome. <a href="#tbl-cross-tables" class="quarto-xref">Table&nbsp;<span>10.2</span></a> shows the three cross tables.</p>
<div class="cell">
<div id="tbl-cross-tables" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cross-tables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.2: Cross tables between each feature and the target.
</figcaption>
<div aria-describedby="tbl-cross-tables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">value=low</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">value=ok</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">value=high</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">size=big</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="even">
<td style="text-align: left;">size=medium</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">size=small</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">pets=no</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">pets=only cats</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">pets=yes</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">location=bad</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">location=good</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">3</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>For each feature, we go through the table row by row: Each feature value is the IF-part of a rule; the most common class for instances with this feature value is the prediction, the THEN-part of the rule. For example, the size feature with the levels <code>small</code>, <code>medium</code>, and <code>big</code> results in three rules. For each feature, we calculate the total error rate of the generated rules, which is the sum of the errors. The location feature has the possible values <code>bad</code> and <code>good</code>. The most frequent value for houses in bad locations is <code>low</code>, and when we use <code>low</code> as a prediction, we make two mistakes, because two houses have an <code>ok</code> value. The predicted value of houses in good locations is <code>high</code>, and again we make two mistakes, because two houses have an <code>ok</code> value. The error we make by using the location feature is <span class="math inline">\(\frac{4}{10}\)</span>, for the size feature it is <span class="math inline">\(\frac{3}{10}\)</span>, and for the pet feature it is <span class="math inline">\(\frac{4}{10}\)</span>. The size feature produces the rules with the lowest error and will be used for the final OneR model:</p>
<p>IF <code>size=small</code> THEN <code>value=low</code><br>
IF <code>size=medium</code> THEN <code>value=ok</code><br>
IF <code>size=big</code> THEN <code>value=high</code></p>
<p>If not properly validated, OneR may overfit on features with many possibly levels. Imagine a dataset that contains only noise and no signal, which means that all features take on random values and have no predictive value for the target. Some features have more levels than others. The features with more levels can now more easily overfit. A feature that has a separate level for each instance from the data would perfectly predict the entire training dataset. A solution would be to split the data into training and validation sets, learn the rules on the training data, and evaluate the total error for choosing the feature on the validation set.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Use validation data
</div>
</div>
<div class="callout-body-container callout-body">
<p>Always validate your chosen model with a separate validation set to ensure that it performs well on unseen data, even if it‚Äôs a simple ‚Äúone-rule‚Äù model.</p>
</div>
</div>
<p>Ties are another issue, i.e.&nbsp;when two features result in the same total error. OneR solves ties by either taking the first feature with the lowest error or the one with the lowest p-value of a chi-squared test.</p>
<p><strong>Example</strong></p>
<p>Let‚Äôs try OneR with real data. We use the <a href="data.html#penguins">Palmer penguins data</a> to test the OneR algorithm. All continuous input features were discretized into 5 quantiles. The rules created by the OneR learning algorithms are shown in <a href="#tbl-oner-penguins" class="quarto-xref">Table&nbsp;<span>10.3</span></a>.</p>
<div class="cell">
<div id="tbl-oner-penguins" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-oner-penguins-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.3: Rule learned by OneR for penguin classification.
</figcaption>
<div aria-describedby="tbl-oner-penguins-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">bill_depth_mm</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(13.1,14.7]</td>
<td style="text-align: left;">female</td>
</tr>
<tr class="even">
<td style="text-align: left;">(14.7,16.3]</td>
<td style="text-align: left;">male</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(16.3,18]</td>
<td style="text-align: left;">female</td>
</tr>
<tr class="even">
<td style="text-align: left;">(18,19.6]</td>
<td style="text-align: left;">male</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(19.6,21.2]</td>
<td style="text-align: left;">male</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>The <code>bill_depth_mm</code> feature was chosen by OneR as the best predictive feature. To get a better feel for how this one rule performs, let‚Äôs look into the cross table between the (discretized) <code>bill_depth_mm</code> feature and the penguin species, see <a href="#tbl-oner-penguin-confusion" class="quarto-xref">Table&nbsp;<span>10.4</span></a>.</p>
<div class="cell">
<div id="tbl-oner-penguin-confusion" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-oner-penguin-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.4: Confusion matrix for penguin sex classification rule found by OneR.
</figcaption>
<div aria-describedby="tbl-oner-penguin-confusion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">bill_depth_mm</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">female</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">male</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">[13.1,14.7)</td>
<td style="text-align: center;">86.7% (13)</td>
<td style="text-align: center;">13.3% (2)</td>
</tr>
<tr class="even">
<td style="text-align: center;">[14.7,16.3)</td>
<td style="text-align: center;">38.5% (10)</td>
<td style="text-align: center;">61.5% (16)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">[16.3,18)</td>
<td style="text-align: center;">72.0% (18)</td>
<td style="text-align: center;">28.0% (7)</td>
</tr>
<tr class="even">
<td style="text-align: center;">[18,19.6)</td>
<td style="text-align: center;">34.4% (11)</td>
<td style="text-align: center;">65.6% (21)</td>
</tr>
<tr class="odd">
<td style="text-align: center;">[19.6,21.2)</td>
<td style="text-align: center;">0% (0)</td>
<td style="text-align: center;">100.0% (12)</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>We can see that this feature is particularly useful for classifying penguins with deep bills. Penguins with bills with a depth of over 1.98 cm are most likely to be male. Very short bills make it likely that we are dealing with a female penguin. Caveat: This model ignores the species, or rather bundles them all together. To fix this, we could train one model per species.</p>
<p>OneR doesn‚Äôt inherently support regression tasks. But we can turn a regression task into a classification task by cutting the continuous outcome into intervals. We use this trick to predict the number of <a href="data.html#bike-data">rented bikes</a> with OneR by cutting the number of bikes into its four quartiles (0-25%, 25-50%, 50-75%, and 75-100%). <a href="#tbl-oner-bike" class="quarto-xref">Table&nbsp;<span>10.5</span></a> shows the selected feature after fitting the OneR model: The selected feature is the previous bike rental count.</p>
<div class="cell">
<div id="tbl-oner-bike" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-oner-bike-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.5: OneR classification rule for the bike data.
</figcaption>
<div aria-describedby="tbl-oner-bike-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">cnt_2d_bfr</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(13.3,1.76e+03]</td>
<td style="text-align: left;">[22,3193]</td>
</tr>
<tr class="even">
<td style="text-align: left;">(1.76e+03,3.5e+03]</td>
<td style="text-align: left;">[22,3193]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(3.5e+03,5.24e+03]</td>
<td style="text-align: left;">(4551,5978.5]</td>
</tr>
<tr class="even">
<td style="text-align: left;">(5.24e+03,6.98e+03]</td>
<td style="text-align: left;">(5978.5,8714]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(6.98e+03,8.72e+03]</td>
<td style="text-align: left;">(5978.5,8714]</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>Now we move from the simple OneR algorithm to a more complex procedure using rules with more complex conditions consisting of several features: Sequential Covering.</p>
</section>
<section id="sequential-covering" class="level2">
<h2 class="anchored" data-anchor-id="sequential-covering">Sequential covering</h2>
<p>Sequential covering is a general procedure that repeatedly learns a single rule to create a decision list (or set) that covers the entire dataset rule by rule. Many rule-learning algorithms are part of the sequential covering family. This chapter introduces the main recipe and uses RIPPER, a variant of the sequential covering algorithm, for the examples.</p>
<p>The idea is simple: First, find a good rule that applies to some of the data points. Remove all data points that are covered by the rule. A data point is covered when the conditions apply, regardless of whether the points are classified correctly or not. Repeat the rule-learning and removal of covered points with the remaining points until no more points are left, or another stop condition is met. The result is a decision list. This approach of repeated rule-learning and removal of covered data points is called ‚Äúseparate-and-conquer.‚Äù</p>
<p>Suppose we already have an algorithm that can create a single rule that covers part of the data. The sequential covering algorithm for two classes (one positive, one negative) works like this:</p>
<ul>
<li>Start with an empty list of rules (rlist).</li>
<li>Learn a rule <span class="math inline">\(r\)</span>.</li>
<li>While the list of rules is below a certain quality threshold (or positive examples are not yet covered):
<ul>
<li>Add rule <span class="math inline">\(r\)</span> to rlist.</li>
<li>Remove all data points covered by rule <span class="math inline">\(r\)</span>.</li>
<li>Learn another rule on the remaining data.</li>
</ul></li>
<li>Return the decision list.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="rules_files/figure-html/covering-algo-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Steps of the covering algorithm."><img src="rules_files/figure-html/covering-algo-1.png" class="img-fluid figure-img" width="672" alt="Steps of the covering algorithm."></a></p>
<figcaption>Steps of the covering algorithm.</figcaption>
</figure>
</div>
</div>
</div>
<p>For example: We have a task and dataset for predicting the values of houses from size, location, and whether pets are allowed. We learn the first rule, which turns out to be: If <code>size=big</code> and <code>location=good</code>, then <code>value=high</code>. Then we remove all big houses in good locations from the dataset. With the remaining data, we learn the next rule. Maybe: If <code>location=good</code>, then <code>value=ok</code>. Note that this rule is learned on data without big houses in good locations, leaving only medium and small houses in good locations.</p>
<p>For multi-class settings, the approach must be modified. First, the classes are ordered by increasing prevalence. The sequential covering algorithm starts with the least common class, learns a rule for it, removes all covered instances, then moves on to the second least common class, and so on. The current class is always treated as the positive class, and all classes with a higher prevalence are combined in the negative class. The last class is the default rule. This is also referred to as one-versus-all strategy in classification.</p>
<p>How do we learn a single rule? The OneR algorithm wouldn‚Äôt work here since it would always cover the whole feature space. But there are many other possibilities. One possibility is to learn a single rule from a decision tree with beam search:</p>
<ul>
<li>Learn a decision tree (with CART or another tree learning algorithm).</li>
<li>Start at the root node and recursively select the purest node (e.g., with the lowest misclassification rate).</li>
<li>The majority class of the terminal node is used as the rule prediction; the path leading to that node is used as the rule condition.</li>
</ul>
<p><a href="#fig-learn-one-rule" class="quarto-xref">Figure&nbsp;<span>10.1</span></a> illustrates the beam search in a tree:</p>
<div id="fig-learn-one-rule" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-learn-one-rule-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/learn-one-rule.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;10.1: Rule learned by searching a path through a decision tree. We end up with: If location=good and size=big, then value=high."><img src="./images/learn-one-rule.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-learn-one-rule-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10.1: Rule learned by searching a path through a decision tree. We end up with: If <code>location=good</code> and <code>size=big</code>, then <code>value=high</code>.
</figcaption>
</figure>
</div>
<p>Learning a single rule is a search problem, where the search space is the space of all possible rules. The goal of the search is to find the best rule according to some criteria. There are many different search strategies: hill-climbing, beam search, exhaustive search, best-first search, ordered search, stochastic search, top-down search, bottom-up search, ‚Ä¶</p>
<p>RIPPER (Repeated Incremental Pruning to Produce Error Reduction) <span class="citation" data-cites="cohen1995fast">(<a href="references.html#ref-cohen1995fast" role="doc-biblioref">Cohen 1995</a>)</span> is a variant of the Sequential Covering algorithm. RIPPER is a bit more sophisticated and uses a post-processing phase (rule pruning) to optimize the decision list (or set). RIPPER can run in ordered or unordered mode and generate either a decision list or decision set.</p>
<p><strong>Examples</strong></p>
<p>First, we extract the rules for the <a href="data.html#penguins">penguin sex classification task</a>. The rules plus the default rule are printed in <a href="#tbl-jrip-penguins" class="quarto-xref">Table&nbsp;<span>10.6</span></a>. The interpretation is simple: To predict a new instance, start at the top of the list and check whether a rule applies. If the conditions apply, predict the species on the right-hand side of the rule. If it doesn‚Äôt apply, go to the next rule until you have a classification. The default rule ensures that there is always a prediction.</p>
<div class="cell">
<div id="tbl-jrip-penguins" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-jrip-penguins-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.6: JRip rules learned for the penguin classification task.
</figcaption>
<div aria-describedby="tbl-jrip-penguins-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">rules</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; width: 35em;">(body_mass_g &lt;= 3700) and (bill_depth_mm &lt;= 18.5) =&gt; sex=F</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">(bill_depth_mm &lt;= 14.8) and (body_mass_g &lt;= 5200) =&gt; sex=F</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 35em;">(body_mass_g &lt;= 3850) and (bill_length_mm &lt;= 36.9) =&gt; sex=F</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">=&gt; sex=M</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<div class="callout-info">
<p>RIPPER has a specific way of resolving conflicts between rules: it applies them sequentially. This is just one of many general strategies, ranging from rules with the most-specific if-clause to using the rule with the highest precision.</p>
</div>
<p>When we use RIPPER on the regression task to predict <a href="data.html#bike-data">bike counts</a>, some rules are found. Since RIPPER only works for classification, the bike counts must be turned into a categorical outcome. I achieved this by cutting the bike counts into the quartiles. For example, the interval ([4548, 5956]) covers predicted bike counts between 4548 and 5956. <a href="#tbl-jrip-bike" class="quarto-xref">Table&nbsp;<span>10.7</span></a> shows the decision list of learned rules. Interpretation is again: If the conditions apply, we predict the interval on the right-hand side for the number of bikes. I don‚Äôt like the decision rules for this example. The nature of the <code>cnt_2d_bfr</code> feature is to adjust for a general trend of bike rentals. <code>cnt</code> and <code>cnt_2d_bfr</code> have a linear relationships which decision rules have a hard time to reflect.</p>
<div class="cell">
<div id="tbl-jrip-bike" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-jrip-bike-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.7: JRip rules for the bike task.
</figcaption>
<div aria-describedby="tbl-jrip-bike-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">rules</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 5729) and (cnt_2d_bfr &gt;= 4780) and (temp &lt;= 26) =&gt; cnt=(4551,5978.5]</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">(temp &gt;= 14) and (cnt_2d_bfr &lt;= 5515) and (hum &lt;= 63) and (cnt_2d_bfr &gt;= 3574) and (temp &lt;= 27) =&gt; cnt=(4551,5978.5]</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &gt;= 3544) and (cnt_2d_bfr &lt;= 3915) and (temp &gt;= 17) and (temp &lt;= 28) =&gt; cnt=(4551,5978.5]</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 5336) and (cnt_2d_bfr &gt;= 2914) and (weather = GOOD) and (temp &gt;= 7) =&gt; cnt=(3193,4551]</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 4833) and (cnt_2d_bfr &gt;= 2169) and (hum &lt;= 72) and (workday = Y) =&gt; cnt=(3193,4551]</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 4097) and (season = WINTER) =&gt; cnt=[22,3193]</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 4570) and (temp &lt;= 13) =&gt; cnt=[22,3193]</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">(hum &gt;= 88) and (season = FALL) =&gt; cnt=[22,3193]</td>
</tr>
<tr class="odd">
<td style="text-align: left; width: 35em;">(cnt_2d_bfr &lt;= 3351) and (cnt_2d_bfr &gt;= 2710) =&gt; cnt=[22,3193]</td>
</tr>
<tr class="even">
<td style="text-align: left; width: 35em;">=&gt; cnt=(5978.5,8714]</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
</section>
<section id="bayesian-rule-lists" class="level2">
<h2 class="anchored" data-anchor-id="bayesian-rule-lists">Bayesian Rule Lists</h2>
<p>In this section, I‚Äôll show you another approach to learning a decision list, which follows this rough recipe:</p>
<ol type="1">
<li>Pre-mine frequent patterns from the data that can be used as conditions for the decision rules.</li>
<li>Learn a decision list from a selection of the pre-mined rules.</li>
</ol>
<p>A specific approach using this recipe is called Bayesian Rule Lists <span class="citation" data-cites="letham2015interpretable">(<a href="references.html#ref-letham2015interpretable" role="doc-biblioref">Letham et al. 2015</a>)</span> or BRL for short. BRL uses Bayesian statistics to learn decision lists from frequent patterns which are pre-mined with the FP-tree algorithm <span class="citation" data-cites="borgelt2005implementation">(<a href="references.html#ref-borgelt2005implementation" role="doc-biblioref">Borgelt 2005</a>)</span>.</p>
<p>But let us start slowly with the first step of BRL.</p>
<p><strong>Pre-mining of frequent patterns</strong></p>
<p>A frequent pattern is the frequent (co-)occurrence of feature values. As a pre-processing step for the BRL algorithm, we use the features (we don‚Äôt need the target outcome in this step) and extract frequently occurring patterns from them. A pattern can be a single feature value such as <code>size=medium</code> or a combination of feature values such as <code>size=medium AND location=bad</code>.</p>
<p>The frequency of a pattern is measured with its support in the dataset:</p>
<p><span class="math display">\[Support(\mathbf{x}_j=A)=\frac{1}{n}\sum_{i=1}^nI(x^{(i)}_{j}=A)\]</span></p>
<p>where A is the feature value, n the number of data points in the dataset, and I the indicator function that returns 1 if the feature <span class="math inline">\(x_j\)</span> of the instance i has level A otherwise 0. In a dataset of house values, if 20% of houses have no balcony and 80% have one or more, then the support for the pattern <code>balcony=0</code> is 20%. Support can also be measured for combinations of feature values, for example, for <code>balcony=0 AND pets=allowed</code>.</p>
<p>There are many algorithms to find such frequent patterns, for example, Apriori or FP-Growth. Which you use doesn‚Äôt matter much; only the speed at which the patterns are found is different, but the resulting patterns are always the same.</p>
<p>I‚Äôll give you a rough idea of how the Apriori algorithm works to find frequent patterns. Actually, the Apriori algorithm consists of two parts, where the first part finds frequent patterns and the second part builds association rules from them. For the BRL algorithm, we are only interested in the frequent patterns that are generated in the first part of Apriori.</p>
<p>In the first step, the Apriori algorithm starts with all feature values that have a support greater than the minimum support defined by the user. If the user says that the minimum support should be 10% and only 5% of the houses have <code>size=big</code>, we would remove that feature value and keep only <code>size=medium</code> and <code>size=small</code> as patterns. This does not mean that the houses are removed from the data; it just means that <code>size=big</code> is not returned as a frequent pattern. Based on frequent patterns with a single feature value, the Apriori algorithm iteratively tries to find combinations of feature values of increasingly higher order. Patterns are constructed by combining <code>feature=value</code> statements with a logical AND, e.g., <code>size=medium AND location=bad</code>. Generated patterns with a support below the minimum support are removed. In the end, we have all the frequent patterns. Any subset of a frequent pattern‚Äôs clauses is frequent again, which is called the Apriori property. It makes sense intuitively: By removing a condition from a pattern, the reduced pattern can only cover more or the same number of data points, but not less. For example, if 20% of the houses are <code>size=medium AND location=good</code>, then the support of houses that are only <code>size=medium</code> is 20% or greater. The Apriori property is used to reduce the number of patterns to be inspected. Only in the case of frequent patterns do we have to check patterns of higher order.</p>
<p>Now we are done with pre-mining conditions for the Bayesian Rule List algorithm. But before we move on to the second step of BRL, I would like to hint at another way for rule-learning based on pre-mined patterns. Other approaches suggest including the outcome of interest in the frequent pattern mining process and also executing the second part of the Apriori algorithm that builds IF-THEN rules. Since the algorithm is unsupervised, the THEN-part also contains feature values we are not interested in. But we can filter by rules that have only the outcome of interest in the THEN-part. These rules already form a decision set, but it would also be possible to arrange, prune, delete or recombine the rules.</p>
<p>In the BRL approach however, we work with the frequent patterns and learn the THEN-part and how to arrange the patterns into a decision list using Bayesian statistics.</p>
<p><strong>Learning Bayesian Rule Lists</strong></p>
<p>The goal of the BRL algorithm is to learn an accurate decision list using a selection of the pre-mined conditions while prioritizing lists with few rules and short conditions. BRL addresses this goal by defining a distribution of decision lists with prior distributions for the length of conditions (preferably shorter rules) and the number of rules (preferably a shorter list).</p>
<p>The posterior probability distribution of lists makes it possible to say how likely a decision list is, given assumptions of shortness and how well the list fits the data. Our goal is to find the list that maximizes this posterior probability. Since it is not possible to find the exact best list directly from the distributions of lists, BRL suggests the following recipe: 1) Generate an initial decision list, which is randomly drawn from the prior distribution. 2) Iteratively modify the list by adding, switching, or removing rules, ensuring that the resulting lists follow the posterior distribution of lists. 3) Select the decision list from the sampled lists with the highest probability according to the posterior distribution.</p>
<p>Let‚Äôs go over the algorithm more closely: The algorithm starts with pre-mining feature value patterns with the FP-Growth algorithm. BRL makes a number of assumptions about the distribution of the target and the distribution of the parameters that define the distribution of the target. (That‚Äôs Bayesian statistics.) If you are unfamiliar with Bayesian statistics, do not get too caught up in the following explanations. It‚Äôs important to know that the Bayesian approach is a way to combine existing knowledge or requirements (so-called priori distributions) while also fitting to the data. In the case of decision lists, the Bayesian approach makes sense, since the prior assumptions nudge the decision lists to be short with short rules.</p>
<p>The goal is to sample decision lists d from the posterior distribution:</p>
<p><span class="math display">\[\underbrace{p(d|\mathbf{x},\mathbf{y},A,\alpha,\lambda,\eta)}_{posteriori}\propto\underbrace{p(\mathbf{y}|\mathbf{x},d,\alpha)}_{likelihood}\cdot\underbrace{p(d|A,\lambda,\eta)}_{priori}\]</span></p>
<p>where d is a decision list, x are the features, y is the target, A the set of pre-mined conditions, <span class="math inline">\(\lambda\)</span> the prior expected length of the decision lists, <span class="math inline">\(\eta\)</span> the prior expected number of conditions in a rule, <span class="math inline">\(\alpha\)</span> the prior pseudo-count for the positive and negative classes which is best fixed at (1,1).</p>
<p><span class="math display">\[p(d|\mathbf{x},\mathbf{y},A,\alpha,\lambda,\eta)\]</span></p>
<p>quantifies how probable a decision list is, given the observed data and the prior assumptions. This is proportional to the likelihood of the outcome <span class="math inline">\(Y\)</span> given the decision list and the data times the probability of the list given prior assumptions and the pre-mined conditions.</p>
<p><span class="math display">\[p(\mathbf{y}|\mathbf{x},d,\alpha)\]</span></p>
<p>is the likelihood of the observed <span class="math inline">\(y\)</span>, given the decision list and the data. BRL assumes that y is generated by a Dirichlet-Multinomial distribution. The better the decision list d explains the data, the higher the likelihood.</p>
<p><span class="math display">\[p(d|A,\lambda,\eta)\]</span></p>
<p>is the prior distribution of the decision lists. It multiplicatively combines a truncated Poisson distribution (parameter <span class="math inline">\(\lambda\)</span>) for the number of rules in the list and a truncated Poisson distribution (parameter <span class="math inline">\(\eta\)</span>) for the number of feature values in the conditions of the rules.</p>
<p>A decision list has a high posterior probability if it explains the outcome y well and is also likely according to the prior assumptions.</p>
<p>Estimations in Bayesian statistics are always a bit tricky because we usually cannot directly calculate the correct answer, but we have to draw candidates, evaluate them, and update our posterior estimates using the Markov chain Monte Carlo method. For decision lists, this is even trickier because we have to draw from the distribution of decision lists. The BRL authors propose to first draw an initial decision list and then iteratively modify it to generate samples of decision lists from the posterior distribution of the lists (a Markov chain of decision lists). The results are potentially dependent on the initial decision list, so it is advisable to repeat this procedure to ensure a great variety of lists. The default in the software implementation is 10 times. The following recipe tells us how to draw an initial decision list:</p>
<ul>
<li>Pre-mine patterns with FP-Growth.</li>
<li>Sample the list length parameter <span class="math inline">\(m\)</span> from a truncated Poisson distribution.</li>
<li>For the default rule: Sample the Dirichlet-Multinomial distribution parameter <span class="math inline">\(\theta_0\)</span> of the target value (i.e., the rule that applies when nothing else applies).</li>
<li>For decision list rule <span class="math inline">\(j=1,...,m\)</span>, do:
<ul>
<li>Sample the rule length parameter <span class="math inline">\(l\)</span> (number of conditions) for rule <span class="math inline">\(j\)</span>.</li>
<li>Sample a condition of length <span class="math inline">\(l_j\)</span> from the pre-mined conditions.</li>
<li>Sample the Dirichlet-Multinomial distribution parameter for the THEN-part (i.e., for the distribution of the target outcome given the rule).</li>
</ul></li>
<li>For each observation in the dataset:
<ul>
<li>Find the rule from the decision list that applies first (top to bottom).</li>
<li>Draw the predicted outcome from the probability distribution (Binomial) suggested by the rule that applies.</li>
</ul></li>
</ul>
<p>The next step is to generate many new lists starting from this initial sample to obtain many samples from the posterior distribution of decision lists.</p>
<p>The new decision lists are sampled by starting from the initial list and then randomly either moving a rule to a different position in the list or adding a rule to the current decision list from the pre-mined conditions or removing a rule from the decision list. Which of the rules is switched, added, or deleted is chosen at random. At each step, the algorithm evaluates the posterior probability of the decision list (mixture of accuracy and shortness). The Metropolis Hastings algorithm ensures that we sample decision lists that have a high posterior probability. This procedure provides us with many samples from the distribution of decision lists. The BRL algorithm selects the decision list of the samples with the highest posterior probability.</p>
<p><strong>Examples</strong></p>
<p>That‚Äôs it with the theory, now let‚Äôs see the BRL method in action. The examples use a faster variant of BRL called Scalable Bayesian Rule Lists (SBRL) <span class="citation" data-cites="yang2017scalable">(<a href="references.html#ref-yang2017scalable" role="doc-biblioref">Yang, Rudin, and Seltzer 2017</a>)</span>. We use the SBRL algorithm to predict the <a href="data.html#penguins">species of the penguins</a>. I had to discretize all input features for the SBRL algorithm to work. To do this, I binned the continuous features based on the frequency of the values by quantiles. We get the rules displayed in <a href="#tbl-sbrl-penguins-show" class="quarto-xref">Table&nbsp;<span>10.8</span></a>.</p>
<!-- Set eval = TRUE to recompute the rules -->
<div class="cell">
<div id="tbl-sbrl-penguins-show" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sbrl-penguins-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.8: Rules from SBRL model.
</figcaption>
<div aria-describedby="tbl-sbrl-penguins-show-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">rules</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">If {body_mass_g=[5.1e+03,6.3e+03]} then p = 0.083</td>
</tr>
<tr class="even">
<td style="text-align: left;">else if {species=Gentoo} then p = 0.873</td>
</tr>
<tr class="odd">
<td style="text-align: left;">else if {body_mass_g=[3.9e+03,5.1e+03)} then p = 0.066</td>
</tr>
<tr class="even">
<td style="text-align: left;">else if {bill_depth_mm=[15.9,18.7)} then p = 0.876</td>
</tr>
<tr class="odd">
<td style="text-align: left;">else (default rule) then p = 0.333</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>The conditions were selected from patterns that were pre-mined with the FP-Growth algorithm. The following table displays the pool of conditions the SBRL algorithm could choose from for building a decision list. The maximum number of feature values in a condition I allowed as a user was two. <a href="#tbl-sbrl-penguins-premined" class="quarto-xref">Table&nbsp;<span>10.9</span></a> shows a sample of ten patterns.</p>
<div class="cell">
<div id="tbl-sbrl-penguins-premined" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sbrl-penguins-premined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;10.9: Premined rules for the penguin classification task.
</figcaption>
<div aria-describedby="tbl-sbrl-penguins-premined-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">pre-mined conditions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">species=Gentoo, bill_depth_mm=[13.1, 15.9)</td>
</tr>
<tr class="even">
<td style="text-align: left;">body_mass_g=[2.7e+03, 3.9e+03)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">bill_depth_mm=[13.1, 15.9), bill_length_mm=[41.3, 50.4)</td>
</tr>
<tr class="even">
<td style="text-align: left;">bill_length_mm=[41.3, 50.4)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">flipper_length_mm=[172, 192), body_mass_g=[3.9e+03, 5.1e+03)</td>
</tr>
<tr class="even">
<td style="text-align: left;">bill_depth_mm=[15.9, 18.7), flipper_length_mm=[211, 231]</td>
</tr>
<tr class="odd">
<td style="text-align: left;">species=Adelie</td>
</tr>
<tr class="even">
<td style="text-align: left;">species=Adelie, bill_depth_mm=[15.9, 18.7)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">bill_depth_mm=[18.7, 21.5], flipper_length_mm=[172, 192)</td>
</tr>
<tr class="even">
<td style="text-align: left;">species=Adelie, bill_length_mm=[41.3, 50.4)</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sparsity is king
</div>
</div>
<div class="callout-body-container callout-body">
<p>Fewer and shorter rules make for better model interpretation. But there is a trade-off with complexity and therefore with predictive performance.</p>
</div>
</div>
</section>
<section id="strengths" class="level2">
<h2 class="anchored" data-anchor-id="strengths">Strengths</h2>
<p>This section discusses the benefits of IF-THEN rules in general.</p>
<p>IF-THEN rules are <strong>easy to interpret</strong>. They are probably the most interpretable of the interpretable models. This statement only applies if the number of rules is small, the conditions of the rules are short (maximum 3, I would say), and if the rules are organized in a decision list or a non-overlapping decision set.</p>
<p>Decision rules can be <strong>as expressive as decision trees, while being more compact</strong>. Decision trees often also suffer from replicated sub-trees, that is, when the splits in a left and a right child node have the same structure.</p>
<p>The <strong>prediction with IF-THEN rules is fast</strong> since only a few binary statements need to be checked to determine which rules apply.</p>
<p>Decision rules are <strong>robust</strong> against monotonic transformations of the input features because only the threshold in the conditions changes. They are also robust against outliers since it only matters if a condition applies or not.</p>
<p>IF-THEN rules usually generate sparse models, which means that not many features are included. They <strong>select only the relevant features</strong> for the model. For example, a linear model assigns a weight to every input feature by default. Features that are irrelevant can simply be ignored by IF-THEN rules.</p>
<p>Simple rules, like from OneR, <strong>can be used as a baseline</strong> for more complex algorithms.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>This section deals with the disadvantages of IF-THEN rules in general.</p>
<p>The research and literature for IF-THEN rules focuses on classification and almost <strong>completely neglects regression</strong>. While you can always divide a continuous target into intervals and turn it into a classification problem, you always lose information. In general, approaches are more attractive if they can be used for both regression and classification.</p>
<p>Often the <strong>features also have to be categorical</strong>. That means numeric features must be categorized if you want to use them. There are many ways to cut a continuous feature into intervals, but this is not trivial and comes with many questions without clear answers. How many intervals should the feature be divided into? What‚Äôs the splitting criterion: Fixed interval lengths, quantiles, or something else? Categorizing continuous features is a non-trivial issue that is often neglected, and people just use the next best method (like I did in the examples).</p>
<p>Many of the older rule-learning algorithms are <strong>prone to overfitting</strong>. The algorithms presented here all have at least some safeguards to prevent overfitting: OneR is limited because it can only use one feature (only problematic if the feature has too many levels or if there are many features, which equates to the multiple testing problem), RIPPER does pruning and Bayesian Rule Lists impose a prior distribution on the decision lists.</p>
<p>Decision rules are <strong>bad at describing linear relationships</strong> between features and output. That‚Äôs a problem they share with decision trees. Decision trees and rules can only produce step-like prediction functions, where changes in the prediction are always discrete steps and never smooth curves. This is related to the issue that the inputs have to be categorical. In decision trees, they are implicitly categorized by splitting them.</p>
</section>
<section id="software-and-alternatives" class="level2">
<h2 class="anchored" data-anchor-id="software-and-alternatives">Software and alternatives</h2>
<p>OneR is implemented in the <a href="https://cran.r-project.org/web/packages/OneR/">R package OneR</a>, which was used for the examples in this book. OneR is also implemented in the <a href="https://www.eecs.yorku.ca/tdb/_doc.php/userg/sw/weka/doc/weka/classifiers/rules/package-summary.html">Weka machine learning library</a> and, as such, is available in Java, R, and Python. RIPPER is also implemented in Weka. For the examples, I used the R implementation of JRIP in the <a href="https://cran.r-project.org/web/packages/RWeka/index.html">RWeka package</a>. SBRL is available as an <a href="https://cran.r-project.org/web/packages/sbrl/index.html">R package</a> (which I used for the examples), in <a href="https://github.com/datascienceinc/Skater">Python</a>, or as a <a href="https://github.com/Hongyuy/sbrlmod">C implementation</a>. Additionally, I recommend the <a href="https://github.com/csinva/imodels">imodels package</a>, which implements rule-based models such as Bayesian rule lists, CORELS, OneR, greedy rule lists, and more in a Python package with a unified scikit-learn interface.</p>
<p>I will not even try to list all alternatives for learning decision rule sets and lists, but will point to some summarizing work. I recommend the book ‚ÄúFoundations of Rule Learning‚Äù by <span class="citation" data-cites="furnkranz2012foundations">F√ºrnkranz, Gamberger, and Lavraƒç (<a href="references.html#ref-furnkranz2012foundations" role="doc-biblioref">2012</a>)</span>. It‚Äôs an extensive work on learning rules, for those who want to dive deeper into the topic. It provides a holistic framework for thinking about learning rules and presents many rule learning algorithms. I also recommend checking out the <a href="http://weka.sourceforge.net/doc.dev/weka/classifiers/rules/package-summary.html">Weka rule learners</a>, which implement RIPPER, M5Rules, OneR, PART, and many more. IF-THEN rules can be used in linear models as described in this book in the chapter about the <a href="rulefit.html">RuleFit algorithm</a>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-borgelt2005implementation" class="csl-entry" role="listitem">
Borgelt, Christian. 2005. <span>‚ÄúAn Implementation of the <span>FP</span>-Growth Algorithm.‚Äù</span> In <em>Proceedings of the 1st International Workshop on Open Source Data Mining: Frequent Pattern Mining Implementations</em>, 1‚Äì5. <span>OSDM</span> ‚Äô05. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/1133905.1133907">https://doi.org/10.1145/1133905.1133907</a>.
</div>
<div id="ref-cohen1995fast" class="csl-entry" role="listitem">
Cohen, William W. 1995. <span>‚ÄúFast <span>Effective</span> <span>Rule</span> <span>Induction</span>.‚Äù</span> In <em>Machine <span>Learning</span> <span>Proceedings</span> 1995</em>, edited by Armand Prieditis and Stuart Russell, 115‚Äì23. San Francisco (CA): Morgan Kaufmann. <a href="https://doi.org/10.1016/B978-1-55860-377-6.50023-2">https://doi.org/10.1016/B978-1-55860-377-6.50023-2</a>.
</div>
<div id="ref-furnkranz2012foundations" class="csl-entry" role="listitem">
F√ºrnkranz, Johannes, Dragan Gamberger, and Nada Lavraƒç. 2012. <em>Foundations of <span>Rule</span> <span>Learning</span></em>. Cognitive <span>Technologies</span>. Berlin, Heidelberg: Springer. <a href="https://doi.org/10.1007/978-3-540-75197-7">https://doi.org/10.1007/978-3-540-75197-7</a>.
</div>
<div id="ref-holte1993very" class="csl-entry" role="listitem">
Holte, Robert C. 1993. <span>‚ÄúVery <span>Simple</span> <span>Classification</span> <span>Rules</span> <span>Perform</span> <span>Well</span> on <span>Most</span> <span>Commonly</span> <span>Used</span> <span>Datasets</span>.‚Äù</span> <em>Machine Learning</em> 11 (1): 63‚Äì90. <a href="https://doi.org/10.1023/A:1022631118932">https://doi.org/10.1023/A:1022631118932</a>.
</div>
<div id="ref-letham2015interpretable" class="csl-entry" role="listitem">
Letham, Benjamin, Cynthia Rudin, Tyler H. McCormick, and David Madigan. 2015. <span>‚ÄúInterpretable Classifiers Using Rules and <span>Bayesian</span> Analysis: <span>Building</span> a Better Stroke Prediction Model.‚Äù</span> <em>The Annals of Applied Statistics</em> 9 (3): 1350‚Äì71. <a href="https://doi.org/10.1214/15-AOAS848">https://doi.org/10.1214/15-AOAS848</a>.
</div>
<div id="ref-yang2017scalable" class="csl-entry" role="listitem">
Yang, Hongyu, Cynthia Rudin, and Margo Seltzer. 2017. <span>‚ÄúScalable Bayesian Rule Lists.‚Äù</span> In <em>International Conference on Machine Learning</em>, 3921‚Äì30. PMLR.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./tree.html" class="pagination-link" aria-label="Decision Tree">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Tree</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./rulefit.html" class="pagination-link" aria-label="RuleFit">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">RuleFit</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="privacy-policy.html" target="_blank" style="font-size:11px;"> Privacy Policy </a> | <a href="https://christophmolnar.com/impressum" target="_blank" style="font-size:11px"> Impressum </a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/rules.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>