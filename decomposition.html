<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>22&nbsp; Functional Decomposition â€“ Interpretable Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./feature-importance.html" rel="next">
<link href="./interaction.html" rel="prev">
<link href="./images/favicon.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/cookie-consent/cookie-consent.js"></script>
<link href="site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5e169a3c071d6ad0320cbd7522dabfb3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-YMSX1DV6TJ"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-YMSX1DV6TJ', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<!-- Add this to your header.html -->
<style>
.book-purchase-links {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.5rem;
    background: linear-gradient(to bottom right, #ffffff, #f8f9fa);
    border-radius: 12px;
    margin: 1.5rem 0;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    border: double 1px transparent;
    background-image: linear-gradient(to bottom right, #ffffff, #f8f9fa),
                     linear-gradient(to bottom right, #3b82f6, #60a5fa);
    background-origin: border-box;
    background-clip: padding-box, border-box;
}

.purchase-header {
    text-align: center;
    margin-bottom: -1rem;
    margin-top: -1rem;
    color: #2b3442;
}

.purchase-header h3 {
    margin: 0 0 0.5rem 0;
    font-size: 1.5rem;
    font-weight: 700;
}

.purchase-header p {
    margin: 0;
    font-size: 0.9rem;
    color: #6c757d;
}

.book-cover {
    width: 80%;
    height: auto;
    border-radius: 8px;
    margin: 0 auto 1rem auto;
    transition: transform 0.3s ease;
}

.book-cover:hover {
    transform: scale(1.1);
}

.purchase-link {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    text-decoration: none;
    color: #2b3442;
    border-radius: 8px;
    transition: all 0.2s ease;
    background: white;
    border: 1px solid #e9ecef;
    font-weight: 500;
}

.purchase-link:hover {
    background-color: #f8f9fa;
    transform: translateY(-2px);
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    text-decoration: none;
}

.purchase-link.primary {
    background-color: #0066cc;
    color: white;
    border: none;
}

.purchase-link.primary:hover {
    background-color: #0052a3;
}

.purchase-link svg {
    width: 20px;
    height: 20px;
    flex-shrink: 0;
}

.price-tag {
    margin-left: auto;
    font-weight: 600;
    color: inherit;
}

.social-proof {
    text-align: center;
    font-size: 0.85rem;
    color: #6c757d;
    margin-top: 0.5rem;
}

.limited-offer {
    background: #fff3cd;
    color: #856404;
    padding: 0.5rem;
    border-radius: 6px;
    font-size: 0.85rem;
    text-align: center;
    margin-bottom: 1rem;
}

@media (max-width: 768px) {
    .book-purchase-links {
        padding: 1rem;
    }
    
    .book-cover {
        width: 60%;
    }
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const purchaseLinksContainer = document.getElementById('book-purchase-links');
    if (!purchaseLinksContainer) return;

    const purchaseOptions = [
        {
            type: 'Paperback',
            primary: true,
            url: 'https://bookgoodies.com/a/3911578032',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>'
        },
        {
            type: 'E-Book & PDF',
            url: 'https://leanpub.com/interpretable-machine-learning',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path><path d="M12 6v8"></path><path d="M8 10h8"></path></svg>'
        }
    ];

    // Create header section
    const header = document.createElement('div');
    header.className = 'purchase-header';
    header.innerHTML = `
        <h3>Buy Book</h3>
    `;
    purchaseLinksContainer.appendChild(header);

    // Create limited time offer banner
    // const limitedOffer = document.createElement('div');
    // limitedOffer.className = 'limited-offer';
    // limitedOffer.textContent = 'ðŸŽ‰ Special Launch Price - Limited Time Only!';
    // purchaseLinksContainer.appendChild(limitedOffer);

    // Create and append book cover
    const bookCover = document.createElement('img');
    //bookCover.src = 'images/mockup-floating.png';
    bookCover.src = './images/cover-sidepanel.jpg';
    bookCover.alt = 'Book Cover';
    bookCover.className = 'book-cover';
    purchaseLinksContainer.appendChild(bookCover);

    // Create and append purchase links
    purchaseOptions.forEach(option => {
        const link = document.createElement('a');
        link.href = option.url;
        link.className = `purchase-link ${option.primary ? 'primary' : ''}`;
        link.innerHTML = `
            ${option.icon}
            ${option.type}
        `;
        purchaseLinksContainer.appendChild(link);
    });

    // Add social proof
    // const socialProof = document.createElement('div');
    // socialProof.className = 'social-proof';
    // socialProof.textContent = 'ðŸ‘¥ Join thousands of satisfied readers!';
    // purchaseLinksContainer.appendChild(socialProof);
});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./pdp.html">Global Model-Agnostic Methods</a></li><li class="breadcrumb-item"><a href="./decomposition.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Interpretable Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/christophM/interpretable-ml-book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./goals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Goals of Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Methods Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data and Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Interpretable Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./limo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./extend-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">GLM, GAM and more</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Tree</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rulefit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">RuleFit</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Local Modal-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ceteris-paribus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ceteris Paribus Plots</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Individual Conditional Expectation (ICE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LIME</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./counterfactual.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anchors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Scoped Rules (Anchors)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shapley.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Shapley Values</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">SHAP</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Global Model-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pdp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Partial Dependence Plot (PDP)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Accumulated Local Effects (ALE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interaction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Feature Interaction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decomposition.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Permutation Feature Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lofo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Leave One Feature Out (LOFO) Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./global.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Surrogate Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Prototypes and Criticisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Neural Network Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cnn-features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Learned Features</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pixel-attribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Saliency Maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./detecting-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Detecting Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adversarial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Adversarial Examples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./influential.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Influential Instances</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Beyond the Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Evaluation of Interpretability Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./storytime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Story Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">The Future of Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./translations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Translations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cite.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Citing this Book</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Acknowledgments</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what-is-machine-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Machine Learning Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./math-terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Math Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">R packages used</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#decomposing-a-function" id="toc-decomposing-a-function" class="nav-link active" data-scroll-target="#decomposing-a-function">Decomposing a function</a></li>
  <li><a href="#functional-anova" id="toc-functional-anova" class="nav-link" data-scroll-target="#functional-anova">Functional ANOVA</a></li>
  <li><a href="#generalized-functional-anova-for-dependent-features" id="toc-generalized-functional-anova-for-dependent-features" class="nav-link" data-scroll-target="#generalized-functional-anova-for-dependent-features">Generalized Functional ANOVA for dependent features</a></li>
  <li><a href="#accumulated-local-effects" id="toc-accumulated-local-effects" class="nav-link" data-scroll-target="#accumulated-local-effects">Accumulated Local Effects</a></li>
  <li><a href="#decomposing-tree-ensembles" id="toc-decomposing-tree-ensembles" class="nav-link" data-scroll-target="#decomposing-tree-ensembles">Decomposing tree ensembles</a></li>
  <li><a href="#statistical-regression-models" id="toc-statistical-regression-models" class="nav-link" data-scroll-target="#statistical-regression-models">Statistical regression models</a></li>
  <li><a href="#strengths" id="toc-strengths" class="nav-link" data-scroll-target="#strengths">Strengths</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/decomposition.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<div id="book-purchase-links" class="book-purchase-links">

</div>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./pdp.html">Global Model-Agnostic Methods</a></li><li class="breadcrumb-item"><a href="./decomposition.html"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="decomposition" class="quarto-section-identifier"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>A supervised machine learning model can be viewed as a function that takes a high-dimensional feature vector as input and produces a prediction or classification score as output. Functional decomposition is an interpretation technique that deconstructs the high-dimensional function and expresses it as a sum of individual feature effects and interaction effects that can be visualized. In addition, functional decomposition is a fundamental principle underlying many interpretation techniques â€“ it helps you better understand other interpretation methods.</p>
<!-- Intuition -->
<p>Letâ€™s jump right in and look at a particular function. This function takes two features as input and produces a one-dimensional output:</p>
<p><span class="math display">\[\hat{f}(x_1, x_2) = 2 + e^{x_1} - x_2 + x_1 \cdot x_2\]</span></p>
<p>Think of the function as a machine learning model. We can visualize the function with a 3D plot or a heatmap with contour lines as in <a href="#fig-decomp-example" class="quarto-xref">Figure&nbsp;<span>22.1</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-decomp-example" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decomp-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="decomposition_files/figure-html/fig-decomp-example-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;22.1: Prediction surface of a function with two features X_1 and X_2. The lighter the color, the larger the prediction."><img src="decomposition_files/figure-html/fig-decomp-example-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decomp-example-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.1: Prediction surface of a function with two features <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. The lighter the color, the larger the prediction.
</figcaption>
</figure>
</div>
</div>
</div>
<!-- Describing the prediction function -->
<p>The function takes large values when <span class="math inline">\(x_1\)</span> is large and <span class="math inline">\(x_2\)</span> is small, and it takes small values for large <span class="math inline">\(x_2\)</span> and small <span class="math inline">\(x_1\)</span>. The prediction function is not simply an additive effect between the two features, but an interaction between the two. The presence of an interaction can be seen in the figure â€“ the effect of changing values for feature <span class="math inline">\(x_1\)</span> depends on the value that feature <span class="math inline">\(x_2\)</span> has.</p>
<!-- Referring back to functional decomposition for machine learning -->
<p>Our job now is to decompose this function into main effects of features <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> and an interaction term. For a two-dimensional function <span class="math inline">\(\hat{f}\)</span> that depends on only two input features: <span class="math inline">\(\hat{f}(x_1, x_2)\)</span>, we want each component to represent a main effect (<span class="math inline">\(\hat{f}_1\)</span> and <span class="math inline">\(\hat{f}_2\)</span>), interaction (<span class="math inline">\(\hat{f}_{1,2}\)</span>), or intercept (<span class="math inline">\(\hat{f}_0\)</span>):</p>
<p><span class="math display">\[\hat{f}(x_1, x_2) = \hat{f}_0 + \hat{f}_1(x_1) + \hat{f}_2(x_2) + \hat{f}_{1,2}(x_{1},x_{2})\]</span></p>
<p>The main effects indicate how each feature affects the prediction, independent of the values the other feature. The interaction effect indicates the joint effect of the features. The intercept is a fixed value that is part of all predictions. If all feature values were set to zero, the prediction would only consist of the intercept. Note that the components themselves are functions (except for the intercept) with different input dimensionality.</p>
<p>Iâ€™ll just give you the components now and explain where they come from later. The intercept is given as <span class="math inline">\(\hat{f}_0 \approx 3.18\)</span>. Since the other components are functions, we can visualize them in <a href="#fig-decomp-example-continued" class="quarto-xref">Figure&nbsp;<span>22.2</span></a>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-decomp-example-continued" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-decomp-example-continued-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="decomposition_files/figure-html/fig-decomp-example-continued-1.png" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;22.2: Decomposition of a 2-dimensional function into main effects and interaction. Top row: Main effects f_1 (left) and f_2. Bottom: Interaction f_{12} between X_1 and X_2"><img src="decomposition_files/figure-html/fig-decomp-example-continued-1.png" class="img-fluid figure-img" width="672"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-decomp-example-continued-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;22.2: Decomposition of a 2-dimensional function into main effects and interaction. Top row: Main effects <span class="math inline">\(f_1\)</span> (left) and <span class="math inline">\(f_2\)</span>. Bottom: Interaction <span class="math inline">\(f_{12}\)</span> between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>
</figcaption>
</figure>
</div>
</div>
</div>
<p>Do you think the components make sense given the above true formula, ignoring that the intercept value seems a bit random? The <span class="math inline">\(X_1\)</span> feature shows an exponential main effect, and <span class="math inline">\(X_2\)</span> shows a negative linear effect. The interaction term looks a bit like a Pringles chip. In less crunchy and more mathematical terms, itâ€™s a hyperbolic paraboloid, as we would expect for <span class="math inline">\(x_1 \cdot x_2\)</span>. Spoiler alert: the decomposition is based on accumulated local effect plots, which we will discuss later in the chapter.</p>
<!-- The naive approach -->
<p>But why all the excitement? A glance at the formula already gives us the answer to the decomposition, so no need for fancy methods, right? For feature <span class="math inline">\(X_1\)</span>, we can take all the summands that contain only <span class="math inline">\(x_1\)</span> as the component for that feature. That would be <span class="math inline">\(\hat{f}_1(x_1) = e^{x_1}\)</span> and <span class="math inline">\(\hat{f}_2(x_2) = -x_2\)</span> for feature <span class="math inline">\(X_2\)</span>. The interaction is then <span class="math inline">\(\hat{f}_{12}(x_{1},x_{2}) = x_1 \cdot x_2\)</span>. While this is the correct answer for this example (up to constants), there are two problems with this approach: Problem 1): While the example started with the formula, the reality is that only structurally simple machine learning models can be described with such a neat formula. Problem 2) is much more intricate and concerns what an interaction is. Imagine a simple function <span class="math inline">\(\hat{f}(x_1,x_2) = x_1 \cdot x_2\)</span>, where both features take values larger than zero and are independent of each other. Using our look-at-the-formula tactic, we would conclude that there is an interaction between features <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, but not individual feature effects. But can we really say that feature <span class="math inline">\(x_1\)</span> has no individual effect on the prediction function? Regardless of what value <span class="math inline">\(x_2\)</span> takes on, the prediction increases as we increase <span class="math inline">\(x_1\)</span>. For example, for <span class="math inline">\(x_2 = 1\)</span>, the effect of <span class="math inline">\(x_1\)</span> is <span class="math inline">\(\hat{f}(x_1, 1) = x_1\)</span>, and when <span class="math inline">\(x_2 = 10\)</span> the effect is <span class="math inline">\(\hat{f}(x_1, 10) = 10 \cdot x_1\)</span>. Thus, itâ€™s clear that feature <span class="math inline">\(X_1\)</span> has a positive effect on the prediction, independent of <span class="math inline">\(X_2\)</span>, and is not zero.</p>
<p>To solve problem 1) of lack of access to a neat formula, we need a method that uses only the prediction function or classification score. To solve problem 2) of lack of definition, we need some axioms that tell us what the components should look like and how they relate to each other. But first, we should define more precisely what functional decomposition is.</p>
<section id="decomposing-a-function" class="level2">
<h2 class="anchored" data-anchor-id="decomposing-a-function">Decomposing a function</h2>
<!-- Explaining the formula -->
<p>A prediction function takes <span class="math inline">\(p\)</span> features as input, <span class="math inline">\(\hat{f}: \mathbb{R}^p \mapsto \mathbb{R}\)</span>, and produces an output. This can be a regression function, but it can also be the classification probability for a given class or the score for a given cluster (unsupervised machine learning). Fully decomposed, we can represent the prediction function as the sum of functional components:</p>
<p><span class="math display">\[\begin{align*}
\hat{f}(\mathbf{x}) = &amp; \hat{f}_0 + \hat{f}_1(x_1) + \ldots + \hat{f}_p(x_p) \\
&amp; + \hat{f}_{1,2}(x_1, x_2) + \ldots + \hat{f}_{1,p}(x_1, x_p) + \ldots + \hat{f}_{p-1,p}(x_{p-1}, x_p) \\
&amp; + \ldots  \\ &amp; +  \hat{f}_{1,\ldots,p}(x_1, \ldots, x_p)
\end{align*}\]</span></p>
<p>We can make the decomposition formula a bit nicer by indexing all possible subsets of feature combinations: <span class="math inline">\(S\subseteq\{1,\ldots,p\}\)</span>. This set contains the intercept (<span class="math inline">\(S=\emptyset\)</span>), main effects (<span class="math inline">\(|S|=1\)</span>), and all interactions (<span class="math inline">\(|S|\geq{}1\)</span>). With this subset defined, we can write the decomposition as follows:</p>
<p><span class="math display">\[\hat{f}(\mathbf{x}) = \sum_{S\subseteq\{1,\ldots,p\}} \hat{f}_S(\mathbf{x}_S)\]</span></p>
<p>In the formula, <span class="math inline">\(\mathbf{x}_S\)</span> is the vector of features in the index set <span class="math inline">\(S\)</span>. And each subset <span class="math inline">\(S\)</span> represents a functional component, for example, a main effect if <span class="math inline">\(S\)</span> contains only one feature, or an interaction if <span class="math inline">\(|S| &gt; 1\)</span>.</p>
<!-- Dimensionality -->
<p>How many components are in the above formula? The answer boils down to how many possible subsets <span class="math inline">\(S\)</span> of the features <span class="math inline">\(1,\ldots, p\)</span> we can form. And these are <span class="math inline">\(\sum_{i=0}^p\binom{p}{i}=2^p\)</span> possible subsets! For example, if a function uses 10 features, we can decompose the function into 1,024 components: 1 intercept, 10 main effects, 90 2-way interaction terms, 720 3-way interaction terms, â€¦ And with each additional feature, the number of components doubles. Clearly, for most functions, it is not feasible to compute all components. Another reason NOT to compute all components is that components with <span class="math inline">\(|S|&gt;2\)</span> are difficult to visualize and interpret.</p>
<p>So far Iâ€™ve avoided talking about how the components are defined and computed. The only constraints we have implicitly talked about were the number and dimensionality of the components, and that the sum of components should yield the original function. But without further constraints on what the components should be, they are not unique. This means we could shift effects between main effects and interactions, or lower-order interactions (few features) and higher-order interactions (more features). In the example at the beginning of the chapter, we could set both main effects to zero and add their effects to the interaction effect.</p>
<p>Hereâ€™s an even more extreme example that illustrates the need for constraints on components. Suppose you have a 3-dimensional function. It does not really matter what this function looks like, but the following decomposition would <strong>always</strong> work: <span class="math inline">\(\hat{f}_0\)</span> is 0.12. <span class="math inline">\(\hat{f}_1(\mathbf{x})=2\cdot{}x_1 + \text{number of shoes you own}\)</span>. <span class="math inline">\(\hat{f}_2\)</span>, <span class="math inline">\(\hat{f}_3\)</span>, <span class="math inline">\(\hat{f}_{1,2}\)</span>, <span class="math inline">\(\hat{f}_{2,3}\)</span>, <span class="math inline">\(\hat{f}_{1,3}\)</span> are all zero. And to make this trick work, I define <span class="math inline">\(\hat{f}_{1,2,3}(x_1,x_2,x_3)=\hat{f}(\mathbf{x})-\sum\limits_{S\subset\{1,\ldots,p\}}\hat{f}_S(\mathbf{x}_S)\)</span>. So the interaction term containing all features simply sucks up all the remaining effects, which by definition always works, in the sense that the sum of all components gives us the original prediction function. This decomposition would not be very meaningful and quite misleading if you were to present this as the interpretation of your model.</p>
<!-- Solutions -->
<p>The ambiguity can be avoided by specifying further constraints or specific methods for computing the components. In this chapter, we will discuss different approaches to functional decomposition:</p>
<ul>
<li>(Generalized) functional ANOVA</li>
<li>Accumulated Local Effects</li>
<li>Statistical regression models</li>
<li>Decomposing tree ensembles</li>
</ul>
</section>
<section id="functional-anova" class="level2">
<h2 class="anchored" data-anchor-id="functional-anova">Functional ANOVA</h2>
<p>Functional ANOVA was proposed by <span class="citation" data-cites="hooker2004discovering">Hooker (<a href="references.html#ref-hooker2004discovering" role="doc-biblioref">2004</a>)</span>. A requirement for this approach is that the model prediction function <span class="math inline">\(\hat{f}\)</span> is square integrable. As with any functional decomposition, the functional ANOVA decomposes the function into components:</p>
<p><span class="math display">\[\hat{f}(\mathbf{x}) = \sum_{S \subseteq \{1, \ldots, p\}} \hat{f}_S(\mathbf{x}_S)\]</span></p>
<p><span class="citation" data-cites="hooker2004discovering">Hooker (<a href="references.html#ref-hooker2004discovering" role="doc-biblioref">2004</a>)</span> defines each component with the following formula:</p>
<p><span class="math display">\[\hat{f}_S(\mathbf{x}) = \int_{X_{-S}} \left( \hat{f}(\mathbf{x}) - \sum_{V \subset S} \hat{f}_V(\mathbf{x})\right) d \mathbb{P}(X_{-S})\]</span></p>
<p>Okay, letâ€™s take this thing apart. We can rewrite the component as:</p>
<p><span class="math display">\[\hat{f}_S(\mathbf{x}) = \int_{X_{-S}} \left( \hat{f}(\mathbf{x})\right) d \mathbb{P}(X_{-S}) - \int_{X_{-S}} \left(\sum_{V \subset S} \hat{f}_V(\mathbf{x}) \right) d \mathbb{P}(X_{-S})\]</span></p>
<p>On the left side is the integral over the prediction function with respect to the features excluded from the set <span class="math inline">\(S\)</span>, denoted with <span class="math inline">\(-S\)</span>. For example, if we compute the 2-way interaction component for features 2 and 3, we would integrate over features 1, 4, 5, â€¦ The integral can also be viewed as the expected value of the prediction function with respect to <span class="math inline">\(X_{-S}\)</span>, assuming that all features follow a uniform distribution from their minimum to their maximum. From this interval, we subtract all components with subsets of <span class="math inline">\(S\)</span>. This subtraction removes the effect of all lower-order effects and centers the effect. For <span class="math inline">\(S=\{1,2\}\)</span>, we subtract the main effects of both features <span class="math inline">\(\hat{f}_1\)</span> and <span class="math inline">\(\hat{f}_2\)</span>, as well as the intercept <span class="math inline">\(\hat{f}_0\)</span>. The occurrence of these lower-order effects makes the formula recursive: We have to go through the hierarchy of subsets to the intercept and compute all these components. For the intercept component <span class="math inline">\(\hat{f}_0\)</span>, the subset is the empty set <span class="math inline">\(S=\{\emptyset\}\)</span> and therefore <span class="math inline">\(-S\)</span> contains all features:</p>
<p><span class="math display">\[\hat{f}_0(\mathbf{x}) = \int_{X} \hat{f}(\mathbf{x}) d \mathbb{P}(X)\]</span></p>
<p>This is simply the prediction function integrated over all features. The intercept can also be interpreted as the expectation of the prediction function when we assume that all features are uniformly distributed. Now that we know <span class="math inline">\(\hat{f}_0\)</span>, we can compute <span class="math inline">\(\hat{f}_1\)</span> (and equivalently <span class="math inline">\(\hat{f}_2\)</span>):</p>
<p><span class="math display">\[\hat{f}_1(\mathbf{x}) = \int_{X_{-1}} \left( \hat{f}(\mathbf{x}) - \hat{f}_0\right) d \mathbb{P}(X_{-1})\]</span></p>
<p>To finish the calculation for the component <span class="math inline">\(\hat{f}_{1,2}\)</span>, we can put everything together:</p>
<p><span class="math display">\[\begin{align*}
\hat{f}_{1,2}(\mathbf{x}) &amp;= \int_{X_{3,4}} \left( \hat{f}(\mathbf{x}) - (\hat{f}_0 + \hat{f}_1(\mathbf{x}) - \hat{f}_0 + \hat{f}_2(\mathbf{x}) - \hat{f}_0)\right) d \mathbb{P}(X_{3},X_4) \\
&amp;= \int_{X_{3,4}} \left(\hat{f}(\mathbf{x}) - \hat{f}_1(\mathbf{x}) - \hat{f}_2(\mathbf{x}) + \hat{f}_0\right) d \mathbb{P}(X_{3},X_4)
\end{align*}\]</span></p>
<p>This example shows how each higher-order effect is defined by integrating over all other features, but also by removing all the lower-order effects that are subsets of the feature set we are interested in.</p>
<p><span class="citation" data-cites="hooker2004discovering">Hooker (<a href="references.html#ref-hooker2004discovering" role="doc-biblioref">2004</a>)</span> has shown that this definition of functional components satisfies these desirable axioms:</p>
<ul>
<li>Zero Means: <span class="math inline">\(\int \hat{f}_S(\mathbf{x}_S)d \mathbb{P}(X_S)=0\)</span> for each <span class="math inline">\(S\neq\emptyset\)</span>.</li>
<li>Orthogonality: <span class="math inline">\(\int \hat{f}_S(\mathbf{x}_S)\hat{f}_V(\mathbf{x}_V)d \mathbb{P}(X)=0\)</span> for <span class="math inline">\(S\neq V\)</span>.</li>
<li>Variance Decomposition: Let <span class="math inline">\(\sigma^2_{\hat{f}}=\int \hat{f}(\mathbf{x})^2d \mathbb{P}(X)\)</span>, then <span class="math inline">\(\sigma^2(\hat{f}) = \sum_{S \subseteq P} \sigma^2_S(\hat{f}_S)\)</span>, where <span class="math inline">\(P=\{1,\ldots,p\}\)</span>.</li>
</ul>
<p>The zero means axiom implies that all effects or interactions are centered around zero. As a consequence, the interpretation at a position <span class="math inline">\(\mathbf{x}\)</span> is relative to the centered prediction and not the absolute prediction.</p>
<p>The orthogonality axiom implies that components do not share information. For example, the first-order effect of feature <span class="math inline">\(X_1\)</span> and the interaction term of <span class="math inline">\(X_{1}\)</span> and <span class="math inline">\(X_2\)</span> are not correlated. Because of orthogonality, all components are â€œpureâ€ in the sense that they do not mix effects. It makes a lot of sense that the component for, say, feature <span class="math inline">\(X_4\)</span> should be independent of the interaction term between features <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. The more interesting consequence arises for orthogonality of hierarchical components, where one component contains features of another, for example, the interaction between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, and the main effect of feature <span class="math inline">\(X_1\)</span>. In contrast, a two-dimensional partial dependence plot for <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> would contain four effects: the intercept, the two main effects of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, and the interaction between them. The functional ANOVA component for <span class="math inline">\(\hat{f}_{1,2}(x_1,x_2)\)</span> contains only the pure interaction.</p>
<p>Variance decomposition allows us to divide the variance of the function <span class="math inline">\(\hat{f}\)</span> among the components and guarantees that it adds up to the total variance of the function in the end. The variance decomposition property can also explain to us why the method is called functional ANOVA. In statistics, ANOVA stands for ANalysis Of VAriance. ANOVA refers to a collection of methods that analyze differences in the mean of a target variable. ANOVA works by dividing the variance and attributing it to the variables. Functional ANOVA can therefore be seen as an extension of this concept to any function.</p>
<p>Problems arise with the functional ANOVA when features are correlated. As a solution, <span class="citation" data-cites="hooker2007generalized">Hooker (<a href="references.html#ref-hooker2007generalized" role="doc-biblioref">2007</a>)</span> proposed the generalized functional ANOVA.</p>
</section>
<section id="generalized-functional-anova-for-dependent-features" class="level2">
<h2 class="anchored" data-anchor-id="generalized-functional-anova-for-dependent-features">Generalized Functional ANOVA for dependent features</h2>
<!-- The extrapolation problem -->
<p>Similar to most interpretation techniques based on sampling data (such as the PDP), the functional ANOVA can produce misleading results when features are correlated. If we integrate over the uniform distribution, when in reality features are dependent, we create a new dataset that deviates from the joint distribution and extrapolates to unlikely combinations of feature values.</p>
<!-- The solution -->
<p><span class="citation" data-cites="hooker2007generalized">Hooker (<a href="references.html#ref-hooker2007generalized" role="doc-biblioref">2007</a>)</span> proposed the generalized functional ANOVA, a decomposition that works for dependent features. Itâ€™s a generalization of the functional ANOVA we encountered earlier, which means that the functional ANOVA is a special case of the generalized functional ANOVA. The components are defined as projections of <span class="math inline">\(\hat{f}\)</span> onto the space of additive functions:</p>
<p><span class="math display">\[\hat{f}_S(\mathbf{x}_S) = \arg\min_{g_S \in L^2(\mathbb{R}^S)_{S \in P}} \int \left(\hat{f}(\mathbf{x}) - \sum_{S \subset P} g_S(\mathbf{x}_S)\right)^2 w(\mathbf{x})\,d\mathbf{x}.\]</span></p>
<p>Instead of orthogonality, the components satisfy a hierarchical orthogonality condition:</p>
<p><span class="math display">\[\forall \hat{f}_S(\mathbf{x}_S)| S \subset U: \int \hat{f}_S(\mathbf{x}_S) \hat{f}_U(\mathbf{x}_U) w(\mathbf{x})\,d\mathbf{x} = 0\]</span></p>
<!-- hierarchical orthogonality -->
<p>Hierarchical orthogonality is different from orthogonality. For two feature sets <span class="math inline">\(S\)</span> and <span class="math inline">\(U\)</span>, neither of which is a subset of the other (e.g., <span class="math inline">\(S=\{1,2\}\)</span> and <span class="math inline">\(U=\{2,3\}\)</span>), the components <span class="math inline">\(\hat{f}_S\)</span> and <span class="math inline">\(\hat{f}_U\)</span> need not be orthogonal for the decomposition to be hierarchically orthogonal. But all components for all subsets of <span class="math inline">\(S\)</span> must be orthogonal to <span class="math inline">\(\hat{f}_S\)</span>. <!-- Entanglement --> As a result, the interpretation differs in relevant ways: Similar to the M-Plot in the <a href="ale.html">ALE chapter</a>, generalized functional ANOVA components can entangle the (marginal) effects of correlated features. Whether the components entangle the marginal effects also depends on the choice of weight function <span class="math inline">\(w(\mathbf{x})\)</span>. If we choose <span class="math inline">\(w\)</span> to be the uniform measure on the unit cube, we obtain the functional ANOVA from the section above. A natural choice for <span class="math inline">\(w\)</span> is the joint probability distribution function. However, the joint distribution is usually unknown and difficult to estimate. A trick can be to start with the uniform measure on the unit cube and cut out areas without data.</p>
<p>The estimation is done on a grid of points in the feature space and is stated as a minimization problem that can be solved using regression techniques. However, the components cannot be computed independently of each other, nor hierarchically, but a complex system of equations involving other components has to be solved. The computation is therefore quite complex and computationally intensive.</p>
</section>
<section id="accumulated-local-effects" class="level2">
<h2 class="anchored" data-anchor-id="accumulated-local-effects">Accumulated Local Effects</h2>
<p>ALE plots <span class="citation" data-cites="apley2020visualizingeffects">(<a href="references.html#ref-apley2020visualizingeffects" role="doc-biblioref">Apley and Zhu 2020</a>)</span> also provide a functional decomposition, meaning that adding all ALE plots from intercept, 1D ALE plots, 2D ALE plots, and so on yields the prediction function. ALE differs from the (generalized) functional ANOVA, as the components are not orthogonal but, as the authors call it, pseudo-orthogonal. To understand pseudo-orthogonality, we have to define the operator <span class="math inline">\(H_S\)</span>, which takes a function <span class="math inline">\(\hat{f}\)</span> and maps it to its ALE plot for feature subset <span class="math inline">\(S\)</span>. For example, the operator <span class="math inline">\(H_{1,2}\)</span> takes as input a machine learning model and produces the 2D ALE plot for features 1 and 2: <span class="math inline">\(H_{1,2}(\hat{f}) = \hat{f}_{ALE,12}\)</span>. If we apply the same operator twice, we get the same ALE plot. After applying the operator <span class="math inline">\(H_{1,2}\)</span> to <span class="math inline">\(\hat{f}\)</span> once, we get the 2D ALE plot <span class="math inline">\(\hat{f}_{ALE,12}\)</span>. Then we apply the operator again, not to <span class="math inline">\(\hat{f}\)</span> but to <span class="math inline">\(\hat{f}_{ALE,12}\)</span>. This is possible because the 2D ALE component is itself a function. The result is again <span class="math inline">\(\hat{f}_{ALE,12}\)</span>, meaning we can apply the same operator several times and always get the same ALE plot. This is the first part of pseudo-orthogonality. But what is the result if we apply two different operators for different feature sets? For example, <span class="math inline">\(H_{1,2}\)</span> and <span class="math inline">\(H_{1}\)</span>, or <span class="math inline">\(H_{1,2}\)</span> and <span class="math inline">\(H_{3,4,5}\)</span>? The answer is zero. If we first apply the ALE operator <span class="math inline">\(H_S\)</span> to a function and then apply <span class="math inline">\(H_U\)</span> to the result (with <span class="math inline">\(S \neq U\)</span>), then the result is zero. In other words, the ALE plot of an ALE plot is zero, unless you apply the same ALE plot twice. Or in other words, the ALE plot for the feature set <span class="math inline">\(S\)</span> does not contain any other ALE plots in it. Or in mathematical terms, the ALE operator maps functions to orthogonal subspaces of an inner product space.</p>
<p>As Apley and Zhu (2020) note, pseudo-orthogonality may be more desirable than hierarchical orthogonality because it does not entangle marginal effects of the features. Furthermore, ALE does not require estimation of the joint distribution; the components can be estimated in a hierarchical manner, which means that calculating the 2D ALE for features 1 and 2 requires only the calculations of individual ALE components of 1 and 2, and the intercept term in addition.</p>
<p>Does the <a href="pdp.html">Partial Dependence Plot</a> also provide a functional decomposition? Short answer: No. Longer answer: The partial dependence plot for a feature set <span class="math inline">\(S\)</span> always contains all effects of the hierarchy â€“ the PDP for <span class="math inline">\(\{1,2\}\)</span> contains not only the interaction, but also the individual feature effects. As a consequence, adding all PDPs for all subsets does not yield the original function, and thus is not a valid decomposition. But could we adjust the PDP, perhaps by removing all lower effects? Yes, we could, but we would get something similar to the functional ANOVA. However, instead of integrating over a uniform distribution, the PDP integrates over the marginal distribution of <span class="math inline">\(X_{-S}\)</span>, which is estimated using Monte Carlo sampling.</p>
</section>
<section id="decomposing-tree-ensembles" class="level2">
<h2 class="anchored" data-anchor-id="decomposing-tree-ensembles">Decomposing tree ensembles</h2>
<p><span class="citation" data-cites="yang2024inherently">Yang et al. (<a href="references.html#ref-yang2024inherently" role="doc-biblioref">2024</a>)</span> proposed a functional decomposition of tree ensembles, for example, trained with XGBoost. Their proposal consists of two parts: a decomposition procedure and a set of training constraints to make the decomposition more interpretable.</p>
<p>The strategy to get from an ensemble of trees to the functional composition involves aggregation, purification, and attribution. First, each tree is decomposed into decision rules, with each leaf node becoming a decision rule. These rules are then sorted by the features they use. For example, all rules using only feature <span class="math inline">\(X_1\)</span> are collected and used to estimate the main effect <span class="math inline">\(\hat{f}_1\)</span>. The same is done for all other main effects and interactions. However, this decomposition wouldnâ€™t be unique since, for example, you could absorb the main effect of <span class="math inline">\(X_1\)</span> into the interaction term of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>. They â€œpurifyâ€ the components to enforce zero means and orthogonality constraints (should sound familiar by now). In the attribution step, feature contributions for each data point are computed and aggregated across the data to get global importance values for each feature. The individual contributions are the same as the <a href="shapley.html">Shapley values</a>.</p>
<p>The other suggestion in the paper is to add constraints to the training so that the functional decomposition can be better interpreted. This includes simple things like setting the maximum tree depth low so that you control the maximum number of features that can interact. For example, setting the maximum depth to two makes the model have only main effects and two-way interactions, but no higher-order interactions. Other suggestions include monotonicity constraints, reduced number of bins, and interaction constraints. They also introduce a post-processing step for pruning effects from the functional decomposition.</p>
</section>
<section id="statistical-regression-models" class="level2">
<h2 class="anchored" data-anchor-id="statistical-regression-models">Statistical regression models</h2>
<p>This approach ties in with interpretable models, in particular <a href="extend-lm.html">generalized additive models</a>. Instead of decomposing a complex function, we can build constraints into the modeling process so that we can easily read out the individual components. While decomposition can be handled in a top-down manner, where we start with a high-dimensional function and decompose it, generalized additive models provide a bottom-up approach, where we build the model from simple components. Both approaches have in common that their goal is to provide individual and interpretable components. In statistical models, we restrict the number of components so that not all <span class="math inline">\(2^p\)</span> components have to be fitted. The simplest version is linear regression:</p>
<p><span class="math display">\[\hat{f}(\mathbf{x}) = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p\]</span></p>
<p>The formula looks very similar to the functional decomposition, but with two major modifications. Modification 1: All interaction effects are excluded, and we keep only the intercept and main effects. Modification 2: The main effects may only be linear in the features: <span class="math inline">\(\hat{f}_j(x_j) = \beta_j x_j\)</span>. Viewing the linear regression model through the lens of functional decomposition, we see that the model itself represents a functional decomposition of the true function that maps from features to target, but under strong assumptions that the effects are linear effects and there are no interactions.</p>
<p>The generalized additive model relaxes the second assumption by allowing more flexible functions <span class="math inline">\(\hat{f}_j\)</span> through the use of splines. Interactions can also be added, but this process is rather manual. Approaches such as GA2M attempt to add 2-way interactions automatically to a GAM <span class="citation" data-cites="caruana2015intelligible">(<a href="references.html#ref-caruana2015intelligible" role="doc-biblioref">Caruana et al. 2015</a>)</span>.</p>
<p>Thinking of a linear regression model or a GAM as functional decomposition can also lead to confusion. If you apply the decomposition approaches from earlier in the chapter (generalized functional ANOVA and accumulated local effects), you may get components that are different from the components read directly from the GAM. This can happen when interaction effects of correlated features are modeled in the GAM. The discrepancy occurs because other functional decomposition approaches split effects differently between interactions and main effects.</p>
<p>So when should you use GAMs instead of a complex model + decomposition? You should stick to GAMs when most interactions are zero, especially when there are no interactions with three or more features. If we know that the maximum number of features involved in interactions is two (<span class="math inline">\(|S| \leq 2\)</span>), then we can use approaches like MARS or GA2M. Ultimately, model performance on test data may indicate whether a GAM is sufficient or a more complex model performs much better.</p>
</section>
<section id="strengths" class="level2">
<h2 class="anchored" data-anchor-id="strengths">Strengths</h2>
<p>I consider functional decomposition to be a <strong>key concept of machine learning interpretability</strong> that helps to better understand many other methods.</p>
<p>Functional decomposition gives us a <strong>theoretical justification</strong> for decomposing high-dimensional and complex machine learning models into individual effects and interactions â€“ a necessary step that allows us to interpret individual effects. Functional decomposition is the core idea for techniques such as statistical regression models, ALE, (generalized) functional ANOVA, PDP, the H-statistic, and ICE curves.</p>
<p>Functional decomposition also provides a <strong>better understanding of other methods</strong>. For example, <a href="feature-importance.html">permutation feature importance</a> breaks the association between a feature and the target. Viewed through the functional decomposition lens, we can see that the permutation â€œdestroysâ€ the effect of all components in which the feature was involved. This affects the main effect of the feature, but also all interactions with other features. As another example, Shapley values decompose a prediction into additive effects of the individual features. But the functional decomposition tells us that there should also be interaction effects in the decomposition, so where are they? Shapley values provide a fair attribution of effects to the individual features, meaning that all interactions are also fairly attributed to the features and therefore divided up among the Shapley values.</p>
<p>When considering functional decomposition as a tool, the use of <strong>ALE plots offers many advantages</strong>. ALE plots provide a functional decomposition that is fast to compute, has software implementations (see the ALE chapter), and desirable pseudo-orthogonality properties.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p>The concept of functional decomposition quickly reaches its <strong>limits for high-dimensional components</strong> beyond interactions between two features. Not only does this exponential explosion in the number of features limit practicability, since we cannot easily visualize higher-order interactions, but computational time is insane if we were to compute all interactions.</p>
<p>Each method of functional decomposition has its <strong>individual disadvantages</strong>. The bottom-up approach â€“ constructing regression models â€“ is a quite manual process and imposes many constraints on the model that can affect predictive performance. Functional ANOVA requires independent features. Generalized functional ANOVA is very difficult to estimate. Accumulated local effect plots do not provide a variance decomposition.</p>
<p>The functional decomposition approach is <strong>more appropriate for analyzing tabular data than text or images</strong>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-apley2020visualizingeffects" class="csl-entry" role="listitem">
Apley, Daniel W., and Jingyu Zhu. 2020. <span>â€œVisualizing the <span>Effects</span> of <span>Predictor</span> <span>Variables</span> in <span>Black</span> <span>Box</span> <span>Supervised</span> <span>Learning</span> <span>Models</span>.â€</span> <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 82 (4): 1059â€“86. <a href="https://doi.org/10.1111/rssb.12377">https://doi.org/10.1111/rssb.12377</a>.
</div>
<div id="ref-caruana2015intelligible" class="csl-entry" role="listitem">
Caruana, Rich, Yin Lou, Johannes Gehrke, Paul Koch, Marc Sturm, and Noemie Elhadad. 2015. <span>â€œIntelligible <span>Models</span> for <span>HealthCare</span>: <span>Predicting</span> <span>Pneumonia</span> <span>Risk</span> and <span>Hospital</span> 30-Day <span>Readmission</span>.â€</span> In <em>Proceedings of the 21th <span>ACM</span> <span>SIGKDD</span> <span>International</span> <span>Conference</span> on <span>Knowledge</span> <span>Discovery</span> and <span>Data</span> <span>Mining</span></em>, 1721â€“30. <span>KDD</span> â€™15. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/2783258.2788613">https://doi.org/10.1145/2783258.2788613</a>.
</div>
<div id="ref-hooker2004discovering" class="csl-entry" role="listitem">
Hooker, Giles. 2004. <span>â€œDiscovering Additive Structure in Black Box Functions.â€</span> In <em>Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 575â€“80.
</div>
<div id="ref-hooker2007generalized" class="csl-entry" role="listitem">
â€”â€”â€”. 2007. <span>â€œGeneralized <span>Functional</span> <span>ANOVA</span> <span>Diagnostics</span> for <span>High</span>-<span>Dimensional</span> <span>Functions</span> of <span>Dependent</span> <span>Variables</span>.â€</span> <em>Journal of Computational and Graphical Statistics</em> 16 (3): 709â€“32. <a href="https://doi.org/10.1198/106186007X237892">https://doi.org/10.1198/106186007X237892</a>.
</div>
<div id="ref-yang2024inherently" class="csl-entry" role="listitem">
Yang, Zebin, Agus Sudjianto, Xiaoming Li, and Aijun Zhang. 2024. <span>â€œInherently <span>Interpretable Tree Ensemble Learning</span>.â€</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2410.19098">https://doi.org/10.48550/arXiv.2410.19098</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./interaction.html" class="pagination-link" aria-label="Feature Interaction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Feature Interaction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./feature-importance.html" class="pagination-link" aria-label="Permutation Feature Importance">
        <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Permutation Feature Importance</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="privacy-policy.html" target="_blank" style="font-size:11px;"> Privacy Policy </a> | <a href="https://christophmolnar.com/impressum" target="_blank" style="font-size:11px"> Impressum </a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/decomposition.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>