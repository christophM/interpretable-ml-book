# Example-Based Explanations {#example-based}

Metode penjelasan berbasis contoh memilih contoh tertentu dari kumpulan data untuk menjelaskan perilaku model machine learning atau untuk menjelaskan distribusi data yang mendasarinya.

Penjelasan berbasis contoh sebagian besar model-agnostic, karena mereka membuat model machine learning lebih dapat ditafsirkan.
Perbedaan metode model-agnostic adalah bahwa metode berbasis contoh menjelaskan model dengan memilih contoh dari kumpulan data dan bukan dengan membuat ringkasan fitur (seperti [feature importance](#feature-importance) atau [ketergantungan parsial](#pdp)).
Penjelasan berbasis contoh hanya masuk akal jika kita dapat mewakili contoh data dengan cara yang dapat dipahami secara manusiawi.
Ini bekerja dengan baik untuk gambar, karena kita dapat melihatnya secara langsung.
Secara umum, metode berbasis contoh bekerja dengan baik jika nilai fitur dari sebuah instance membawa lebih banyak konteks, artinya data memiliki struktur, seperti gambar atau teks.
Lebih menantang untuk merepresentasikan data tabular dengan cara yang berarti, karena sebuah instance dapat terdiri dari ratusan atau ribuan fitur (kurang terstruktur).
Mencantumkan semua nilai fitur untuk mendeskripsikan sebuah instance biasanya tidak berguna.
Ini berfungsi dengan baik jika hanya ada beberapa fitur atau jika kami memiliki cara untuk meringkas sebuah instance.

Penjelasan berbasis contoh membantu manusia membangun model mental dari model machine learning dan data yang telah dilatih oleh model machine learning.
Ini terutama membantu untuk memahami distribusi data yang kompleks.
Tapi apa yang saya maksud dengan penjelasan berbasis contoh?
Kita sering menggunakannya dalam pekerjaan dan kehidupan sehari-hari.
Mari kita mulai dengan beberapa contoh[^cbr].

Seorang dokter melihat pasien dengan batuk yang tidak biasa dan demam ringan.
Gejala pasien mengingatkannya pada pasien lain yang dia alami bertahun-tahun lalu dengan gejala serupa.
Dia menduga bahwa pasiennya saat ini bisa memiliki penyakit yang sama dan dia mengambil sampel darah untuk menguji penyakit spesifik ini.

Seorang ilmuwan data mengerjakan proyek baru untuk salah satu kliennya:
Analisis faktor risiko yang menyebabkan kegagalan mesin produksi untuk keyboard.
Ilmuwan data mengingat proyek serupa yang dia kerjakan dan menggunakan kembali bagian kode dari proyek lama karena menurutnya klien menginginkan analisis yang sama.

Seekor anak kucing duduk di ambang jendela sebuah rumah yang terbakar dan tidak berpenghuni.
Pemadam kebakaran telah tiba dan salah satu petugas pemadam kebakaran merenungkan sejenak apakah dia dapat mengambil risiko masuk ke gedung untuk menyelamatkan anak kucing itu.
Dia ingat kasus serupa dalam hidupnya sebagai petugas pemadam kebakaran:
Rumah-rumah kayu tua yang telah terbakar perlahan selama beberapa waktu seringkali tidak stabil dan akhirnya runtuh.
Karena kesamaan kasus ini, dia memutuskan untuk tidak masuk, karena risiko rumah runtuh terlalu besar.
Untungnya, kucing itu melompat keluar dari jendela, mendarat dengan selamat dan tidak ada yang terluka dalam kebakaran itu. Akhir yang bahagia.

Kisah-kisah ini menggambarkan bagaimana kita manusia berpikir dalam contoh atau analogi.
Cetak biru penjelasan berbasis contoh adalah:
Hal B mirip dengan hal A dan A menyebabkan Y, jadi saya memprediksi bahwa B akan menyebabkan Y juga.
Secara implisit, beberapa pendekatan machine learning bekerja berdasarkan contoh.
[decision trees](#tree) mempartisi data menjadi node berdasarkan kesamaan titik data dalam fitur yang penting untuk memprediksi target.
Sebuah decision trees mendapatkan prediksi untuk contoh data baru dengan menemukan contoh yang serupa (= dalam simpul terminal yang sama) dan mengembalikan rata-rata hasil dari contoh tersebut sebagai prediksi.
Metode k-nearest neighbor (knn) bekerja secara eksplisit dengan prediksi berbasis contoh.
Untuk contoh baru, model knn menempatkan k-neighbors terdekat (misalnya k=3 contoh terdekat) dan mengembalikan rata-rata hasil neighbors tersebut sebagai prediksi.
Prediksi knn dapat dijelaskan dengan mengembalikan k neighbors, yang -- sekali lagi -- hanya bermakna jika kita memiliki cara yang baik untuk merepresentasikan satu instance.

Bab-bab di bagian ini mencakup metode interpretasi berbasis contoh berikut:

- [counterfactual explanations](#counterfactual) memberi tahu kami bagaimana sebuah instance harus berubah untuk mengubah prediksinya secara signifikan.
Dengan membuat contoh kontrafaktual, kita belajar tentang bagaimana model membuat prediksinya dan dapat menjelaskan prediksi individu.
- [adversarial examples](#adversarial) adalah kontrafaktual yang digunakan untuk mengelabui model machine learning.
Penekanannya adalah membalik prediksi dan tidak menjelaskannya.
- [prototypes](#proto) adalah pilihan contoh representatif dari data dan kritik adalah contoh yang tidak terwakili dengan baik oleh prototypes tersebut. [^critique]
- [influential instances](#influential) adalah titik data pelatihan yang paling berpengaruh untuk parameter model prediksi atau prediksi itu sendiri.
Mengidentifikasi dan menganalisis influential instances membantu menemukan masalah dengan data, men-debug model, dan memahami perilaku model dengan lebih baik.
- [model k-nearest neighbor](#other-interpretable): Model machine learning (dapat ditafsirkan) berdasarkan contoh.


[^cbr]: Aamodt, Agnar, and Enric Plaza. "Case-based reasoning: Foundational issues, methodological variations, and system approaches." AI communications 7.1 (1994): 39-59.

