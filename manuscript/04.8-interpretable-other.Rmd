
<!--{pagebreak}-->

## Other Interpretable Models {#other-interpretable}

Daftar model yang dapat ditafsirkan terus bertambah dan ukurannya tidak diketahui.
Ini mencakup model sederhana seperti model linier, decision trees, dan naive Bayes, tetapi juga model yang lebih kompleks yang menggabungkan atau memodifikasi model machine learning yang tidak dapat ditafsirkan untuk membuatnya lebih dapat ditafsirkan.
Khususnya publikasi tentang jenis model yang terakhir saat ini sedang diproduksi dengan frekuensi tinggi dan sulit untuk mengikuti perkembangan.
Buku ini hanya menggoda classifier Naive Bayes dan k-nearest neighbor dalam bab ini.

### Naive Bayes Classifier

Pengklasifikasi Naive Bayes menggunakan teorema peluang bersyarat Bayes.
Untuk setiap fitur, itu menghitung probabilitas untuk kelas tergantung pada nilai fitur.
Pengklasifikasi Naive Bayes menghitung probabilitas kelas untuk setiap fitur secara independen, yang setara dengan asumsi kuat (= naif) tentang independensi bersyarat fitur.
Naive Bayes adalah model probabilitas bersyarat dan memodelkan probabilitas kelas $C_k$ sebagai berikut:

$$P(C_k|x)=\frac{1}{Z}P(C_k)\prod_{i=1}^n{}P(x_i|C_k)$$

Istilah Z adalah parameter penskalaan yang memastikan bahwa jumlah probabilitas untuk semua kelas adalah 1 (jika tidak, mereka tidak akan menjadi probabilitas).
Probabilitas bersyarat dari suatu kelas adalah peluang kelas dikalikan dengan peluang setiap fitur yang diberikan kelas tersebut, dinormalisasi dengan Z.
Rumus ini dapat diturunkan dengan menggunakan teorema Bayes.

Naive Bayes adalah interpretable models karena asumsi independensi.
Hal ini dapat ditafsirkan pada tingkat modular.
Sangat jelas untuk setiap fitur seberapa besar kontribusinya terhadap prediksi kelas tertentu, karena kita dapat menginterpretasikan probabilitas bersyarat.

### K-Nearest Neighbors

Metode k-nearest neighbor dapat digunakan untuk regresi dan klasifikasi dan menggunakan tetangga terdekat dari titik data untuk prediksi.
Untuk klasifikasi, metode k-nearest neighbor menetapkan kelas yang paling umum dari tetangga terdekat dari sebuah instance.
Untuk regresi, dibutuhkan rata-rata dari hasil tetangga.
Bagian yang sulit adalah menemukan k yang tepat dan memutuskan bagaimana mengukur jarak antar instance, yang pada akhirnya menentukan lingkungan.

Model k-nearest neighbor berbeda dari model interpretable lain yang disajikan dalam buku ini karena merupakan algoritma pembelajaran berbasis instance.
Bagaimana k-tetangga terdekat dapat diinterpretasikan?
Pertama-tama, tidak ada parameter untuk dipelajari, jadi tidak ada interpretasi pada tingkat modular.
Selain itu, ada kekurangan interpretasi model global karena model tersebut secara inheren lokal dan tidak ada bobot atau struktur global yang dipelajari secara eksplisit.
Mungkin itu bisa ditafsirkan di tingkat lokal?
Untuk menjelaskan prediksi, Anda selalu dapat mengambil k tetangga yang digunakan untuk prediksi.
Apakah model dapat ditafsirkan hanya bergantung pada pertanyaan apakah Anda dapat 'menafsirkan' satu contoh dalam kumpulan data.
Jika sebuah instance terdiri dari ratusan atau ribuan fitur, maka itu tidak dapat ditafsirkan, menurut saya.
Tetapi jika Anda memiliki sedikit fitur atau cara untuk mengurangi instans Anda menjadi fitur yang paling penting, menghadirkan k-nearest neighbor dapat memberi Anda penjelasan yang baik.
