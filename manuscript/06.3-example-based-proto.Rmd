```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## Prototypes and Criticisms {#proto}

Sebuah **prototypes** adalah contoh data yang mewakili semua data.
Sebuah **criticism** adalah contoh data yang tidak terwakili dengan baik oleh kumpulan prototypes.
Tujuan criticism adalah untuk memberikan wawasan bersama dengan prototypes, terutama untuk titik-data point yang tidak terwakili dengan baik oleh prototypes.
prototypes dan criticism dapat digunakan secara independen dari model machine learning untuk menggambarkan data, tetapi mereka juga dapat digunakan untuk membuat interpretable models atau untuk membuat model black box yang dapat diinterpretasikan.

Dalam bab ini saya menggunakan ungkapan "data point" untuk merujuk ke satu instance, untuk menekankan interpretasi bahwa suatu instance juga merupakan titik dalam sistem koordinat di mana setiap fitur adalah dimensi.
Gambar berikut menunjukkan distribusi data simulasi, dengan beberapa contoh dipilih sebagai prototypes dan beberapa sebagai criticism.
Poin kecil adalah data, poin besar criticism, dan kotak besar adalah prototypes.
Prototypes dipilih (secara manual) untuk menutupi pusat-pusat distribusi data dan criticism adalah titik-titik dalam sebuah cluster tanpa prototypes.
Prototypes dan criticism selalu merupakan contoh aktual dari data.

```{r, fig.cap = "Prototypes and criticisms for a data distribution with two features x1 and x2."}
set.seed(1)
dat1 = data.frame(x1 = rnorm(20, mean = 4, sd = 0.3), x2 = rnorm(20, mean = 1, sd = 0.3))
dat2 = data.frame(x1 = rnorm(30, mean = 2, sd = 0.2), x2 = rnorm(30, mean = 2, sd = 0.2))
dat3 = data.frame(x1 = rnorm(40, mean = 3, sd = 0.2), x2 = rnorm(40, mean = 3))
dat4 = data.frame(x1 = rnorm(7, mean = 4, sd = 0.1), x2 = rnorm(7, mean = 2.5, sd = 0.1))

dat = rbind(dat1, dat2, dat3, dat4)
dat$type = "data"
dat$type[c(7, 23, 77)] = "prototype"
dat$type[c(81,95)] = "criticism"

ggplot(dat, aes(x = x1, y = x2)) + geom_point(alpha = 0.7) +
  geom_point(data = filter(dat, type!='data'), aes(shape = type), size = 9, alpha = 1, color = "blue") +
  scale_shape_manual(breaks = c("prototype", "criticism"), values = c(18, 19))

```

Saya memilih prototypes secara manual, yang skalanya tidak baik dan mungkin menghasilkan hasil yang buruk.
Ada banyak pendekatan untuk menemukan prototypes dalam data.
Salah satunya adalah k-medoids, sebuah algoritma clustering yang terkait dengan algoritma k-means.
Setiap algoritma pengelompokan yang mengembalikan data point aktual sebagai pusat cluster akan memenuhi syarat untuk memilih prototypes.
Tetapi sebagian besar metode ini hanya menemukan prototypes, tetapi tidak ada criticism.
Bab ini menyajikan MMD-criticismus oleh Kim et. al (2016)[^criticism], sebuah pendekatan yang menggabungkan prototypes dan criticism dalam satu kerangka.

MMD-critic membandingkan distribusi data dan distribusi prototypes yang dipilih.
Ini adalah konsep sentral untuk memahami metode criticism MMD.
MMD-critic memilih prototypes yang meminimalkan perbedaan antara dua distribusi.
data point di area dengan kepadatan tinggi adalah prototypes yang baik, terutama ketika titik dipilih dari "klaster data" yang berbeda.
Titik-data point dari daerah yang tidak dijelaskan dengan baik oleh prototypes dipilih sebagai criticism.

Mari kita mempelajari lebih dalam teorinya.

### Theory

Prosedur criticism MMD pada level tinggi dapat diringkas secara singkat:

1. Pilih jumlah prototypes dan criticism yang ingin Anda temukan.
1. Temukan prototypes dengan greedy search.
prototypes dipilih agar sebaran prototypes mendekati sebaran data.
1. Temukan criticism dengan greedy search.
Poin dipilih sebagai criticism dimana distribusi prototypes berbeda dari distribusi data.

Kami membutuhkan beberapa bahan untuk menemukan prototypes dan criticism untuk dataset dengan MMD-critic.
Sebagai bahan paling dasar, kita membutuhkan **kernel function** untuk memperkirakan kepadatan data.
Kernel adalah fungsi yang menimbang dua data point sesuai dengan kedekatannya.
Berdasarkan perkiraan densitas, kita memerlukan ukuran yang memberitahu kita betapa berbedanya dua distribusi sehingga kita dapat menentukan apakah distribusi prototypes yang kita pilih dekat dengan distribusi data.
Ini diselesaikan dengan mengukur **maximum mean discrepancy (MMD)**.
Juga berdasarkan kernel function, kita memerlukan **witness function** untuk memberi tahu kita perbedaan dua distribusi pada data point tertentu.
Dengan witness function, kita dapat memilih criticism, yaitu data point di mana distribusi prototypes dan data menyimpang dan witness function mengambil nilai absolut yang besar.
Bahan terakhir adalah strategi pencarian untuk prototypes dan criticism yang baik, yang diselesaikan dengan **greedy search** sederhana.


Mari kita mulai dengan **maximum mean discrepancy (MMD)**, yang mengukur perbedaan antara dua distribusi.
Pemilihan prototypes menciptakan distribusi kepadatan prototypes.
Kami ingin mengevaluasi apakah distribusi prototypes berbeda dari distribusi data.
Kami memperkirakan keduanya dengan fungsi kepadatan kernel.
Perbedaan mean maksimum mengukur perbedaan antara dua distribusi, yang merupakan supremum atas ruang fungsi dari perbedaan antara harapan menurut dua distribusi.
Semua jelas?
Secara pribadi, saya memahami konsep-konsep ini jauh lebih baik ketika saya melihat bagaimana sesuatu dihitung dengan data.
Rumus berikut menunjukkan cara menghitung ukuran MMD kuadrat (MMD2):

$$MMD^2=\frac{1}{m^2}\sum_{i,j=1}^m{}k(z_i,z_j)-\frac{2}{mn}\sum_{i,j=1}^{m,n}k(z_i,x_j)+\frac{1}{n^2}\sum_{i,j=1}^n{}k(x_i,x_j)$$

k adalah kernel function yang mengukur kesamaan dua titik, tetapi lebih lanjut tentang ini nanti.
m adalah jumlah prototypes z, dan n adalah jumlah data point x dalam kumpulan data asli kami.
prototypes z adalah pilihan data point x.
Setiap titik bersifat multidimensi, yaitu dapat memiliki banyak fitur.
Tujuan dari MMD-critic adalah untuk meminimalkan MMD2.
Semakin dekat MMD2 ke nol, semakin baik distribusi prototypes sesuai dengan data.
Kunci untuk membawa MMD2 ke nol adalah istilah di tengah, yang menghitung jarak rata-rata antara prototypes dan semua data point lainnya (dikalikan 2).
Jika istilah ini ditambahkan ke suku pertama (kedekatan rata-rata prototypes satu sama lain) ditambah suku terakhir (kedekatan rata-rata data point satu sama lain), maka prototypes menjelaskan data dengan sempurna.
Cobalah apa yang akan terjadi pada rumus jika Anda menggunakan semua n data point sebagai prototypes.

Grafik berikut menggambarkan ukuran MMD2.
Plot pertama menunjukkan titik-data point dengan dua fitur, dimana estimasi kepadatan data ditampilkan dengan latar belakang yang diarsir.
Masing-masing plot lainnya menunjukkan pilihan prototypes yang berbeda, bersama dengan ukuran MMD2 dalam judul plot.
Prototypes adalah titik-titik besar dan distribusinya ditampilkan sebagai garis kontur.
Pemilihan prototypes yang paling baik mencakup data dalam skenario ini (kiri bawah) memiliki nilai ketidaksesuaian yang paling rendah.

```{r mmd, fig.cap = "The squared maximum mean discrepancy measure (MMD2) for a dataset with two features and different selections of prototypes.", cache = FALSE}
set.seed(42)
n = 40
# create dataset from three gaussians in 2d
dt1 = data.frame(x1 = rnorm(n, mean = 1, sd = 0.1), x2 = rnorm(n, mean = 1, sd = 0.3))
dt2 = data.frame(x1 = rnorm(n, mean = 4, sd = 0.3), x2 = rnorm(n, mean = 2, sd = 0.3))
dt3 = data.frame(x1 = rnorm(n, mean = 3, sd = 0.5), x2 = rnorm(n, mean = 3, sd = 0.3))
dt4 = data.frame(x1 = rnorm(n, mean = 2.6, sd = 0.1), x2 = rnorm(n, mean = 1.7, sd = 0.1))
dt = rbind(dt1, dt2, dt3, dt4)


radial = function(x1, x2, sigma = 1) {
  dist = sum((x1 - x2)^2)
  exp(-dist/(2*sigma^2))
}


cross.kernel = function(d1, d2) {
  kk = c()
  for (i in 1:nrow(d1)) {
    for (j in 1:nrow(d2)) {
      res = radial(d1[i,], d2[j,])
      kk = c(kk, res)
    }
  }
  mean(kk)
}

mmd2 = function(d1, d2) {
  cross.kernel(d1, d1) - 2 * cross.kernel(d1, d2) + cross.kernel(d2,d2)
}

# create 3 variants of prototypes
pt1 = rbind(dt1[c(1,2),], dt4[1,])
pt2 = rbind(dt1[1,], dt2[3,], dt3[19,])
pt3 = rbind(dt2[3,], dt3[19,])

# create plot with all data and density estimation
p = ggplot(dt, aes(x = x1, y = x2)) +
  stat_density_2d(geom = "tile", aes(fill = ..density..), contour = FALSE, alpha = 0.9) +
  geom_point() +
  scale_fill_gradient2(low = "white", high = "blue", guide = "none") +
  scale_x_continuous(limits = c(0, NA)) +
  scale_y_continuous(limits = c(0, NA))
# create plot for each prototype
p1 = p + geom_point(data = pt1, color = "red", size = 4) + geom_density_2d(data = pt1, color = "red") +
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt1)))

p2 = p + geom_point(data = pt2, color = "red", size = 4) +
  geom_density_2d(data = pt2, color = "red") +
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt2)))

p3 = p + geom_point(data = pt3, color = "red", size = 4) +
  geom_density_2d(data = pt3, color = "red") +
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt3)))
# TODO: Add custom legend for prototypes

# overlay mmd measure for each plot
gridExtra::grid.arrange(p, p1, p2, p3, ncol = 2)
```


Pilihan untuk kernel adalah kernel radial basis function:

$$k(x,x^\prime)=exp\left(-\gamma||x-x^\prime||^2\right)$$

di mana ||x-x'||^2^ adalah jarak Euclidean antara dua titik dan $\gamma$ adalah parameter penskalaan.
Nilai kernel menurun dengan jarak antara dua titik dan berkisar antara nol dan satu:
Nol ketika dua titik berjauhan tak terhingga;
satu ketika dua titik sama.

Kami menggabungkan ukuran MMD2, kernel, dan greedy search dalam algoritme untuk menemukan prototypes:

- Mulailah dengan daftar prototypes yang kosong.
- Sedangkan jumlah prototype dibawah jumlah terpilih m :
    - Untuk setiap titik dalam kumpulan data, periksa seberapa banyak MMD2 berkurang saat titik ditambahkan ke daftar prototypes. Tambahkan data point yang meminimalkan MMD2 ke daftar.
- Kembalikan daftar prototypes.

Bahan yang tersisa untuk menemukan criticism adalah witness function, yang memberitahu kita berapa banyak dua perkiraan kepadatan berbeda pada titik tertentu.
Dapat diperkirakan dengan menggunakan:

$$witness(x)=\frac{1}{n}\sum_{i=1}^nk(x,x_i)-\frac{1}{m}\sum_{j=1}^mk(x,z_j)$$

Untuk dua kumpulan data (dengan fitur yang sama), witness function memberi Anda sarana untuk mengevaluasi di mana distribusi empiris titik x lebih cocok.
Untuk menemukan criticism, kami mencari nilai ekstrem dari witness function baik ke arah negatif maupun positif.
Suku pertama dalam witness function adalah jarak rata-rata antara titik x dan data, dan suku kedua berturut-turut adalah jarak rata-rata antara titik x dan prototypes.
Jika witness function untuk titik x mendekati nol, maka fungsi kerapatan data dan prototypes saling berdekatan, yang berarti sebaran prototypes menyerupai sebaran data di titik x.
witness function negatif pada titik x berarti bahwa distribusi prototypes melebih-lebihkan distribusi data (misalnya jika kita memilih prototypes tetapi hanya ada beberapa data point di dekatnya);
witness function positif pada titik x berarti bahwa distribusi prototypes meremehkan distribusi data (misalnya jika ada banyak data point di sekitar x tetapi kami belum memilih prototypes terdekat).

Untuk memberi Anda lebih banyak intuisi, mari kita gunakan kembali prototypes dari plot sebelumnya dengan MMD2 terendah dan tampilkan witness function untuk beberapa titik yang dipilih secara manual.
Label pada plot berikut menunjukkan nilai witness function untuk berbagai titik yang ditandai sebagai segitiga.
Hanya titik di tengah yang memiliki nilai absolut tinggi dan oleh karena itu merupakan kandidat yang baik untuk dicriticism.


```{r witness, fig.cap = "Evaluations of the witness function at different points.", cache = FALSE, dependson = "mmd"}
witness = function(x, dist1, dist2, sigma = 1) {
  k1 = apply(dist1, 1, function(z) radial(x, z, sigma = sigma))
  k2 = apply(dist2, 1, function(z) radial(x, z, sigma = sigma))
  mean(k1) - mean(k2)
}

w.points.indices = c(125, 2, 60, 19, 100)
wit.points = dt[w.points.indices,]
wit.points$witness = apply(wit.points, 1, function(x) round(witness(x[c("x1", "x2")], dt, pt2, sigma = 1), 3))

p + geom_point(data = pt2, color = "red") +
  geom_density_2d(data = pt2, color = "red") +
  ggtitle(sprintf("%.3f MMD2", mmd2(dt, pt2))) +
  geom_label(data = wit.points, aes(label = witness), alpha = 0.9, vjust = "top") +
    geom_point(data = wit.points, color = "black", shape = 17, size = 4)
```

Witness function memungkinkan kita untuk secara eksplisit mencari contoh data yang tidak terwakili dengan baik oleh prototypes.
Criticism adalah poin yang memiliki nilai absolut tinggi dalam witness function.
Seperti prototypes, criticism juga ditemukan melalui greedy search.
Namun alih-alih mengurangi MMD2 secara keseluruhan, kami mencari poin yang memaksimalkan fungsi biaya yang mencakup witness function dan istilah pengatur.
Istilah tambahan dalam fungsi optimasi memaksakan keragaman pada titik-titik, yang diperlukan agar titik-titik itu berasal dari cluster yang berbeda.

Langkah kedua ini tidak tergantung pada bagaimana prototypes ditemukan.
Saya juga bisa memilih sendiri beberapa prototypes dan menggunakan prosedur yang dijelaskan di sini untuk mempelajari criticism.
Atau prototypes dapat berasal dari prosedur pengelompokan apa pun, seperti k-medoid.

Itu saja dengan bagian penting dari teori criticism MMD.
Satu pertanyaan tersisa:
**Bagaimana MMD-critic dapat digunakan untuk machine learning yang dapat diinterpretasikan?**

MMD-critic dapat menambahkan interpretabilitas dalam tiga cara:
Dengan membantu untuk lebih memahami distribusi data;
dengan membangun model yang dapat ditafsirkan;
dengan membuat model black box dapat diinterpretasikan.

Jika Anda menerapkan MMD-critic ke data Anda untuk menemukan prototypes dan criticism, itu akan meningkatkan pemahaman Anda tentang data, terutama jika Anda memiliki distribusi data yang kompleks dengan kasus tepi.
Tetapi dengan MMD-critic Anda dapat mencapai lebih banyak!

Misalnya, Anda dapat membuat model prediksi yang dapat ditafsirkan: apa yang disebut "model prototypes terdekat".
Fungsi prediksi didefinisikan sebagai:

$$\hat{f}(x)=argmax_{i\in{}S}k(x,x_i)$$

yang berarti bahwa kita memilih prototypes i dari himpunan prototypes S yang paling dekat dengan data point baru, dalam arti bahwa ia menghasilkan nilai tertinggi dari kernel function.
Prototypes itu sendiri dikembalikan sebagai penjelasan untuk prediksi.
Prosedur ini memiliki tiga parameter penyetelan:
Jenis kernel, parameter penskalaan kernel, dan jumlah prototypes.
Semua parameter dapat dioptimalkan dalam loop validasi silang.
Criticism tidak digunakan dalam pendekatan ini.

Sebagai opsi ketiga, kita dapat menggunakan MMD-critic untuk membuat model machine learning apa pun yang dapat dijelaskan secara global dengan memeriksa prototypes dan criticism beserta prediksi modelnya.
Prosedurnya adalah sebagai berikut:

1. Temukan prototypes dan criticism dengan MMD-critic.
1. Latih model machine learning seperti biasa.
1. Memprediksi hasil untuk prototypes dan criticism dengan model machine learning.
1. Analisis prediksi: Dalam kasus apa algoritmanya salah?
Sekarang Anda memiliki sejumlah contoh yang mewakili data dengan baik dan membantu Anda menemukan kelemahan model machine learning.

Bagaimana itu membantu?
Ingat ketika pengklasifikasi gambar Google mengidentifikasi orang kulit hitam sebagai gorila?
Mungkin mereka seharusnya menggunakan prosedur yang dijelaskan di sini sebelum menerapkan model pengenalan gambar mereka.
Tidak cukup hanya mengecek performa model, karena jika sudah 99% benar, masalah ini masih bisa di 1%.
Dan label juga bisa salah!
Memeriksa semua data pelatihan dan melakukan pemeriksaan kewarasan jika prediksi bermasalah mungkin telah mengungkapkan masalahnya, tetapi tidak mungkin.
Tetapi pemilihan -- katakanlah beberapa ribu -- prototypes dan criticism layak dilakukan dan dapat mengungkapkan masalah dengan data:
Ini mungkin menunjukkan bahwa ada kekurangan gambar orang dengan kulit gelap, yang menunjukkan adanya masalah dengan keragaman dalam kumpulan data.
Atau bisa juga menampilkan satu atau lebih gambar seseorang dengan kulit gelap sebagai prototypes atau (mungkin) sebagai criticism dengan klasifikasi "gorila" yang terkenal kejam.
Saya tidak berjanji bahwa criticismus MMD pasti akan mencegat kesalahan semacam ini, tetapi ini adalah pemeriksaan kewarasan yang baik.

### Examples

Contoh criticism MMD berikut menggunakan dataset digit tulisan tangan.

Melihat prototypes sebenarnya, Anda mungkin memperhatikan bahwa jumlah gambar per digit berbeda.
Ini karena sejumlah prototypes tetap dicari di seluruh dataset dan bukan dengan jumlah tetap per kelas.
Seperti yang diharapkan, prototypes menunjukkan cara yang berbeda untuk menulis angka.

```{r, prototypes-and-criticisms2, fig.cap = "Prototypes for a handwritten digits dataset.", out.width=600}
knitr::include_graphics("images/proto-critique2.jpg")
```


### Advantages

Dalam studi pengguna, penulis criticism MMD memberikan gambar kepada peserta, yang harus mereka sesuaikan secara visual dengan salah satu dari dua set gambar, masing-masing mewakili satu dari dua kelas (misalnya dua ras anjing).
**Peserta tampil paling baik saat set menunjukkan prototypes dan criticism** daripada gambar acak dari suatu kelas.

Anda bebas **memilih jumlah prototypes dan criticism**.

MMD-critic bekerja dengan perkiraan kepadatan data.
Ini **berfungsi dengan semua jenis data dan semua jenis model machine learning**.

Algoritmenya **mudah diterapkan**.

MMD-critic sangat fleksibel dalam penggunaannya untuk meningkatkan kemampuan interpretasi.
Ini dapat digunakan untuk memahami distribusi data yang kompleks.
Ini dapat digunakan untuk membangun model interpretable machine learning.
Atau dapat menjelaskan pengambilan keputusan model machine learning black box.

**Menemukan criticism tidak tergantung pada proses pemilihan prototypes**.
Tetapi masuk akal untuk memilih prototypes menurut criticism MMD, karena prototypes dan criticism dibuat menggunakan metode yang sama untuk membandingkan prototypes dan kepadatan data.


### Disadvantages

Sementara, secara matematis, prototypes dan criticism didefinisikan secara berbeda, **perbedaannya didasarkan pada nilai batas** (jumlah prototypes).
Misalkan Anda memilih jumlah prototypes yang terlalu rendah untuk menutupi distribusi data.
Criticism akan berakhir di area yang tidak dijelaskan dengan baik.
Tetapi jika Anda menambahkan lebih banyak prototypes, mereka juga akan berakhir di area yang sama.
Setiap interpretasi harus memperhitungkan bahwa criticism sangat bergantung pada prototypes yang ada dan nilai batas (sewenang-wenang) untuk jumlah prototypes.

Anda harus **memilih jumlah prototypes dan criticism**.
Sebanyak ini bisa menyenangkan untuk dimiliki, itu juga merupakan loss.
Berapa banyak prototypes dan criticism yang sebenarnya kita butuhkan?
Lebih banyak lebih baik? Semakin sedikit semakin baik?
Salah satu solusinya adalah memilih jumlah prototypes dan criticism dengan mengukur berapa banyak waktu yang dimiliki manusia untuk tugas melihat gambar, yang tergantung pada aplikasi tertentu.
Hanya ketika menggunakan MMD-critic untuk membangun classifier, kami memiliki cara untuk mengoptimalkannya secara langsung.
Salah satu solusi dapat berupa screeplot yang menunjukkan jumlah prototypes pada sumbu x dan ukuran MMD2 pada sumbu y.
Kami akan memilih jumlah prototypes di mana kurva MMD2 rata.

Parameter lainnya adalah pilihan kernel dan parameter penskalaan kernel.
Kami memiliki masalah yang sama dengan jumlah prototypes dan criticism:
**Bagaimana cara memilih kernel dan parameter penskalaannya?**
Sekali lagi, ketika kita menggunakan MMD-critic sebagai pengklasifikasi prototypes terdekat, kita dapat menyetel parameter kernel.
Namun, untuk kasus penggunaan criticismus MMD yang tidak supervised, masih belum jelas.
(Mungkin saya agak keras di sini, karena semua metode tanpa pengawasan memiliki masalah ini.)

Dibutuhkan semua fitur sebagai masukan, **mengabaikan fakta bahwa beberapa fitur mungkin tidak relevan** untuk memprediksi hasil yang diinginkan.
Salah satu solusinya adalah dengan hanya menggunakan fitur yang relevan, misalnya penyematan gambar, bukan piksel mentah.
Ini berfungsi selama kita memiliki cara untuk memproyeksikan instance asli ke representasi yang hanya berisi informasi yang relevan.

Ada beberapa kode yang tersedia, tetapi **belum diimplementasikan sebagai perangkat lunak yang dikemas dan didokumentasikan dengan baik**.


### Code and Alternatives

Implementasi MMD-critic dapat ditemukan di sini: [https://github.com/BeenKim/MMD-critic](https://github.com/BeenKim/MMD-critic).

Alternatif paling sederhana untuk menemukan prototypes adalah [k-medoids](https://en.wikipedia.org/wiki/K-medoids) oleh Kaufman et. al (1987).[^medoids]

[^medoids]: Kaufman, Leonard, and Peter Rousseeuw. "Clustering by means of medoids". North-Holland (1987).

[^critique]: Kim, Been, Rajiv Khanna, and Oluwasanmi O. Koyejo. "Examples are not enough, learn to criticize! Criticism for interpretability." Advances in Neural Information Processing Systems (2016).
