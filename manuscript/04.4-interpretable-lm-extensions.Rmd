```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## GLM, GAM and more {#extend-lm}

Kekuatan terbesar tetapi juga kelemahan terbesar dari [model linear regression](#limo) adalah bahwa prediksi dimodelkan sebagai jumlah bobot fitur.
Selain itu, model linier hadir dengan banyak asumsi lain.
Berita buruknya adalah (yah, bukan benar-benar berita) bahwa semua asumsi itu sering dilanggar dalam kenyataan:
Hasil yang diberikan fitur mungkin memiliki distribusi non-Gaussian, fitur mungkin berinteraksi dan hubungan antara fitur dan hasilnya mungkin nonlinier.
Kabar baiknya adalah bahwa komunitas statistik telah mengembangkan berbagai modifikasi yang mengubah model linear regression dari pisau sederhana menjadi pisau Swiss.

Bab ini jelas bukan panduan pasti Anda untuk memperluas model linier.
Sebaliknya, ini berfungsi sebagai ikhtisar ekstensi seperti Generalized Linear Models (GLMs) dan Generalized Additive Models (GAMs) dan memberi Anda sedikit intuisi.
Setelah membaca, Anda harus memiliki gambaran yang solid tentang bagaimana memperluas model linier.
Jika Anda ingin mempelajari lebih lanjut tentang model linear regression terlebih dahulu, saya sarankan Anda membaca [bab tentang model linear regression](#limo), jika Anda belum melakukannya.

Mari kita ingat rumus model linear regression:

$$y=\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}+\epsilon$$

Model linear regression mengasumsikan bahwa hasil y dari sebuah instance dapat dinyatakan dengan jumlah bobot fitur p dengan individual error $\epsilon$ yang mengikuti distribusi Gaussian.
Dengan memaksakan data ke dalam korset formula ini, kami memperoleh banyak interpretasi model.
Efek fitur bersifat aditif, artinya tidak ada interaksi, dan hubungannya linier, artinya peningkatan fitur sebesar satu unit dapat langsung diterjemahkan ke dalam peningkatan/penurunan hasil yang diprediksi.
Model linier memungkinkan kita untuk memadatkan hubungan antara fitur dan hasil yang diharapkan menjadi satu angka, yaitu bobot yang diperkirakan.

Tapi jumlah tertimbang sederhana terlalu membatasi untuk banyak masalah prediksi dunia nyata.
Dalam bab ini kita akan belajar tentang tiga masalah model linear regression klasik dan bagaimana menyelesaikannya.
Ada banyak lagi masalah dengan asumsi yang mungkin dilanggar, tetapi kami akan fokus pada tiga yang ditunjukkan pada gambar berikut:

```{r three-lm-problems, fig.cap = "Three assumptions of the linear model (left side): Gaussian distribution of the outcome given the features, additivity (= no interactions) and linear relationship. Reality usually does not adhere to those assumptions (right side): Outcomes might have non-Gaussian distributions, features might interact and the relationship might be nonlinear."}
theme_blank = theme(axis.line=element_blank(),axis.text.x=element_blank(),
          axis.text.y=element_blank(),axis.ticks=element_blank(),
          axis.title.x=element_blank(),
          axis.title.y=element_blank(),legend.position="none",
          panel.background=element_blank(),panel.border=element_blank(),panel.grid.major=element_blank(),
          panel.grid.minor=element_blank(),plot.background=element_blank())

## For the GLM
n = 10000
df = data.frame(x = c(rnorm(n), rexp(n, rate = 0.5)), dist = rep(c("Gaussian", "Definitely Not Gaussian"), each = n))
df$dist  = relevel(factor(df$dist), "Gaussian")
p.glm = ggplot(df) + geom_density(aes(x = x)) + facet_grid(. ~ dist, scales = "free") + theme_blank

# For the interaction
df = data.frame(x1 = seq(from = -3, to = 3, length.out = n), x2 = sample(c(1,2), size = n, replace = TRUE))
df$y = 3 + 5 * df$x1 + (2  - 8 * df$x1 ) * (df$x2 == 2)
df$interaction = "Interaction"
df2 = df
df2$y = 3  + 5 * df$x1 + 0.5 * (- 8 * df$x1 ) + 2 * (df$x2 == 2)
df2$interaction = "No Interaction"

df = rbind(df, df2)
df$interaction  = relevel(factor(df$interaction), "No Interaction")
df$x2 = factor(df$x2)
p.interaction = ggplot(df) + geom_line(aes(x = x1, y = y, group = x2, lty = x2)) + facet_grid(. ~ interaction) + theme_blank


# For the gam
df = data.frame(x  = seq(from = 0, to = 10, length.out = 200))
df$y = 5 + 2 * df$x
df$type = "Linear"
df2 = df
df2$y = 3 + 2 * df$x + 3 * sin(df$x)
df2$type = "Nonlinear"
df = rbind(df, df2)

p.gam = ggplot(df) + geom_line(aes(x = x, y = y)) + facet_grid(. ~ type) + theme_blank

gridExtra::grid.arrange(p.glm, p.interaction, p.gam)

```

Ada solusi untuk semua masalah ini:

**Masalah**: Hasil target y yang diberikan fitur tidak mengikuti distribusi Gaussian.
**Contoh**: Misalkan saya ingin memprediksi berapa menit saya akan mengendarai sepeda pada hari tertentu.
Sebagai fitur saya memiliki jenis hari, cuaca dan sebagainya.
Jika saya menggunakan model linier, itu bisa memprediksi menit negatif karena mengasumsikan distribusi Gaussian yang tidak berhenti pada 0 menit.
Juga jika saya ingin memprediksi probabilitas dengan model linier, saya bisa mendapatkan probabilitas yang negatif atau lebih besar dari 1.
**Solusi**: [Generalized Linear Models (GLM)](#glm).

**Masalah**: Fitur berinteraksi.
**Contoh**: Rata-rata, hujan ringan memiliki sedikit efek negatif pada keinginan saya untuk bersepeda.
Tapi di musim panas, selama jam sibuk, saya menyambut hujan, karena semua pengendara sepeda cuaca cerah tinggal di rumah dan saya memiliki jalur sepeda untuk diri saya sendiri!
Ini adalah interaksi antara waktu dan cuaca yang tidak dapat ditangkap oleh model aditif murni.
**Solusi**: [Menambahkan interaksi secara manual](#lm-interact).

**Masalah**: Hubungan sebenarnya antara fitur dan y tidak linier.
**Contoh**: Antara 0 dan 25 derajat Celcius, pengaruh suhu terhadap keinginan saya untuk bersepeda dapat bersifat linier, yang berarti bahwa peningkatan dari 0 ke 1 derajat menyebabkan peningkatan keinginan bersepeda yang sama dengan peningkatan dari 20 sampai 21.
Tetapi pada suhu yang lebih tinggi, motivasi saya untuk bersepeda turun dan bahkan menurun - saya tidak suka bersepeda saat terlalu panas.
**Solusi**: [Generalized Additive Models (GAM); transformasi fitur](#gam).

Solusi untuk ketiga masalah ini disajikan dalam bab ini.
Banyak ekstensi lebih lanjut dari model linier dihilangkan.
Jika saya mencoba untuk membahas semuanya di sini, bab ini akan dengan cepat berubah menjadi buku di dalam buku tentang topik yang sudah dibahas di banyak buku lain.
Tetapi karena Anda sudah berada di sini, saya telah membuat sedikit masalah plus gambaran umum solusi untuk ekstensi model linier, yang dapat Anda temukan di [akhir bab](#more-lm-extension).
Nama solusi dimaksudkan sebagai titik awal pencarian.

### Non-Gaussian Outcomes - GLMs {#glm}

Model linear regression mengasumsikan bahwa hasil yang diberikan fitur masukan mengikuti distribusi Gaussian.
Asumsi ini mengecualikan banyak kasus:
Hasil juga dapat berupa kategori (kanker vs. sehat), hitungan (jumlah anak), waktu terjadinya suatu peristiwa (waktu kegagalan mesin) atau hasil yang sangat miring dengan beberapa nilai yang sangat tinggi (pendapatan rumah tangga).
Model linear regression dapat diperluas untuk memodelkan semua jenis hasil ini.
Ekstensi ini disebut **Generalized Linear Models** atau **GLM** singkatnya.
Sepanjang bab ini, saya akan menggunakan nama GLM untuk kerangka umum dan model khusus dari kerangka itu.
Konsep inti dari setiap GLM adalah:
Pertahankan jumlah tertimbang dari fitur, tetapi izinkan distribusi hasil non-Gaussian dan hubungkan rata-rata yang diharapkan dari distribusi ini dan jumlah tertimbang melalui fungsi yang mungkin nonlinier.
Misalnya, logistic regression model mengasumsikan distribusi Bernoulli untuk hasil dan menghubungkan rata-rata yang diharapkan dan jumlah tertimbang menggunakan fungsi logistik.

GLM secara matematis menghubungkan jumlah bobot fitur dengan nilai rata-rata dari distribusi yang diasumsikan menggunakan fungsi tautan g, yang dapat dipilih secara fleksibel tergantung pada jenis hasil.

$$g(E_Y(y|x))=\beta_0+\beta_1{}x_{1}+\ldots{}\beta_p{}x_{p}$$

GLM terdiri dari tiga komponen:
Fungsi tautan g, jumlah bobot $X^T\beta$ (kadang-kadang disebut prediktor linier) dan distribusi probabilitas dari keluarga eksponensial yang mendefinisikan $E_Y$.

Keluarga eksponensial adalah himpunan distribusi yang dapat ditulis dengan rumus yang sama (berparameter) yang mencakup eksponen, mean dan varians dari distribusi dan beberapa parameter lainnya.
Saya tidak akan membahas detail matematika karena ini adalah alam semesta yang sangat besar yang tidak ingin saya masuki.
Wikipedia memiliki [daftar distribusi yang rapi dari keluarga eksponensial](https://en.wikipedia.org/wiki/Exponential_family#Table_of_distributions).
Distribusi apa pun dari daftar ini dapat dipilih untuk GLM Anda.
Berdasarkan jenis hasil yang ingin Anda prediksi, pilih distribusi yang sesuai.
Apakah hasilnya menghitung sesuatu (misalnya jumlah anak yang tinggal di rumah tangga)?
Maka distribusi Poisson bisa menjadi pilihan yang baik.
Apakah hasilnya selalu positif (misalnya waktu antara dua peristiwa)?
Maka distribusi eksponensial bisa menjadi pilihan yang baik.

Mari kita pertimbangkan model linier klasik sebagai kasus khusus dari GLM.
Fungsi tautan untuk distribusi Gaussian dalam model linier klasik hanyalah fungsi identitas.
Distribusi Gaussian diparameterisasi oleh mean dan parameter varians.
Rata-rata menggambarkan nilai yang kita harapkan rata-rata dan varians menggambarkan seberapa besar nilai bervariasi di sekitar rata-rata ini.
Dalam model linier, fungsi tautan menghubungkan jumlah bobot fitur dengan rata-rata distribusi Gaussian.

Di bawah kerangka kerja GLM, konsep ini digeneralisasikan ke distribusi apa pun (dari keluarga eksponensial) dan fungsi tautan arbitrer.
Jika y adalah hitungan sesuatu, seperti jumlah kopi yang diminum seseorang pada hari tertentu, kita dapat memodelkannya dengan GLM dengan distribusi Poisson dan logaritma natural sebagai fungsi tautan:

$$ln(E_Y(y|x))=x^{T}\beta$$

Model logistic regression juga merupakan GLM yang mengasumsikan distribusi Bernoulli dan menggunakan fungsi logit sebagai fungsi link.
Rerata distribusi binomial yang digunakan dalam logistic regression adalah probabilitas bahwa y adalah 1.

$$x^{T}\beta=ln\left(\frac{E_Y(y|x)}{1-E_Y(y|x)}\right)=ln\left(\frac{P(y=1|x)}{1-P(y=1|x)}\right)$$

Dan jika kita memecahkan persamaan ini untuk memiliki P(y=1) di satu sisi, kita mendapatkan rumus logistic regression:

$$P(y=1)=\frac{1}{1+exp(-x^{T}\beta)}$$

Setiap distribusi dari keluarga eksponensial memiliki fungsi tautan kanonik yang dapat diturunkan secara matematis dari distribusi tersebut.
Kerangka kerja GLM memungkinkan untuk memilih fungsi tautan secara independen dari distribusi.
Bagaimana cara memilih fungsi tautan yang tepat?
Tidak ada resep yang sempurna.
Anda memperhitungkan pengetahuan akun tentang distribusi target Anda, tetapi juga pertimbangan teoritis dan seberapa baik model sesuai dengan data Anda yang sebenarnya.
Untuk beberapa distribusi, fungsi tautan kanonik dapat menghasilkan nilai yang tidak valid untuk distribusi tersebut.
Dalam kasus distribusi eksponensial, fungsi tautan kanonik adalah kebalikan negatif, yang dapat menyebabkan prediksi negatif yang berada di luar domain distribusi eksponensial.
Karena Anda dapat memilih fungsi tautan apa pun, solusi sederhananya adalah memilih fungsi lain yang menghormati domain distribusi.

**Contoh**
Saya telah mensimulasikan kumpulan data tentang perilaku minum kopi untuk menyoroti perlunya GLM.
Misalkan Anda telah mengumpulkan data tentang perilaku minum kopi Anda sehari-hari.
Jika Anda tidak suka kopi, berpura-puralah tentang teh.
Seiring dengan jumlah cangkir, Anda mencatat tingkat stres Anda saat ini pada skala 1 sampai 10, seberapa baik Anda tidur malam sebelumnya pada skala 1 sampai 10 dan apakah Anda harus bekerja pada hari itu.
Tujuannya adalah untuk memprediksi jumlah kopi yang diberikan fitur stres, tidur dan bekerja.
Saya mensimulasikan data selama 200 hari.
Stres dan tidur digambar secara seragam antara 1 dan 10 dan pekerjaan ya/tidak digambar dengan peluang 50/50 (sungguh hidup!).
Untuk setiap hari, jumlah kopi kemudian diambil dari distribusi Poisson, memodelkan intensitas $\lambda$ (yang juga merupakan nilai yang diharapkan dari distribusi Poisson) sebagai fungsi dari fitur tidur, stres, dan kerja.
Anda bisa menebak kemana arah cerita ini:
*"Hei, mari kita memodelkan data ini dengan model linier ... Oh tidak berhasil ... Mari kita coba GLM dengan distribusi Poisson ... SURPRISE! Sekarang berhasil!".*
Saya harap saya tidak merusak cerita terlalu banyak untuk Anda.

Mari kita lihat distribusi variabel target, jumlah kopi pada hari tertentu:

```{r poisson-data, fig.cap = "Simulated distribution of number of daily coffees for 200 days."}
# simulate data where the normal linear model fails.
n = 200
df = data.frame(stress  = runif(n = n, min = 1, max = 10), 
  sleep = runif(n = n, min = 1, max = 10), 
  work = sample(c("YES", "NO"), size = n, replace = TRUE))
lambda = exp(1* df$stress/10 - 2 * (df$sleep - 5)/10  - 1 * (df$work == "NO"))
df$y = rpois(lambda = lambda, n = n)

tab = data.frame(table(df$y))

ggplot(tab) + 
  geom_col(aes(x = Var1, y = Freq), fill = default_color, width = 0.3) +
  scale_x_discrete("Number of coffees on a given day") + 
  scale_y_continuous("Number of days")
```

Pada `r tab[1,2]` dari `r n` hari Anda tidak minum kopi sama sekali dan pada hari yang paling ekstrem Anda memiliki `r tab[nrow(tab),1]`.
Mari kita secara naif menggunakan model linier untuk memprediksi jumlah kopi menggunakan tingkat tidur, tingkat stres dan bekerja ya/tidak sebagai fitur.
Apa yang bisa salah ketika kita salah mengasumsikan distribusi Gaussian?
Asumsi yang salah dapat membuat estimasi menjadi tidak valid, terutama confidence intervals dari bobot.
Masalah yang lebih jelas adalah bahwa prediksi tidak cocok dengan domain "diizinkan" dari hasil sebenarnya, seperti yang ditunjukkan gambar berikut.

```{r failing-linear-model, fig.cap = "Predicted number of coffees dependent on stress, sleep and work. The linear model predicts negative values."}
mod.gaus = glm(y ~ ., data = df, x = TRUE)
pred.gauss = data.frame(pred = predict(mod.gaus), actual = df$y)
ggplot(pred.gauss) + 
  geom_histogram(aes(x = pred), fill = default_color) + 
  scale_x_continuous("Predicted number of coffees") + 
  scale_y_continuous("Frequency")
```

Model linier tidak masuk akal, karena memprediksi jumlah kopi negatif.
Masalah ini dapat diselesaikan dengan Generalized Linear Models (GLMs).
Kita dapat mengubah fungsi tautan dan distribusi yang diasumsikan.
Salah satu kemungkinan adalah menjaga distribusi Gaussian dan menggunakan fungsi tautan yang selalu mengarah pada prediksi positif seperti tautan log (kebalikannya adalah fungsi exp) alih-alih fungsi identitas.
Bahkan lebih baik:
Kami memilih distribusi yang sesuai dengan proses pembuatan data dan fungsi tautan yang sesuai.
Karena hasilnya adalah hitungan, distribusi Poisson adalah pilihan alami, bersama dengan logaritma sebagai fungsi tautan.
Dalam hal ini, data bahkan dihasilkan dengan distribusi Poisson, sehingga GLM Poisson adalah pilihan yang tepat.
GLM Poisson yang dipasang mengarah ke distribusi nilai prediksi berikut:

```{r linear-model-positive, fig.cap = "Predicted number of coffees dependent on stress, sleep and work. The GLM with Poisson assumption and log link is an appropriate model for this dataset."}
mod.pois = glm(y ~ ., data = df, x = TRUE, family = poisson(link = "log"))
pred.pois = data.frame(pred = predict(mod.pois, type = "response"), actual = df$y)
ggplot(pred.pois)  + 
  geom_histogram(aes(x = pred), fill = default_color)+ 
  scale_x_continuous("Predicted number of coffees") + 
  scale_y_continuous("Frequency")
```

Tidak ada jumlah negatif kopi, terlihat jauh lebih baik sekarang.

**Interpretasi bobot GLM**

Distribusi yang diasumsikan bersama dengan fungsi tautan menentukan bagaimana perkiraan bobot fitur diinterpretasikan.
Dalam contoh hitungan kopi, saya menggunakan GLM dengan distribusi Poisson dan tautan log, yang menyiratkan hubungan berikut antara fitur dan hasil yang diharapkan.

$$ln(E(\text{coffees}|\text{stress},\text{sleep},\text{work}))=\beta_0+\beta_{\text{stress}}x_{\text{stress}}+\beta_{\text{sleep}}x_{\text{sleep}}+\beta_{\text{work}}x_{\text{work}}$$

Untuk menginterpretasikan bobot, kami membalikkan fungsi tautan sehingga kami dapat menginterpretasikan efek fitur pada hasil yang diharapkan dan bukan pada logaritma dari hasil yang diharapkan.

$$E(\text{coffees}|\text{stress},\text{sleep},\text{work})=exp(\beta_0+\beta_{\text{stress}}x_{\text{stress}}+\beta_{\text{sleep}}x_{\text{sleep}}+\beta_{\text{work}}x_{\text{work}})$$

Karena semua bobot berada dalam fungsi eksponensial, interpretasi efek bukanlah aditif, tetapi perkalian, karena exp(a + b) adalah exp(a) kali exp(b).
Bahan terakhir untuk interpretasi adalah bobot sebenarnya dari contoh mainan.
Tabel berikut mencantumkan perkiraan bobot dan exp(bobot) bersama dengan confidence intervals 95%:

```{r poisson-model-params}
cc = data.frame(summary(mod.pois)$coefficients)
cc = cc[,c("Estimate", "Std..Error")]
colnames(cc) = c("beta", 'var.beta')
cc$exp.beta = exp(cc[, 'beta'])
cc = cc[c("beta", "exp.beta")]
cc = cbind(cc, exp(confint(mod.pois)))
cc$ci = sprintf("%.2f [%.2f, %.2f]", cc$exp.beta, cc$`2.5 %`, cc$`97.5 %`)
kable(cc[c("beta", "ci")], col.names = c("weight", "exp(weight) [2.5%, 97.5%]"), digits = 2)
```

Meningkatkan tingkat stres dengan satu poin mengalikan jumlah kopi yang diharapkan dengan faktor `r round(cc["stress", "exp.beta"], 2)`.
Meningkatkan kualitas tidur satu poin mengalikan jumlah kopi yang diharapkan dengan faktor `r round(cc["sleep", "exp.beta"], 2)`.
Jumlah kopi yang diprediksi pada hari kerja rata-rata adalah `r round(cc["workYES", "exp.beta"], 2)` kali jumlah kopi pada hari libur.
Singkatnya, semakin banyak stres, semakin sedikit tidur dan semakin banyak bekerja, semakin banyak kopi yang dikonsumsi.

Pada bagian ini Anda belajar sedikit tentang Generalized Linear Models yang berguna ketika target tidak mengikuti distribusi Gaussian.
Selanjutnya, kita melihat bagaimana mengintegrasikan interaksi antara dua fitur ke dalam model linear regression.

### Interactions {#lm-interact}

Model linear regression mengasumsikan bahwa efek dari satu fitur adalah sama terlepas dari nilai fitur lainnya (= tidak ada interaksi).
Namun seringkali ada interaksi dalam data.
Untuk memprediksi [jumlah sepeda](#bike-data) yang disewa, mungkin ada interaksi antara suhu dan hari kerja atau tidak.
Mungkin, ketika orang harus bekerja, suhu tidak terlalu mempengaruhi jumlah sepeda sewaan, karena orang akan mengendarai sepeda sewaan untuk bekerja apa pun yang terjadi.
Pada hari libur, banyak orang bersepeda untuk bersenang-senang, tetapi hanya jika cuaca cukup hangat.
Dalam hal penyewaan sepeda, Anda mungkin mengharapkan interaksi antara suhu dan hari kerja.

Bagaimana kita bisa mendapatkan model linier untuk memasukkan interaksi?
Sebelum Anda menyesuaikan model linier, tambahkan kolom ke matriks fitur yang mewakili interaksi antara fitur dan sesuaikan model seperti biasa.
Solusinya elegan, karena tidak memerlukan perubahan model linier, hanya kolom tambahan dalam data.
Dalam contoh hari kerja dan suhu, kami akan menambahkan fitur baru yang memiliki nol untuk hari tidak bekerja, selain itu memiliki nilai fitur suhu, dengan asumsi bahwa hari kerja adalah kategori referensi.
Misalkan data kita terlihat seperti ini:

```{r data-frame}
x = data.frame(work = c("Y", "N", "N", "Y"), temp = c(25, 12, 30, 5))
knitr::kable(x)
```

Matriks data yang digunakan oleh model linier terlihat sedikit berbeda.
Tabel berikut menunjukkan seperti apa data yang disiapkan untuk model jika kita tidak menentukan interaksi apa pun.
Biasanya, transformasi ini dilakukan secara otomatis oleh perangkat lunak statistik apa pun.

```{r data-frame-lm-no-interaction}
mod = lm(1:4 ~ ., data = x)
model.tab = data.frame(model.matrix(mod))
colnames(model.tab)[1] = "Intercept"
knitr::kable(model.tab)
```

Kolom pertama adalah istilah intersep.
Kolom kedua mengkodekan fitur kategoris, dengan 0 untuk kategori referensi dan 1 untuk yang lain.
Kolom ketiga berisi suhu.

Jika kita ingin model linier mempertimbangkan interaksi antara suhu dan fitur hari kerja, kita harus menambahkan kolom untuk interaksi:

```{r data-frame-lm}
mod = lm(1:4 ~ work * temp, data = x)
model.tab = data.frame(model.matrix(mod))
colnames(model.tab)[1] = "Intercept"
knitr::kable(model.tab)
```

Kolom baru "workY.temp" menangkap interaksi antara fitur hari kerja (kerja) dan suhu (temp).
Kolom fitur baru ini adalah nol untuk instans jika fitur kerja berada pada kategori referensi ("N" tanpa hari kerja), jika tidak, ia mengasumsikan nilai fitur suhu instans.
Dengan jenis pengkodean ini, model linier dapat mempelajari efek linier yang berbeda dari suhu untuk kedua jenis hari.
Ini adalah efek interaksi antara dua fitur.
Tanpa istilah interaksi, efek gabungan dari fitur kategoris dan numerik dapat dijelaskan dengan garis yang digeser secara vertikal untuk kategori yang berbeda.
Jika kami memasukkan interaksi, kami mengizinkan efek fitur numerik (kemiringan) memiliki nilai yang berbeda di setiap kategori.

Interaksi dua fitur kategoris bekerja dengan cara yang sama.
Kami membuat fitur tambahan yang mewakili kombinasi kategori.
Berikut adalah beberapa data buatan yang berisi hari kerja (kerja) dan fitur cuaca kategoris (wthr):

```{r data-frame-lm-cat}
x = data.frame(work = c("Y", "N", "N", "Y"), wthr = c("2", "0", "1", "2"))
knitr::kable(x)
```

Selanjutnya, kami menyertakan istilah interaksi:

```{r data-frame-lm-cat2}
mod = lm(1:4 ~ work * wthr, data = x)
model.tab = data.frame(model.matrix(mod))
colnames(model.tab)[1] = c("Intercept")
knitr::kable(model.tab)
```

Kolom pertama berfungsi untuk memperkirakan intersep.
Kolom kedua adalah fitur kerja yang disandikan.
Kolom tiga dan empat adalah untuk fitur cuaca, yang memerlukan dua kolom karena Anda memerlukan dua bobot untuk menangkap efek untuk tiga kategori, salah satunya adalah kategori referensi.
Kolom lainnya menangkap interaksi.
Untuk setiap kategori dari kedua fitur (kecuali untuk kategori referensi), kami membuat kolom fitur baru yaitu 1 jika kedua fitur memiliki kategori tertentu, jika tidak 0.

Untuk dua fitur numerik, kolom interaksi bahkan lebih mudah dibuat:
Kami hanya mengalikan kedua fitur numerik.

Ada pendekatan untuk mendeteksi dan menambahkan istilah interaksi secara otomatis.
Salah satunya dapat ditemukan di [bab RuleFit](#rulefit).
Algoritme RuleFit pertama-tama menambang istilah interaksi dan kemudian memperkirakan model linear regression termasuk interaksi.

**Contoh**

Mari kita kembali ke [tugas prediksi sewa sepeda](#bike-data) yang telah kita modelkan di [bab model linier](#limo).
Kali ini, kami juga mempertimbangkan interaksi antara suhu dan fitur hari kerja.
Ini menghasilkan perkiraan bobot dan confidence intervals berikut.

```{r example-lm-interaction}
data(bike)
X = bike[bike.features.of.interest]
y = bike[,'cnt']
dat = cbind(X, y)

mod = lm(y ~ . + temp * workingday, data = dat, x = TRUE)
lm_summary = summary(mod)$coefficients

lm_summary_print = lm_summary
rownames(lm_summary_print) = pretty_rownames(rownames(lm_summary_print))

# var name becomes to long otherwise
rownames(lm_summary_print)[rownames(lm_summary_print) == "weathersitRAIN/SNOW/STORM"] = "weathersitRAIN/..."
kable(cbind(lm_summary_print[,c('Estimate', 'Std. Error')], confint(mod)), digits = 1, col.names = c('Weight', 'Std. Error', "2.5%","97.5%"))
```

Efek interaksi tambahan negatif (`r round(lm_summary_print['workingdayWORKING DAY:temp','Estimate'], 1)`) dan berbeda secara signifikan dari nol, seperti yang ditunjukkan oleh confidence intervals 95%, yang tidak tidak termasuk nol.
Omong-omong, datanya tidak iid, karena hari-hari yang dekat satu sama lain tidak independen satu sama lain.
confidence intervals mungkin menyesatkan, ambil saja dengan sebutir garam.
Istilah interaksi mengubah interpretasi bobot fitur yang terlibat.
Apakah suhu memiliki efek negatif mengingat ini adalah hari kerja?
Jawabannya tidak, bahkan jika tabel menyarankannya kepada pengguna yang tidak terlatih.
Kami tidak dapat menginterpretasikan bobot interaksi "workingdayWORKING DAY:temp" secara terpisah, karena interpretasinya adalah:
"Sambil membiarkan semua nilai fitur lainnya tidak berubah, meningkatkan efek interaksi suhu untuk hari kerja akan menurunkan jumlah sepeda yang diprediksi."
Tetapi efek interaksi hanya menambah efek utama suhu.
Misalkan ini adalah hari kerja dan kita ingin tahu apa yang akan terjadi jika suhu 1 derajat lebih hangat hari ini.
Kemudian kita perlu menjumlahkan bobot untuk "temp" dan "workingdayWORKING DAY:temp" untuk menentukan seberapa besar peningkatan perkiraan.

Lebih mudah untuk memahami interaksi secara visual.
Dengan memperkenalkan istilah interaksi antara fitur kategoris dan numerik, kami mendapatkan dua kemiringan untuk suhu, bukan satu.
Kemiringan suhu untuk hari-hari di mana orang tidak harus bekerja ('NO WORKING DAY') dapat dibaca langsung dari tabel (`r round(lm_summary_print['temp','Estimate'], 1)`).
Kemiringan suhu untuk hari-hari di mana orang harus bekerja ('WORKING DAY') adalah jumlah dari kedua bobot suhu (`r round(lm_summary_print['temp','Estimate'], 1)`  `r round(lm_summary_print['workingdayWORKING DAY:temp','Estimate'], 1)` = `r round(lm_summary_print['temp','Estimate'], 1) + round(lm_summary_print['workingdayWORKING DAY:temp','Estimate'], 1)`).
Perpotongan garis 'NO WORKING DAY' pada suhu = 0 ditentukan oleh suku intersep dari model linier (`r round(lm_summary_print['(Intercept)','Estimate'], 1)`).
Intersep garis 'WORKING DAY' pada suhu = 0 ditentukan oleh istilah intersep + efek hari kerja (`r round(lm_summary_print['(Intercept)','Estimate'], 1)` + `r round(lm_summary_print['workingdayWORKING DAY','Estimate'], 1)` = `r round(lm_summary_print['(Intercept)','Estimate'], 1) + round(lm_summary_print['workingdayWORKING DAY','Estimate'], 1)`).

```{r interaction-plot, fig.cap = "The effect (including interaction) of temperature and working day on the predicted number of bikes for a linear model. Effectively, we get two slopes for the temperature, one for each category of the working day feature."}
interactions::interact_plot(mod, pred = "temp", modx = "workingday")
```

### Nonlinear Effects - GAMs {#gam}


**Dunia ini tidak linier.**
Linearitas dalam model linier berarti bahwa tidak peduli berapa nilai sebuah instance dalam fitur tertentu, peningkatan nilai satu unit selalu memiliki efek yang sama pada hasil yang diprediksi.
Apakah masuk akal untuk berasumsi bahwa peningkatan suhu satu derajat pada 10 derajat Celcius memiliki efek yang sama pada jumlah sepeda sewaan dengan peningkatan suhu ketika sudah mencapai 40 derajat?
Secara intuitif, orang berharap bahwa peningkatan suhu dari 10 menjadi 11 derajat Celcius memiliki efek positif pada persewaan sepeda dan dari 40 menjadi 41 efek negatif, yang juga terjadi, seperti yang akan Anda lihat, dalam banyak contoh di seluruh buku ini.
Fitur suhu memiliki efek positif linier pada jumlah sepeda sewaan, tetapi di beberapa titik mendatar dan bahkan memiliki efek negatif pada suhu tinggi.
Model linier tidak peduli, ia akan dengan patuh menemukan bidang linier terbaik (dengan meminimalkan jarak Euclidean).

Anda dapat memodelkan hubungan nonlinier menggunakan salah satu teknik berikut:

- Transformasi sederhana dari fitur (misalnya logaritma)
- Kategorisasi fitur
- Generalized Additive Models (GAM)

Sebelum saya masuk ke rincian masing-masing metode, mari kita mulai dengan contoh yang menggambarkan ketiganya.
Saya mengambil [dataset sewa sepeda](#bike-data) dan melatih model linier dengan hanya fitur suhu untuk memprediksi jumlah sepeda sewaan.
Gambar berikut menunjukkan perkiraan kemiringan dengan: model linier standar, model linier dengan transformasi suhu (logaritma), model linier dengan suhu yang diperlakukan sebagai fitur kategoris dan menggunakan regresi splines (GAM).

```{r nonlinear-effects, fig.cap = "Predicting the number of rented bicycles using only the temperature feature. A linear model (top left) does not fit the data well. One solution is to transform the feature with e.g. the logarithm (top right), categorize it (bottom left), which is usually a bad decision, or use Generalized Additive Models that can automatically fit a smooth curve for temperature (bottom right)."}
mod.simpel = lm(cnt ~ temp, data = bike)
bike.plt = bike
bike.plt$pred.lm = predict(mod.simpel)

bike.plt$log.temp = log(bike$temp + 10)
mod.simpel = lm(cnt ~ log.temp, data = bike.plt)
bike.plt$pred.sqrt = predict(mod.simpel)

bike.plt$cat.temp = cut(bike$temp, breaks = seq(from = min(bike$temp), to = max(bike$temp), length.out = 10), include.lowest = TRUE)
mod.simpel = lm(cnt ~ cat.temp, data = bike.plt)
bike.plt$pred.cat = predict(mod.simpel)

library(mgcv)
mod.gam = gam(cnt ~ s(temp), data = bike)
bike.plt$pred.gam = predict(mod.gam)


bike.plt = data.table::melt(bike.plt[c("pred.lm", "pred.sqrt", "pred.cat", "pred.gam")])
bike.plt$temp = rep(bike$temp, times = 4)
bike.plt$cnt = rep(bike$cnt, times = 4)

model.type = c(pred.lm = "Linear model", 
  pred.sqrt = "Linear model with log(temp + 10)", 
  pred.cat = "Linear model with categorized temp", 
  pred.gam = "GAM")

ggplot(bike.plt) + 
  geom_point(aes(x = temp, y = cnt), size = 1 , alpha = 0.3)  + 
  geom_line(aes(x = temp, y = value), size = 1.2, color = "blue") + 
  facet_wrap("variable", labeller = labeller(variable = model.type)) + 
  scale_x_continuous("Temperature (temp)") + 
  scale_y_continuous("(Predicted) Number of rented bikes")
```


**Transformasi fitur**

Seringkali logaritma fitur digunakan sebagai transformasi.
Menggunakan logaritma menunjukkan bahwa setiap kenaikan suhu 10 kali lipat memiliki efek linier yang sama pada jumlah sepeda, jadi perubahan dari 1 derajat Celcius ke 10 derajat Celcius memiliki efek yang sama dengan perubahan dari 0,1 ke 1 (kedengarannya salah).
Contoh lain untuk transformasi fitur adalah akar kuadrat, fungsi kuadrat dan fungsi eksponensial.
Menggunakan transformasi fitur berarti Anda mengganti kolom fitur ini dalam data dengan fungsi fitur, seperti logaritma, dan menyesuaikan model linier seperti biasa.
Beberapa program statistik juga memungkinkan Anda untuk menentukan transformasi dalam panggilan model linier.
Anda bisa menjadi kreatif saat mengubah fitur.
Interpretasi fitur berubah sesuai dengan transformasi yang dipilih.
Jika Anda menggunakan transformasi log, interpretasi dalam model linier menjadi:
"Jika logaritma fitur bertambah satu, prediksi bertambah dengan bobot yang sesuai."
Ketika Anda menggunakan GLM dengan fungsi tautan yang bukan fungsi identitas, maka interpretasinya menjadi lebih rumit, karena Anda harus memasukkan kedua transformasi ke dalam interpretasi (kecuali ketika mereka saling membatalkan, seperti log dan exp, maka interpretasinya menjadi lebih mudah).

**Kategorisasi fitur**

Kemungkinan lain untuk mencapai efek nonlinier adalah dengan mendiskritisasi fitur; mengubahnya menjadi fitur kategoris.
Misalnya, Anda dapat memotong fitur suhu menjadi 20 interval dengan level [-10, -5), [-5, 0), ... dan seterusnya.
Saat Anda menggunakan suhu yang dikategorikan dan bukan suhu kontinu, model linier akan memperkirakan fungsi langkah karena setiap tingkat mendapatkan perkiraannya sendiri.
Masalah dengan pendekatan ini adalah bahwa ia membutuhkan lebih banyak data, lebih mungkin untuk overfit dan tidak jelas bagaimana mendiskritkan fitur secara bermakna (interval atau kuantil yang sama? berapa banyak interval?).
Saya hanya akan menggunakan diskritisasi jika ada kasus yang sangat kuat untuk itu.
Misalnya, untuk membuat model yang sebanding dengan penelitian lain.

**Generalized Additive Models (GAM)**
Mengapa tidak 'hanya' mengizinkan model linier (umum) untuk mempelajari hubungan nonlinier?
Itulah motivasi di balik GAM.
GAM melonggarkan batasan bahwa hubungan harus berupa penjumlahan berbobot sederhana, dan sebaliknya berasumsi bahwa hasilnya dapat dimodelkan dengan jumlah fungsi arbitrer dari setiap fitur.
Secara matematis, hubungan dalam GAM terlihat seperti ini:

$$g(E_Y(y|x))=\beta_0+f_1(x_{1})+f_2(x_{2})+\ldots+f_p(x_{p})$$

Rumusnya mirip dengan rumus GLM dengan perbedaan bahwa suku linier $\beta_j{}x_{j}$ diganti dengan fungsi yang lebih fleksibel $f_j(x_{j})$.
Inti dari GAM masih merupakan gabungan dari efek fitur, tetapi Anda memiliki opsi untuk mengizinkan hubungan nonlinier antara beberapa fitur dan output.
Efek linier juga dicakup oleh kerangka kerja, karena agar fitur ditangani secara linier, Anda dapat membatasi $f_j(x_{j})$ hanya untuk mengambil bentuk $x_{j}\beta_j$.

Pertanyaan besarnya adalah bagaimana mempelajari fungsi nonlinier.
Jawabannya disebut "splines" atau "fungsi spline".
Splines adalah fungsi yang dapat digabungkan untuk mendekati fungsi arbitrer.
Sedikit seperti menumpuk batu bata Lego untuk membangun sesuatu yang lebih kompleks.
Ada sejumlah cara yang membingungkan untuk mendefinisikan fungsi spline ini.
Jika Anda tertarik untuk mempelajari lebih lanjut tentang semua cara untuk mendefinisikan splines, semoga Anda beruntung dalam perjalanan Anda.
Saya tidak akan membahas detailnya di sini, saya hanya akan membangun intuisi.
Apa yang secara pribadi paling membantu saya untuk memahami splines adalah memvisualisasikan masing-masing fungsi spline dan melihat bagaimana matriks data dimodifikasi.
Misalnya, untuk memodelkan suhu dengan splines, kami menghapus fitur suhu dari data dan menggantinya dengan, katakanlah, 4 kolom, masing-masing mewakili fungsi spline.
Biasanya Anda akan memiliki lebih banyak fungsi spline, saya hanya mengurangi jumlahnya untuk tujuan ilustrasi.
Nilai untuk setiap instans fitur spline baru ini bergantung pada nilai suhu instans.
Bersama dengan semua efek linier, GAM kemudian juga memperkirakan bobot spline ini.
GAM juga memperkenalkan istilah penalty untuk bobot agar tetap mendekati nol.
Ini secara efektif mengurangi fleksibilitas splines dan mengurangi overfitting.
Parameter kelancaran yang biasanya digunakan untuk mengontrol fleksibilitas kurva kemudian disetel melalui validasi silang.
Mengabaikan istilah penalti, pemodelan nonlinier dengan splines adalah rekayasa fitur mewah.

Dalam contoh di mana kami memprediksi jumlah sepeda dengan GAM hanya menggunakan suhu, matriks fitur model terlihat seperti ini:

```{r splines-df}
# fit GAM again with less splines
mod.gam = gam(cnt ~ s(temp, k = 5), data = bike)
kable(head(model.matrix(mod.gam)), digits = 2)
```

Setiap baris mewakili contoh individual dari data (satu hari).
Setiap kolom spline berisi nilai fungsi spline pada nilai suhu tertentu.
Gambar berikut menunjukkan bagaimana fungsi spline ini terlihat:

```{r splines, fig.cap = "To smoothly model the temperature effect, we use 4 spline functions. Each temperature value is mapped to (here) 4 spline values. If an instance has a temperature of 30 °C, the value for the first spline feature is -1, for the second 0.7, for the third -0.8 and for the 4th 1.7."}

mm = model.matrix(mod.gam)
mm2 = data.table::melt(mm)
mm2 = mm2[mm2$Var2 != "(Intercept)",]

ggplot(mm2) + geom_line(aes(x = rep(bike$temp, times = 4), y = value)) + facet_wrap("Var2") + 
  scale_x_continuous("Temperature") + 
  scale_y_continuous("Value of spline feature")
```

GAM memberikan bobot untuk setiap fitur spline suhu:

```{r splines-weights}
kable(coef(mod.gam), digits = 2, col.names = "weight")
```

Dan kurva sebenarnya, yang dihasilkan dari penjumlahan fungsi spline yang dibobot dengan bobot yang diperkirakan, terlihat seperti ini:

```{r splines-curve, fig.cap = "GAM feature effect of the temperature for predicting the number of rented bikes (temperature used as the only feature)."}
plot(mod.gam)
```


Interpretasi efek halus memerlukan pemeriksaan visual dari kurva yang dipasang.
Splines biasanya berpusat di sekitar prediksi rata-rata, jadi titik pada kurva adalah perbedaan dengan prediksi rata-rata.
Misalnya, pada 0 derajat Celcius, jumlah sepeda yang diprediksi 3000 lebih rendah dari prediksi rata-rata.


### Advantages

Semua perluasan model linier ini adalah bagian dari alam semesta itu sendiri.
Masalah apa pun yang Anda hadapi dengan model linier, **Anda mungkin akan menemukan ekstensi yang memperbaikinya**.

Sebagian besar metode telah digunakan selama beberapa dekade.
Misalnya, usia GAM hampir 30 tahun.
Banyak peneliti dan praktisi dari industri sangat **berpengalaman** dengan model linier dan metodenya **diterima di banyak komunitas sebagai status quo untuk pemodelan**.

Selain membuat prediksi, Anda dapat menggunakan model untuk **melakukan inferensi**, menarik kesimpulan tentang data -- mengingat asumsi model tidak dilanggar.
Anda mendapatkan confidence intervals untuk bobot, uji signifikansi, interval prediksi, dan banyak lagi.

Perangkat lunak statistik biasanya memiliki antarmuka yang sangat bagus agar sesuai dengan GLM, GAM, dan model linier yang lebih khusus.

Opacity dari banyak model machine learning berasal dari 1) kurangnya sparseness, yang berarti banyak fitur yang digunakan, 2) fitur yang diperlakukan secara nonlinier, yang berarti Anda memerlukan lebih dari satu bobot untuk menggambarkan efeknya, dan 3) pemodelan interaksi antar fitur.
Dengan asumsi bahwa model linier sangat dapat diinterpretasikan tetapi seringkali tidak sesuai dengan kenyataan, ekstensi yang dijelaskan dalam bab ini menawarkan cara yang baik untuk mencapai **transisi mulus ke model yang lebih fleksibel**, sambil mempertahankan beberapa interpretasi.

### Disadvantages

Sebagai keuntungan saya telah mengatakan bahwa model linier hidup di alam semesta mereka sendiri.
**Banyaknya cara Anda dapat memperluas model linier sederhana sangat banyak**, tidak hanya untuk pemula.
Sebenarnya, ada beberapa alam semesta paralel, karena banyak komunitas peneliti dan praktisi memiliki nama mereka sendiri untuk metode yang melakukan hal yang kurang lebih sama, yang bisa sangat membingungkan.

Sebagian besar modifikasi model linier membuat model **kurang dapat diinterpretasikan**.
Setiap fungsi tautan (dalam GLM) yang bukan merupakan fungsi identitas memperumit interpretasi;
interaksi juga memperumit interpretasi;
efek fitur nonlinier kurang intuitif (seperti transformasi log) atau tidak lagi dapat diringkas dengan satu angka (misalnya fungsi spline).

GLM, GAM, dan sebagainya **bergantung pada asumsi** tentang proses pembuatan data.
Jika itu dilanggar, interpretasi bobot tidak berlaku lagi.

Kinerja ansambel berbasis pohon seperti random forest atau gradient tree boosting dalam banyak kasus lebih baik daripada model linier paling canggih.
Ini sebagian adalah pengalaman saya sendiri dan sebagian pengamatan dari model pemenang di platform seperti kaggle.com.


### Software

Semua contoh dalam bab ini dibuat menggunakan bahasa R.
Untuk GAM, paket `gam` digunakan, tetapi masih banyak lagi.
R memiliki jumlah paket yang luar biasa untuk memperluas model linear regression.
Tak tertandingi oleh bahasa analitik lainnya, R adalah rumah bagi setiap ekstensi yang mungkin dari ekstensi model linear regression.
Anda akan menemukan implementasi mis. GAM dengan Python (seperti [pyGAM](https://github.com/dswah/pyGAM)), tetapi implementasi ini belum matang.


### Further Extensions {#more-lm-extension}

Seperti yang dijanjikan, berikut adalah daftar masalah yang mungkin Anda temui dengan model linier, bersama dengan nama solusi untuk masalah ini yang dapat Anda salin dan tempel ke mesin pencari favorit Anda.

Data saya melanggar asumsi independen dan terdistribusi secara identik (iid).
Misalnya, pengukuran berulang pada pasien yang sama.
Telusuri **mixed models** atau **generalized estimating equations**.

Model saya memiliki kesalahan heteroskedastis.
Misalnya, ketika memprediksi nilai rumah, kesalahan model biasanya lebih tinggi di rumah mahal, yang melanggar homoskedastisitas model linier.
Telusuri **robust regression**.

Saya memiliki outlier yang sangat mempengaruhi model saya.
Telusuri **robust regression**.

Saya ingin memprediksi waktu sampai suatu peristiwa terjadi.
Data waktu-ke-peristiwa biasanya dilengkapi dengan pengukuran yang disensor, yang berarti bahwa untuk beberapa kasus tidak ada cukup waktu untuk mengamati peristiwa tersebut.
Misalnya, sebuah perusahaan ingin memprediksi kegagalan mesin esnya, tetapi hanya memiliki data selama dua tahun.
Beberapa mesin masih utuh setelah dua tahun, tetapi mungkin gagal nanti.
Telusuri **parametric survival models**, **cox regression**, **survival analysis**.

Hasil prediksi saya adalah sebuah kategori.
Jika hasilnya memiliki dua kategori, gunakan [logistic regression model](#logistic), yang memodelkan probabilitas untuk kategori tersebut.
Jika Anda memiliki lebih banyak kategori, telusuri **multinomial regression**.
logistic regression dan multinomial regression keduanya merupakan GLM.

Saya ingin memprediksi kategori yang dipesan.
Misalnya nilai sekolah.
Telusuri **proportional odds model**.

Hasil saya adalah hitungan (seperti jumlah anak dalam keluarga).
Telusuri **Poisson regression**.
Model Poisson juga merupakan GLM.
Anda mungkin juga memiliki masalah bahwa nilai hitungan 0 sangat sering.
Telusuri **zero-inflated Poisson regression**, **hurdle model**.

Saya tidak yakin fitur apa yang perlu dimasukkan dalam model untuk menarik kesimpulan kausal yang benar.
Misalnya, saya ingin mengetahui pengaruh obat terhadap tekanan darah.
Obat memiliki efek langsung pada beberapa nilai darah dan nilai darah ini mempengaruhi hasilnya.
Haruskah saya memasukkan nilai darah ke dalam regression models?
Telusuri **causal inference**, **mediation analysis**.

Saya memiliki data yang hilang.
Telusuri **multiple imputation**.

Saya ingin mengintegrasikan pengetahuan sebelumnya ke dalam model saya.
Telusuri **Bayesian inference**.

Saya merasa agak down akhir-akhir ini.
Cari **"Amazon Alexa Gone Wild!!! Versi lengkap dari awal hingga akhir"**.
