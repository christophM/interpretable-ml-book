```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## Accumulated Local Effects (ALE) Plot {#ale}

Accumulated local effects[^ALE] menjelaskan bagaimana fitur memengaruhi prediksi model machine learning secara rata-rata.
Plot ALE adalah alternatif yang lebih cepat dan tidak bias untuk partial dependence plot (PDP).

Saya sarankan membaca [bab tentang partial dependence plot](#pdp) terlebih dahulu, karena lebih mudah dipahami dan kedua metode memiliki tujuan yang sama:
Keduanya menggambarkan bagaimana fitur mempengaruhi prediksi secara rata-rata.
Di bagian berikut, saya ingin meyakinkan Anda bahwa partial dependence plot memiliki masalah serius ketika fitur-fiturnya dikorelasikan.


### Motivation and Intuition

Jika fitur model machine learning berkorelasi, partial dependence plot tidak dapat dipercaya.
Perhitungan partial dependence plot untuk fitur yang sangat berkorelasi dengan fitur lain melibatkan prediksi rata-rata dari contoh data buatan yang tidak mungkin dalam kenyataan.
Ini dapat sangat membiaskan perkiraan efek fitur.
Bayangkan menghitung partial dependence plot untuk model machine learning yang memprediksi nilai sebuah rumah tergantung pada jumlah kamar dan ukuran ruang tamu.
Kami tertarik pada efek ruang tamu pada p-valuerediksi.
Sebagai pengingat, resep untuk partial dependence plot adalah: 1) Pilih fitur. 2) Tentukan kisi-kisi. 3) Per grid value: a) Ganti fitur dengan nilai grid dan b) prediksi rata-rata. 4) Menggambar kurva.
Untuk penghitungan nilai grid pertama PDP -- katakanlah 30 m^2^ -- kami mengganti ruang tamu untuk **semua** instance dengan 30 m^2^, bahkan untuk rumah dengan 10 kamar.
Kedengarannya bagi saya seperti rumah yang sangat tidak biasa.
Partial dependence plot memasukkan rumah-rumah yang tidak realistis ini dalam estimasi efek fitur dan berpura-pura bahwa semuanya baik-baik saja.
Gambar berikut mengilustrasikan dua fitur yang berkorelasi dan bagaimana metode partial dependence plot rata-rata memprediksi kejadian yang tidak mungkin terjadi.

```{r aleplot-motivation1, fig.cap = "Strongly correlated features x1 and x2. To calculate the feature effect of x1 at 0.75, the PDP replaces x1 of all instances with 0.75, falsely assuming that the distribution of x2 at x1 = 0.75 is the same as the marginal distribution of x2 (vertical line). This results in unlikely combinations of x1 and x2 (e.g. x2=0.2 at x1=0.75), which the PDP uses for the calculation of the average effect."}

set.seed(1)
n = 100
intercept = 0.75

x1 = runif(n)
x2 = x1 + rnorm(n, sd = 0.1)
df = data.frame(x1, x2)  

p = ggplot(df) + geom_point(aes(x = x1, y = x2)) +  
  theme(panel.grid.major.y = element_blank(), 
    panel.grid.minor.y = element_blank(), 
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank())

p.int = p + geom_vline(xintercept = intercept)
x1.dens = density(x1)
x1.dens.df = data.frame(dens = x1.dens$y, x = x1.dens$x)


p1 = p.int + geom_path(data = x1.dens.df, aes(x = intercept - dens/10, y = x)) + 
  ggtitle(sprintf("Marginal distribution P(x2)", intercept)) + 
  scale_y_continuous(limits = c(-0.2, 1.2))
p1
```

Apa yang bisa kita lakukan untuk mendapatkan perkiraan efek fitur yang menghormati korelasi fitur?
Kami dapat merata-ratakan distribusi bersyarat dari fitur, yang berarti pada nilai kisi x1, kami merata-ratakan prediksi instance dengan nilai x1 yang serupa.
Solusi untuk menghitung efek fitur menggunakan distribusi bersyarat disebut Marginal Plots, atau M-Plot (nama yang membingungkan, karena didasarkan pada distribusi bersyarat, bukan distribusi marjinal).
Tunggu, bukankah aku berjanji untuk membicarakan plot ALE?
M-Plots bukanlah solusi yang kami cari.
Mengapa M-Plots tidak menyelesaikan masalah kita?
Jika kita rata-ratakan prediksi semua rumah sekitar 30 m^2^, kita memperkirakan efek **gabungan** dari ruang tamu dan jumlah kamar, karena korelasinya.
Misalkan ruang tamu tidak berpengaruh pada nilai prediksi sebuah rumah, hanya jumlah kamar yang berpengaruh.
M-Plot masih akan menunjukkan bahwa ukuran ruang tamu meningkatkan nilai prediksi, karena jumlah kamar meningkat dengan ruang tamu.
Plot berikut menunjukkan dua fitur berkorelasi bagaimana M-Plots bekerja.

```{r aleplot-motivation2, fig.cap = "Strongly correlated features x1 and x2. M-Plots average over the conditional distribution. Here the conditional distribution of x2 at x1 = 0.75. Averaging the local predictions leads to mixing the effects of both features."}

set.seed(1)
n = 100
intercept = 0.75

x1 = runif(n)
x2 = x1 + rnorm(n, sd = 0.1)
df = data.frame(x1, x2)  

p = ggplot(df) + geom_point(aes(x = x1, y = x2)) +  
  theme(panel.grid.major.y = element_blank(), 
    panel.grid.minor.y = element_blank(), 
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank())

p.int = p + geom_vline(xintercept = intercept)
x1.dens = density(x1)
x1.dens.df = data.frame(dens = x1.dens$y, x = x1.dens$x)


p1 = p.int + geom_path(data = x1.dens.df, aes(x = intercept - dens/10, y = x)) + 
  ggtitle(sprintf("Marginal distribution p(x2)", intercept)) + 
  scale_y_continuous(limits = c(-0.2, 1.2))

x1.dens.ale = density(x1[(x1 > (intercept - 0.1)) & (x1 < (intercept + 0.1))])
x1.dens.ale.df = data.frame(dens = x1.dens.ale$y, x = x1.dens.ale$x)

p2 = p.int + geom_path(data = x1.dens.ale.df, aes(x = intercept - dens/20, y = x)) + 
  ggtitle(sprintf("Conditional distribution P(x2|x1=%.2f)", intercept)) + 
  scale_y_continuous(limits = c(-0.2, 1.2))
p2
```


M-Plots menghindari prediksi rata-rata dari instance data yang tidak mungkin, tetapi mereka menggabungkan efek fitur dengan efek dari semua fitur yang berkorelasi.
Plot ALE memecahkan masalah ini dengan menghitung -- juga berdasarkan distribusi bersyarat dari fitur -- **perbedaan dalam prediksi dan bukan rata-rata**.
Untuk pengaruh luas tempat tinggal pada 30 m^2^, metode ALE menggunakan semua rumah dengan sekitar 30 m^2^, mendapatkan prediksi model dengan menganggap rumah-rumah ini adalah 31 m^2^ dikurangi prediksi yang berpura-pura 29 m^2 ^.
Ini memberi kita efek murni dari ruang tamu dan tidak mencampur efek dengan efek fitur yang berkorelasi.
Penggunaan perbedaan menghalangi efek fitur lain.
Grafik berikut memberikan intuisi bagaimana plot ALE dihitung.


```{r aleplot-computation, fig.cap = "Calculation of ALE for feature x1, which is correlated with x2. First, we divide the feature into intervals (vertical lines). For the data instances (points) in an interval, we calculate the difference in the prediction when we replace the feature with the upper and lower limit of the interval (horizontal lines). These differences are later accumulated and centered, resulting in the ALE curve."}

set.seed(12)
n = 25

x1 = runif(n)
x2 = x1 + rnorm(n, sd = 0.1)
df = data.frame(x1, x2)  

p = ggplot(df) + geom_point(aes(x = x1, y = x2)) +
  theme(panel.grid.major.y = element_blank(), 
    panel.grid.minor.y = element_blank(), 
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank()) 


grid.df = data.frame(x1 = seq(from = 0,  to = 1, length.out = 6)[1:6], x2 = NA)
label.df = grid.df[1:5,]
label.df$x1 = label.df$x1 + 0.1
label.df$x2 = 0.95
label.df$label = sprintf("N1(%i)", 1:5)

break.labels = c(expression(z[0~","~1]),  expression(z[1~","~1]), expression(z[2~","~1]), expression(z[3~","~1]),
  expression(z[4~","~1]), expression(z[5~","~1]))

diff.df = df[df$x1 <= 0.8 & df$x1 > 0.6, ]

p + geom_vline(data = grid.df, aes(xintercept = x1), linetype = 3) + 
  scale_x_continuous(breaks = seq(from = 0,  to = 1, length.out = 6), limits = c(0, 1), labels = break.labels) + 
  geom_label(data = label.df, aes(x = x1, y = x2, label = label)) + 
  geom_segment(data = diff.df, aes(x = 0.6, xend = 0.8, y = x2, yend  = x2), arrow = arrow(ends = "both", angle = 90, length = unit(0.07, "inches")))
```


Untuk meringkas bagaimana setiap jenis plot (PDP, M, ALE) menghitung efek fitur pada nilai grid tertentu v:
**partial dependence plot**: "Biarkan saya menunjukkan kepada Anda apa yang diprediksi model secara rata-rata ketika setiap instance data memiliki nilai v untuk fitur itu.
Saya mengabaikan apakah nilai v masuk akal untuk semua instance data."
**M-Plots**: "Biarkan saya menunjukkan kepada Anda apa yang diprediksi model rata-rata untuk instance data yang memiliki nilai mendekati v untuk fitur tersebut.
Efeknya bisa karena fitur itu, tetapi juga karena fitur yang berkorelasi."
**ALE plot**: "Biarkan saya menunjukkan kepada Anda bagaimana prediksi model berubah di "jendela" kecil fitur di sekitar v untuk instance data di jendela itu."

### Theory

Bagaimana plot PD, M dan ALE berbeda secara matematis?
Umum untuk ketiga metode adalah bahwa mereka mengurangi fungsi prediksi kompleks f menjadi fungsi yang hanya bergantung pada satu (atau dua) fitur.
Ketiga metode tersebut mengurangi fungsi dengan merata-ratakan efek fitur lainnya, tetapi mereka berbeda dalam apakah rata-rata prediksi atau **perbedaan prediksi** dihitung dan apakah rata-rata dilakukan pada distribusi marjinal atau bersyarat.

Partial dependence plot rata-rata prediksi atas distribusi marjinal.

$$\begin{align*}\hat{f}_{x_S,PDP}(x_S)&=E_{X_C}\left[\hat{f}(x_S,X_C)\right]\\&=\int_{x_C}\hat{f}(x_S,x_C)\mathbb{P}(x_C)d{}x_C\end{align*}$$

Ini adalah nilai fungsi prediksi f, pada nilai fitur $x_S$, dirata-ratakan untuk semua fitur di $x_C$.
Rata-rata berarti menghitung ekspektasi marginal E atas fitur-fitur di himpunan C, yang merupakan integral dari prediksi yang dibobot oleh distribusi probabilitas.
Kedengarannya bagus, tetapi untuk menghitung nilai yang diharapkan atas distribusi marjinal, kami hanya mengambil semua contoh data kami, memaksa mereka untuk memiliki nilai grid tertentu untuk fitur di set S, dan rata-rata prediksi untuk dataset yang dimanipulasi ini.
Prosedur ini memastikan bahwa kita rata-rata atas distribusi marjinal fitur.

M-plot rata-rata prediksi atas distribusi bersyarat.

$$\begin{align*}\hat{f}_{x_S,M}(x_S)&=E_{X_C|X_S}\left[\hat{f}(X_S,X_C)|X_S=x_s\right]\\&=\int_{x_C}\hat{f}(x_S,x_C)\mathbb{P}(x_C|x_S)d{}x_C\end{align*}$$

Satu-satunya hal yang berubah dibandingkan dengan PDP adalah bahwa kami merata-ratakan prediksi bersyarat pada setiap nilai grid fitur yang diinginkan, daripada mengasumsikan distribusi marjinal pada setiap nilai grid.
Dalam prakteknya, ini berarti bahwa kita harus mendefinisikan sebuah lingkungan, misalnya untuk perhitungan pengaruh 30 m^2^ pada nilai rumah yang diprediksi, kita bisa rata-rata prediksi semua rumah antara 28 dan 32 m^2^.

Plot ALE rata-rata perubahan prediksi dan mengakumulasikannya di atas grid (lebih lanjut tentang perhitungan nanti).

$$\begin{align*}\hat{f}_{x_S,ALE}(x_S)=&\int_{z_{0,1}}^{x_S}E_{X_C|X_S}\left[\hat{f}^S(X_s,X_c)|X_S=z_S\right]dz_S-\text{constant}\\=&\int_{z_{0,1}}^{x_S}\int_{x_C}\hat{f}^S(z_s,x_c)\mathbb{P}(x_C|z_S)d{}x_C{}dz_S-\text{constant}\end{align*}$$

Rumus tersebut mengungkapkan tiga perbedaan pada M-Plots.
Pertama, kita rata-ratakan perubahan prediksi, bukan prediksi itu sendiri.
Perubahan didefinisikan sebagai gradien (tetapi kemudian, untuk perhitungan aktual, digantikan oleh perbedaan dalam prediksi selama interval).

$$\hat{f}^S(x_s,x_c)=\frac{\delta\hat{f}(x_S,x_C)}{\delta{}x_S}$$

Perbedaan kedua adalah integral tambahan atas z.
Kami mengumpulkan gradien lokal pada rentang fitur di set S, yang memberi kami efek fitur pada prediksi.
Untuk perhitungan aktual, z digantikan oleh kisi interval di mana kita menghitung perubahan dalam prediksi.
Alih-alih merata-ratakan prediksi secara langsung, metode ALE menghitung perbedaan prediksi yang bergantung pada fitur S dan mengintegrasikan turunan di atas fitur S untuk memperkirakan efeknya.
Yah, itu terdengar bodoh.
Turunan dan integrasi biasanya saling meniadakan, seperti mengurangkan dulu, lalu menjumlahkan bilangan yang sama.
Mengapa masuk akal di sini?
Turunan (atau perbedaan interval) mengisolasi efek dari fitur yang diinginkan dan memblokir efek dari fitur yang berkorelasi.

Perbedaan ketiga plot ALE dengan plot-M adalah bahwa kita mengurangi konstanta dari hasilnya.
Langkah ini memusatkan plot ALE sehingga efek rata-rata terhadap data adalah nol.

Satu masalah tetap:
Tidak semua model datang dengan gradien, misalnya random forest tidak memiliki gradien.
Tetapi seperti yang akan Anda lihat, perhitungan sebenarnya bekerja tanpa gradien dan menggunakan interval.
Mari kita mempelajari lebih dalam estimasi plot ALE.


### Estimation

Pertama saya akan menjelaskan bagaimana plot ALE diperkirakan untuk fitur numerik tunggal, kemudian untuk dua fitur numerik dan untuk fitur kategoris tunggal.
Untuk memperkirakan efek lokal, kami membagi fitur menjadi banyak interval dan menghitung perbedaan dalam prediksi.
Prosedur ini mendekati gradien dan juga berfungsi untuk model tanpa gradien.

Pertama kami memperkirakan efek tidak terpusat:

$$\hat{\tilde{f}}_{j,ALE}(x)=\sum_{k=1}^{k_j(x)}\frac{1}{n_j(k)}\sum_{i:x_{j}^{(i)}\in{}N_j(k)}\left[f(z_{k,j},x^{(i)}_{\setminus{}j})-f(z_{k-1,j},x^{(i)}_{\setminus{}j})\right]$$

Mari kita pecahkan rumus ini, mulai dari sisi kanan.
Nama **Accumulated Local Effects** dengan baik mencerminkan semua komponen individual dari formula ini.
Pada intinya, metode ALE menghitung perbedaan prediksi, dimana kita mengganti fitur yang diinginkan dengan nilai grid z.
Perbedaan dalam prediksi adalah **Efek** yang dimiliki fitur untuk masing-masing instance dalam interval tertentu.
Jumlah di sebelah kanan menjumlahkan efek dari semua kejadian dalam interval yang muncul dalam rumus sebagai lingkungan $N_j(k)$.
Kami membagi jumlah ini dengan jumlah kejadian dalam interval ini untuk mendapatkan perbedaan rata-rata prediksi untuk interval ini.
Rata-rata dalam interval ini dicakup oleh istilah **Local** dalam nama ALE.
Simbol jumlah kiri berarti bahwa kita mengumpulkan efek rata-rata di semua interval.
ALE (tidak terpusat) dari nilai fitur yang terletak, misalnya, pada interval ketiga adalah jumlah efek dari interval pertama, kedua, dan ketiga.
Kata **Accumulated** dalam ALE mencerminkan hal ini.

Efek ini terpusat sehingga efek rata-rata adalah nol.

$$\hat{f}_{j,ALE}(x)=\hat{\tilde{f}}_{j,ALE}(x)-\frac{1}{n}\sum_{i=1}^{n}\hat{\tilde{f}}_{j,ALE}(x^{(i)}_{j})$$

Nilai ALE dapat diartikan sebagai efek utama dari fitur pada nilai tertentu dibandingkan dengan rata-rata prediksi data.
Misalnya, perkiraan ALE -2 pada $x_j=3$ berarti ketika fitur ke-j memiliki nilai 3, maka prediksi lebih rendah 2 dibandingkan dengan prediksi rata-rata.

Kuantil dari distribusi fitur digunakan sebagai grid yang mendefinisikan interval.
Menggunakan kuantil memastikan bahwa ada jumlah instance data yang sama di setiap interval.
Kuantil memiliki kelemahan bahwa interval dapat memiliki panjang yang sangat berbeda.
Hal ini dapat menyebabkan beberapa plot ALE yang aneh jika fitur yang diinginkan sangat miring, misalnya banyak nilai rendah dan hanya sedikit nilai yang sangat tinggi.

**Plot ALE untuk interaksi dua fitur**

Plot ALE juga dapat menunjukkan efek interaksi dari dua fitur.
Prinsip perhitungannya sama seperti untuk fitur tunggal, tetapi kami bekerja dengan sel persegi, bukan interval, karena kami harus mengumpulkan efek dalam dua dimensi.
Selain menyesuaikan untuk efek rata-rata keseluruhan, kami juga menyesuaikan untuk efek utama dari kedua fitur tersebut.
Ini berarti bahwa ALE untuk dua fitur memperkirakan efek orde kedua, yang tidak termasuk efek utama dari fitur tersebut.
Dengan kata lain, ALE untuk dua fitur hanya menunjukkan efek interaksi tambahan dari kedua fitur tersebut.
Saya memberi Anda formula untuk plot ALE 2D karena panjang dan tidak enak dibaca.
Jika Anda tertarik dengan perhitungannya, saya merujuk Anda ke makalah, rumus (13) -- (16).
Saya akan mengandalkan visualisasi untuk mengembangkan intuisi tentang perhitungan ALE orde kedua.

```{r aleplot-computation-2d, fig.cap = 'Calculation of 2D-ALE. We place a grid over the two features. In each grid cell we calculate the 2nd-order differences for all instance within. We first replace values of x1 and x2 with the values from the cell corners. If a, b, c and d represent the "corner"-predictions of a manipulated instance (as labeled in the graphic), then the 2nd-order difference is (d - c) - (b - a). The mean 2nd-order difference in each cell is accumulated over the grid and centered.'}

p = ggplot(df) + geom_point(aes(x = x1, y = x2)) +
  theme(panel.grid.major.y = element_blank(), 
    panel.grid.minor.y = element_blank(), 
    panel.grid.major.x = element_blank(), 
    panel.grid.minor.x = element_blank()) 


grid.df1 = data.frame(x1 = seq(from = min(df$x1),  to = max(df$x1), length.out = 6)[1:6], x2 = NA)
grid.df2 = data.frame(x2 = seq(from = min(df$x2),  to = max(df$x2), length.out = 6)[1:6], x1 = NA)

chosen.tile = expand.grid(x1 = grid.df1$x1[4:5], x2 = grid.df2$x2[4:5])
chosen.tile2 = data.frame(x = grid.df1$x1[4], xend = grid.df1$x1[5], y = grid.df2$x2[4], yend = grid.df2$x2[5])

points.df =  df[df$x1 < grid.df1$x1[5] & df$x1 > grid.df1$x1[4] & df$x2 < grid.df2$x2[5] & df$x2 > grid.df2$x2[4], ]
mv.arr = 0.02
p + geom_vline(data = grid.df1, aes(xintercept = x1), linetype = 3) + 
  geom_hline(data = grid.df2, aes(yintercept = x2), linetype = 3) + 
  geom_rect(aes(xmin = x, xmax = xend,  ymin = y, ymax = yend), data = chosen.tile2, alpha = 0, color = "black", size = 1.1) +
  geom_label(data = chosen.tile, aes(x = x1, y = x2), label = letters[1:4]) + 
  geom_point(aes(x = x1, y = x2), data = points.df, size = 3)

```

Pada gambar sebelumnya, banyak sel kosong karena korelasi.
Dalam plot ALE ini dapat divisualisasikan dengan kotak abu-abu atau gelap.
Atau, Anda dapat mengganti perkiraan ALE yang hilang dari sel kosong dengan perkiraan ALE dari sel tidak kosong terdekat.

Karena estimasi ALE untuk dua fitur hanya menunjukkan efek orde kedua dari fitur, interpretasi memerlukan perhatian khusus.
Efek orde kedua adalah efek interaksi tambahan dari fitur setelah kami memperhitungkan efek utama dari fitur tersebut.
Misalkan dua fitur tidak berinteraksi, tetapi masing-masing memiliki efek linier pada hasil yang diprediksi.
Dalam plot ALE 1D untuk setiap fitur, kita akan melihat garis lurus sebagai kurva ALE yang diperkirakan.
Tetapi ketika kita memplot perkiraan ALE 2D, mereka harus mendekati nol, karena efek orde kedua hanya efek tambahan dari interaksi.
Plot ALE dan plot PD berbeda dalam hal ini:
PDP selalu menunjukkan efek total, plot ALE menunjukkan efek orde pertama atau kedua.
Ini adalah keputusan desain yang tidak bergantung pada matematika yang mendasarinya.
Anda dapat mengurangi efek orde rendah dalam partial dependence plot untuk mendapatkan efek orde kedua atau utama murni atau, Anda bisa mendapatkan perkiraan total plot ALE dengan menahan diri dari mengurangi efek orde rendah.

Accumulated local effects juga dapat dihitung untuk urutan yang lebih tinggi secara sewenang-wenang (interaksi tiga fitur atau lebih), tetapi seperti yang dijelaskan dalam [bab PDP](#pdp), hanya hingga dua fitur yang masuk akal, karena interaksi yang lebih tinggi tidak dapat divisualisasikan atau bahkan dimaknai secara bermakna.

**ALE untuk fitur kategoris**

Metode accumulated local effects membutuhkan - menurut definisi - nilai fitur untuk memiliki urutan, karena metode ini mengakumulasi efek dalam arah tertentu.
Fitur kategoris tidak memiliki tatanan alami.
Untuk menghitung plot ALE untuk fitur kategoris, kita harus membuat atau menemukan pesanan.
Urutan kategori mempengaruhi perhitungan dan interpretasi accumulated local effects.

Salah satu solusinya adalah mengurutkan kategori menurut kesamaannya berdasarkan fitur lainnya.
Jarak antara dua kategori adalah jumlah jarak setiap fitur.
Jarak fitur-bijaksana membandingkan distribusi kumulatif di kedua kategori, juga disebut jarak Kolmogorov-Smirnov (untuk fitur numerik) atau tabel frekuensi relatif (untuk fitur kategoris).
Setelah kami memiliki jarak antara semua kategori, kami menggunakan penskalaan multi-dimensi untuk mengurangi matriks jarak menjadi ukuran jarak satu dimensi.
Ini memberi kita urutan kategori berdasarkan kesamaan.

Untuk membuatnya sedikit lebih jelas, berikut adalah salah satu contohnya:
Mari kita asumsikan kita memiliki dua fitur kategoris "musim" dan "cuaca" dan fitur numerik "suhu".
Untuk fitur kategorikal pertama (musim) kami ingin menghitung ALE.
Fitur ini memiliki kategori "musim semi", "musim panas", "musim gugur", "musim dingin".
Kami mulai menghitung jarak antara kategori "musim semi" dan "musim panas".
Jarak adalah jumlah jarak atas fitur suhu dan cuaca.
Untuk suhu, kami mengambil semua contoh dengan musim "musim semi", menghitung fungsi distribusi kumulatif empiris dan melakukan hal yang sama untuk contoh dengan musim "musim panas" dan mengukur jaraknya dengan statistik Kolmogorov-Smirnov.
Untuk fitur cuaca, kami menghitung untuk semua kejadian "musim semi" probabilitas untuk setiap jenis cuaca, lakukan hal yang sama untuk kejadian "musim panas" dan jumlahkan jarak absolut dalam distribusi probabilitas.
Jika "musim semi" dan "musim panas" memiliki suhu dan cuaca yang sangat berbeda, jarak kategori totalnya besar.
Kami mengulangi prosedur dengan pasangan musiman lainnya dan mengurangi matriks jarak yang dihasilkan menjadi satu dimensi dengan penskalaan multi-dimensi.


### Examples

Mari kita lihat plot ALE beraksi.
Saya telah membangun sebuah skenario di mana partial dependence plot gagal.
Skenario terdiri dari model prediksi dan dua fitur yang sangat berkorelasi.
Model prediksi sebagian besar merupakan model linear regression, tetapi melakukan sesuatu yang aneh pada kombinasi dua fitur yang belum pernah kami amati.

```{r correlation-problem, fig.cap = "Two features and the predicted outcome. The model predicts the sum of the two features (shaded background), with the exception that if x1 is greater than 0.7 and x2 less than 0.3, the model always predicts 2. This area is far from the distribution of data (point cloud) and does not affect the performance of the model and also should not affect its interpretation."}

set.seed(1)
n = 25

x1 = runif(n)
x2 = x1 + rnorm(n, sd = 0.1)
df = data.frame(x1, x2)  
df$y = x1 + x2

mod  = lm(y ~ ., data = df)

y.fun = function(X.model, newdata) {
  pred = predict(X.model, newdata)
  pred[newdata$x1 > 0.7 & newdata$x2 < 0.3] = 2
  pred
}

grid.dat = expand.grid(x1 = seq(from = 0, to = 1, length.out = 20), x2 = seq(from = 0, to = 1, length.out = 20))
grid.dat$predicted = y.fun(mod, grid.dat)

ggplot(df) + geom_tile(data = grid.dat, aes(x = x1, y = x2, fill = predicted)) + 
  geom_point(aes(x = x1, y = x2), size = 3) + 
  scale_fill_viridis("Model\nprediction", option = "D")
```

Apakah ini skenario yang realistis dan relevan?
Saat Anda melatih model, learning algorithm meminimalkan loss untuk instance data pelatihan yang ada.
Hal-hal aneh dapat terjadi di luar distribusi data pelatihan, karena model tidak dihukum karena melakukan hal-hal aneh di area ini.
Meninggalkan distribusi data disebut ekstrapolasi, yang juga dapat digunakan untuk menipu model machine learning, yang dijelaskan dalam [bab tentang adversarial examples](#adversarial).
Lihat dalam contoh kecil kami bagaimana partial dependence plot berperilaku dibandingkan dengan plot ALE.


```{r correlation-pdp-ale-plot, fig.cap = "Comparison of the feature effects computed with PDP (upper row) and ALE (lower row). The PDP estimates are influenced by the odd behavior of the model outside the data distribution (steep jumps in the plots). The ALE plots correctly identify that the machine learning model has a linear relationship between features and prediction, ignoring areas without data."}
pred = Predictor$new(mod, data = df, predict.fun = y.fun)
pdp = FeatureEffect$new(pred, feature = "x1", method = "pdp")
pdp1 = pdp$plot() + ggtitle("PDP")
pdp = FeatureEffect$new(pred, feature = "x2", method = "pdp")
pdp2 = pdp$plot() + ggtitle("PDP")

ale1 = FeatureEffect$new(pred, feature = "x1", method = "ale")$plot() + ggtitle("ALE")
ale2 = FeatureEffect$new(pred, feature = "x2", method = "ale")$plot() + ggtitle("ALE")
gridExtra::grid.arrange(pdp1, pdp2, ale1, ale2)
```



Tapi bukankah menarik untuk melihat bahwa model kita berperilaku aneh pada x1 > 0,7 dan x2 <0,3?
Yah, ya dan tidak.
Karena ini adalah contoh data yang mungkin secara fisik tidak mungkin atau setidaknya sangat tidak mungkin, biasanya tidak relevan untuk melihat contoh ini.
Tetapi jika Anda menduga bahwa distribusi pengujian Anda mungkin sedikit berbeda dan beberapa contoh sebenarnya berada dalam kisaran tersebut, maka akan menarik untuk menyertakan area ini dalam penghitungan efek fitur.
Tapi itu harus menjadi keputusan sadar untuk memasukkan area di mana kami belum mengamati data dan itu tidak boleh menjadi efek samping dari metode pilihan seperti PDP.
Jika Anda menduga bahwa model tersebut nantinya akan digunakan dengan data yang terdistribusi berbeda, saya sarankan untuk menggunakan plot ALE dan mensimulasikan distribusi data yang Anda harapkan.

Beralih ke dataset nyata, mari kita prediksi [jumlah sepeda sewaan](#bike-data) berdasarkan cuaca dan hari dan periksa apakah plot ALE benar-benar berfungsi seperti yang dijanjikan.
Kami melatih regression tree untuk memprediksi jumlah sepeda yang disewa pada hari tertentu dan menggunakan plot ALE untuk menganalisis bagaimana suhu, kelembaban relatif, dan kecepatan angin memengaruhi prediksi.
Mari kita lihat apa yang dikatakan plot ALE:

```{r ale-bike-train}
data(bike)
library("mlr")
library("ggplot2")

set.seed(42)
bike.task = makeRegrTask(data = bike, target = "cnt")
mod.bike = mlr::train(mlr::makeLearner(cl = 'regr.ctree'), bike.task)$learner.model

pred.bike = Predictor$new(mod.bike, data = bike, y = "cnt")
```



```{r ale-bike, fig.cap = "ALE plots for the bike prediction model by temperature, humidity and wind speed. The temperature has a strong effect on the prediction. The average prediction rises with increasing temperature, but falls again above 25 degrees Celsius. Humidity has a negative effect: When above 60%, the higher the relative humidity, the lower the prediction. The wind speed does not affect the predictions much."}
limits = c(-1500, 800)

ale1 = FeatureEffect$new(pred.bike, "temp", method = "ale")$plot() +
  scale_x_continuous("Temperature") + scale_y_continuous("ALE", limits = limits)
ale2 = FeatureEffect$new(pred.bike, "hum", method = "ale")$plot() +
  scale_x_continuous("Humidity") + scale_y_continuous("", limits = limits)
ale3 = FeatureEffect$new(pred.bike, "windspeed", method = "ale")$plot() +
  scale_x_continuous("Wind speed") + scale_y_continuous("", limits = limits)

gridExtra::grid.arrange(ale1, ale2, ale3, ncol = 3)
```

Mari kita lihat korelasi antara suhu, kelembaban dan kecepatan angin dan semua fitur lainnya.
Karena data juga berisi fitur kategoris, kami tidak dapat hanya menggunakan correlation coefficient Pearson, yang hanya berfungsi jika kedua fitur tersebut numerik.
Sebagai gantinya, saya melatih model linier untuk memprediksi, misalnya, suhu berdasarkan salah satu fitur lain sebagai input.
Kemudian saya mengukur berapa banyak varians yang dijelaskan oleh fitur lain dalam model linier dan mengambil akar kuadrat.
Jika fitur lainnya adalah numerik, maka hasilnya sama dengan nilai absolut dari correlation coefficient Pearson standar.
Tetapi pendekatan berbasis model dari "variance-explained" (juga disebut ANOVA, yang merupakan singkatan dari ANalysis Of VAriance) berfungsi bahkan jika fitur lainnya bersifat kategoris.
Ukuran "yang dijelaskan varians" selalu terletak antara 0 (tidak ada hubungan) dan 1 (suhu dapat diprediksi dengan sempurna dari fitur lainnya).
Kami menghitung varians suhu, kelembaban, dan kecepatan angin yang dijelaskan dengan semua fitur lainnya.
Semakin tinggi varians yang dijelaskan (korelasi), semakin banyak (potensial) masalah dengan plot PD.
Gambar berikut memvisualisasikan seberapa kuat fitur cuaca berkorelasi dengan fitur lainnya.

```{r ale-bike-cor, fig.cap = "The strength of the correlation between temperature, humidity and wind speed with all features, measured as the amount of variance explained, when we train a linear model with e.g. temperature to predict and season as feature. For temperature we observe -- not surprisingly -- a high correlation with season and month. Humidity correlates with weather situation."}

mycor = function(cnames, dat) {
  x.num = dat[cnames[1]][[1]]
  x.cat = dat[cnames[2]][[1]]
  av = anova(lm(x.num ~ x.cat))
  sqrt(av$`Sum Sq`[1] / sum(av$`Sum Sq`))
}

cnames = c("temp", "hum", "windspeed")
combs = expand.grid(y = cnames, x = setdiff(colnames(bike), "cnt"))
combs$cor = apply(combs, 1, mycor, dat = bike)
combs$lab = sprintf("%.2f", combs$cor)
forder = c(cnames, setdiff(unique(combs$x), cnames))
combs$x = factor(combs$x, levels = forder)
combs$y = factor(combs$y, levels = rev(cnames))
ggplot(combs, aes(x = x, y = y, fill = cor, label = lab)) + 
  geom_tile() + 
  geom_label(fill = "white", size = 3) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))  + 
  scale_x_discrete("") + 
  scale_y_discrete("") + 
  scale_fill_viridis("Variance\nexplained", begin = 0.2)
```

Analisis korelasi ini mengungkapkan bahwa kita mungkin menghadapi masalah dengan partial dependence plot, terutama untuk fitur suhu.
Nah, lihat sendiri:

```{r pdp-bike-compare, fig.cap = 'PDPs for temperature, humidity and wind speed. Compared to the ALE plots, the PDPs show a smaller decrease in predicted number of bikes for high temperature or high humidity. The PDP uses all data instances to calculate the effect of high temperatures, even if they are, for example, instances with the season "winter". The ALE plots are more reliable.'}
pdp = FeatureEffect$new(pred.bike, "temp", method = "pdp") 
p1 = pdp$plot() +  scale_x_continuous('Temperature') + scale_y_continuous('Predicted number of rented bikes', limits = c(3700, 5300))
pdp$set.feature("hum")
p2 = pdp$plot() +  scale_x_continuous('Humidity') + scale_y_continuous('', limits = c(3000, 5500))
pdp$set.feature("windspeed")
p3 = pdp$plot() + scale_x_continuous('Wind speed') + scale_y_continuous('', limits = c(3000, 5500))

gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```

Selanjutnya, mari kita lihat plot ALE beraksi untuk fitur kategoris.
Bulan adalah fitur kategoris yang ingin kami analisis pengaruhnya terhadap prediksi jumlah sepeda.
Boleh dibilang, bulan-bulan sudah memiliki urutan tertentu (Januari hingga Desember), tetapi mari kita coba melihat apa yang terjadi jika kita mengurutkan ulang kategori berdasarkan kesamaan dan kemudian menghitung efeknya.
Bulan-bulan diurutkan berdasarkan kesamaan hari setiap bulan berdasarkan fitur lainnya, seperti suhu atau apakah itu hari libur.


```{r ale-bike-cat, fig.cap = 'ALE plot for the categorical feature month. The months are ordered by their similarity to each other, based on the distributions of the other features by month. We observe that January, March and April, but especially December and November, have a lower effect on the predicted number of rented bikes compared to the other months.'}
alecat1 = FeatureEffect$new(pred.bike, "mnth", method = "ale") 

ggplot(alecat1$results) + 
  geom_col(aes(x = mnth, y = .value), fill = default_color, width = 0.3) + 
  scale_x_discrete('') + 
  scale_y_continuous("ALE of predicted bike rentals")
```

Karena banyak fitur yang terkait dengan cuaca, urutan bulan sangat mencerminkan seberapa mirip cuaca di antara bulan-bulan tersebut.
Semua bulan yang lebih dingin berada di sisi kiri (Februari hingga April) dan bulan-bulan yang lebih hangat di sisi kanan (Oktober hingga Agustus).
Perlu diingat bahwa fitur non-cuaca juga telah dimasukkan dalam perhitungan kesamaan, misalnya frekuensi relatif hari libur memiliki bobot yang sama dengan suhu untuk menghitung kesamaan antar bulan.

Selanjutnya, kami mempertimbangkan efek orde kedua dari kelembaban dan suhu pada jumlah sepeda yang diprediksi.
Ingat bahwa efek orde kedua adalah efek interaksi tambahan dari dua fitur dan tidak termasuk efek utama.
Ini berarti bahwa, misalnya, Anda tidak akan melihat efek utama bahwa kelembaban tinggi menyebabkan jumlah sepeda yang diprediksi lebih rendah rata-rata di plot ALE orde kedua.

```{r ale-bike-2d, fig.cap = 'ALE plot for the 2nd-order effect of humidity and temperature on the predicted number of rented bikes. Lighter shade indicates an above average and darker shade a below average prediction when the main effects are already taken into account. The plot reveals an interaction between temperature and humidity: Hot and humid weather increases the prediction. In cold and humid weather an additional negative effect on the number of predicted bikes is shown.'}
FeatureEffect$new(pred.bike, feature = c("hum", "temp"), method = "ale", grid.size = 40)$plot() +   
  scale_fill_gradient("ALE", low = "red", high = "yellow") + 
  scale_x_continuous("Relative Humidity") + 
  scale_y_continuous("Temperature")+
  scale_fill_viridis(option = "D")
```

Perlu diingat bahwa kedua efek utama dari kelembaban dan suhu mengatakan bahwa jumlah sepeda yang diprediksi berkurang dalam cuaca yang sangat panas dan lembab.
Dalam cuaca panas dan lembab, efek gabungan dari suhu dan kelembaban oleh karena itu bukan jumlah dari efek utama, tetapi lebih besar dari jumlah tersebut.
Untuk menekankan perbedaan antara efek orde kedua murni (plot ALE 2D yang baru saja Anda lihat) dan efek total, mari kita lihat partial dependence plot.
PDP menunjukkan efek total, yang menggabungkan prediksi rata-rata, dua efek utama dan efek orde kedua (interaksi).

```{r pdp-bike-vs-ale-2D, fig.cap = "PDP of the total effect of temperature and humidity on the predicted number of bikes. The plot combines the main effect of each of the features and their interaction effect, as opposed to the 2D-ALE plot which only shows the interaction."}
pdp = FeatureEffect$new(pred.bike, c("hum", "temp"), method = "pdp")
pdp$plot() + 
  scale_fill_gradient("Prediction", low = "red", high = "yellow") + 
  scale_x_continuous("Relative Humidity") + 
  scale_y_continuous("Temperature") +
  scale_fill_viridis(option = "D")
```

Jika Anda hanya tertarik pada interaksi, Anda harus melihat efek orde kedua, karena efek total mencampur efek utama ke dalam plot.
Tetapi jika Anda ingin mengetahui efek gabungan dari fitur-fitur tersebut, Anda harus melihat efek totalnya (yang ditunjukkan oleh PDP).
Misalnya, jika Anda ingin mengetahui perkiraan jumlah sepeda pada suhu 30 derajat Celcius dan kelembaban 80 persen, Anda dapat membacanya langsung dari PDP 2D.
Jika Anda ingin membaca yang sama dari plot ALE, Anda perlu melihat tiga plot:
Plot ALE untuk suhu, untuk kelembaban dan untuk suhu + kelembaban dan Anda juga perlu mengetahui prediksi rata-rata keseluruhan.
Dalam skenario di mana dua fitur tidak memiliki interaksi, effect plot total dari dua fitur bisa menyesatkan karena mungkin menunjukkan lanskap yang kompleks, menunjukkan beberapa interaksi, tetapi itu hanyalah produk dari dua efek utama.
Efek orde kedua akan segera menunjukkan bahwa tidak ada interaksi.

Cukup sepeda untuk saat ini, mari kita beralih ke tugas klasifikasi.
Kami melatih random forest untuk memprediksi probabilitas [kanker serviks](#cervical) berdasarkan faktor risiko.
Kami memvisualisasikan accumulated local effects untuk dua fitur:

```{r ale-cervical-1D, fig.cap = "ALE plots for the effect of age and years with hormonal contraceptives on the predicted probability of cervical cancer. For the age feature, the ALE plot shows that the predicted cancer probability is low on average up to age 40 and increases after that. The number of years with hormonal contraceptives is associated with a higher predicted cancer risk after 8 years."}
data(cervical)
cervical.task = makeClassifTask(data = cervical, target = "Biopsy")
mod = mlr::train(mlr::makeLearner(cl = 'classif.randomForest', id = 'cervical-rf', predict.type = 'prob'), cervical.task)

pred.cervical = Predictor$new(mod, data = cervical, class = "Cancer")
ale1 = FeatureEffect$new(pred.cervical, "Age", method = "ale")$plot()
ale2 = FeatureEffect$new(pred.cervical, "Hormonal.Contraceptives..years.", method = "ale")$plot() +
  scale_x_continuous("Years with hormonal contraceptives") + 
  scale_y_continuous("")
gridExtra::grid.arrange(ale1, ale2, ncol = 2)
```

Selanjutnya, kita melihat interaksi antara jumlah kehamilan dan usia.


```{r ale-cervical-2d, fig.cap = 'ALE plot of the 2nd-order effect of number of pregnancies and age. The interpretation of the plot is a bit inconclusive, showing what seems like overfitting. For example, the plot shows an odd model behavior at age of 18-20 and more than 3 pregnancies (up to 5 percentage point increase in cancer probability). There are not many women in the data with this constellation of age and number of pregnancies (actual data are displayed as points), so the model is not severely penalized during the training for making mistakes for those women.'}
FeatureEffect$new(pred.cervical, c("Age", "Num.of.pregnancies"), grid.size = 30)$plot(show.data = TRUE) + 
    scale_fill_gradient("ALE", low = "red", high = "yellow") + 
  scale_y_continuous("Number of pregnancies")  + 
  scale_x_continuous("Age") +
  scale_fill_viridis(option = "D")

```


### Advantages

**Plot ALE tidak bias**, yang berarti plot tersebut masih berfungsi saat fitur dikorelasikan.
Partial dependence plot gagal dalam skenario ini karena mereka meminggirkan kombinasi nilai fitur yang tidak mungkin atau bahkan tidak mungkin secara fisik.

**Plot ALE lebih cepat dihitung** daripada PDP dan diskalakan dengan O(n), karena jumlah interval terbesar yang mungkin adalah jumlah instance dengan satu interval per instance.
PDP membutuhkan n kali jumlah estimasi titik grid.
Untuk 20 titik grid, PDP membutuhkan prediksi 20 kali lebih banyak daripada plot ALE kasus terburuk di mana interval sebanyak instance digunakan.

**Interpretasi plot ALE jelas**: Tergantung pada nilai yang diberikan, efek relatif dari perubahan fitur pada prediksi dapat dibaca dari plot ALE.
**Plot ALE dipusatkan di nol**.
Ini membuat interpretasi mereka bagus, karena nilai pada setiap titik kurva ALE adalah perbedaan dari prediksi rata-rata.
**Plot ALE 2D hanya menunjukkan interaksi**:
Jika dua fitur tidak berinteraksi, plot tidak menunjukkan apa-apa.

Secara keseluruhan, dalam kebanyakan situasi saya akan **lebih suka plot ALE daripada PDP**, karena fitur biasanya berkorelasi sampai batas tertentu.

### Disadvantages

**Plot ALE bisa menjadi sedikit goyah** (banyak pasang surut kecil) dengan jumlah interval yang tinggi.
Dalam hal ini, mengurangi jumlah interval membuat perkiraan lebih stabil, tetapi juga menghaluskan dan menyembunyikan beberapa kompleksitas model prediksi yang sebenarnya.
**Tidak ada solusi sempurna untuk menyetel jumlah interval**.
Jika jumlahnya terlalu kecil, plot ALE mungkin tidak terlalu akurat.
Jika jumlahnya terlalu tinggi, kurva bisa menjadi goyah.

Tidak seperti PDP, **plot ALE tidak disertai dengan kurva ICE**.
Untuk PDP, kurva ICE sangat bagus karena dapat mengungkapkan heterogenitas dalam efek fitur, yang berarti bahwa efek fitur terlihat berbeda untuk subset data.
Untuk plot ALE Anda hanya dapat memeriksa per interval apakah efeknya berbeda antara instance, tetapi setiap interval memiliki instance yang berbeda sehingga tidak sama dengan kurva ICE.

**Perkiraan ALE urutan kedua memiliki stabilitas yang bervariasi di seluruh ruang fitur, yang tidak divisualisasikan dengan cara apa pun.**
Alasan untuk ini adalah bahwa setiap estimasi efek lokal dalam sel menggunakan jumlah instance data yang berbeda.
Akibatnya, semua perkiraan memiliki akurasi yang berbeda (tetapi masih merupakan perkiraan terbaik).
Masalahnya ada dalam versi yang kurang parah untuk plot ALE efek utama.
Jumlah instance sama di semua interval, berkat penggunaan kuantil sebagai grid, tetapi di beberapa area akan ada banyak interval pendek dan kurva ALE akan terdiri dari lebih banyak perkiraan.
Tetapi untuk interval yang panjang, yang dapat membentuk sebagian besar dari seluruh kurva, ada lebih sedikit contoh.
Hal ini terjadi pada plot ALE prediksi kanker serviks untuk usia tinggi misalnya.

**Effect plot urutan kedua bisa sedikit mengganggu untuk ditafsirkan**, karena Anda harus selalu mengingat efek utama.
Sangat menggoda untuk membaca peta panas sebagai efek total dari dua fitur, tetapi itu hanya efek tambahan dari interaksi.
Efek orde kedua murni menarik untuk menemukan dan mengeksplorasi interaksi, tetapi untuk menafsirkan seperti apa efeknya, saya pikir lebih masuk akal untuk mengintegrasikan efek utama ke dalam plot.

**Penerapan plot ALE jauh lebih kompleks** dan kurang intuitif dibandingkan dengan partial dependence plot.

Meskipun plot ALE tidak bias dalam hal fitur berkorelasi, **interpretasi tetap sulit ketika fitur berkorelasi kuat**.
Karena jika mereka memiliki korelasi yang sangat kuat, masuk akal untuk menganalisis efek perubahan kedua fitur secara bersamaan dan tidak secara terpisah.
Kerugian ini tidak khusus untuk plot ALE, tetapi masalah umum fitur berkorelasi kuat.

Jika fitur tidak berkorelasi dan waktu komputasi tidak menjadi masalah, PDP sedikit lebih disukai karena lebih mudah dipahami dan dapat diplot bersama dengan kurva ICE.


Daftar kekurangannya menjadi cukup panjang, tetapi jangan tertipu oleh jumlah kata yang saya gunakan:
Sebagai aturan praktis: Gunakan ALE alih-alih PDP.


### Implementation and Alternatives

Apakah saya menyebutkan bahwa [partial dependence plot](#pdp) dan [kurva individual conditional expectation](#ice) adalah alternatif? =)

Plot ALE diimplementasikan dalam R dan Python, sekali dalam [paket ALEPlot R](https://cran.r-project.org/web/packages/ALEPlot/index.html) oleh penemu sendiri dan sekali di [iml package](https://cran.r-project.org/web/packages/iml/index.html) dan dalam [paket ALEPython](https://github.com/blent-ai/ALEPython).


[^ALE]: Apley, Daniel W. "Visualizing the effects of predictor variables in black box supervised learning models." arXiv preprint arXiv:1612.08468 (2016).
