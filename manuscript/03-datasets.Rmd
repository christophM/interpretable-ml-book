```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
```


# Datasets {#data}
Throughout the book, all models and techniques are applied to real datasets that are freely available online.
We will use different datasets for different tasks:
Classification, regression and text classification.

## Bike Rentals (Regression) {#bike-data}
This dataset contains daily number of rented bicycles from the bicycle rental company [Capital-Bikeshare](https://www.capitalbikeshare.com/) in Washington D.C., along with weather and seasonal information.
The data was kindly made openly available by Capital-Bikeshare and the folks from Fanaee-T and Gama (2013)[^Fanaee] added the weather data and the season information.
The goal is to predict how many bikes will be rented depending on the weather and the day.
The data can be downloaded from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset).


New features were added to the dataset and not all original features were used for the examples.
Here is the list of features that were used:

- cnt: Count of bicycles including both casual and registered users.
The count is used as the target in the regression task.
- season: spring, summer, autumn, winter
- holiday: Binary feature that indicates whether the day was a holiday or not
- yr: The year (2011 or 2012)
- days_since_2011: Number of days since the 01.01.2011 (the first day in the dataset)
This feature was introduced to take account of the trend over time
- workingday: Binary feature that indicates whether the day was a working day (1) or weekend / holiday (0)
- weathersit: The weather situation on that day
    - Clear, Few clouds, Partly cloudy, Cloudy
    - Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
    - Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
    - Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
- temp: Temperature in degrees Celsius
- hum: Relative humidity in percent (0 to 100)
- windspeed: Wind speed in km per hour


For the examples in this book, the data has been slightly processed.
You can find the processing R-script in the book's [Github repository](https://github.com/christophM/interpretable-ml-book/blob/master/R/get-bike-sharing-dataset.R) together with the [final RData file](https://github.com/christophM/interpretable-ml-book/blob/master/data/bike.RData).


## YouTube Spam Comments (Text Classification) {#spam-data}
As an example for text classification we work with 1956 comments from 5 different YouTube videos.
Thankfully, the authors who used this dataset in an article on spam classification made the data  [freely available](http://dcomp.sor.ufscar.br/talmeida/youtubespamcollection/) (Alberto, Lochter, and Almeida 2015[^Alberto]).

The comments were collected via the YouTube API from five of the ten most viewed videos on YouTube in the first half of 2015. 
All 5 are music videos.
One of them is "Gangnam Style" by Korean artist Psy. 
The other artists were Katy Perry, LMFAO, Eminem, and Shakira.


Checkout some of the comments. 
The comments were manually labeled as spam or legitimate.
Spam was coded with a '1' and legitimate comments with a '0'.

```{r show-dating-data-TubeSpam}
data(ycomments)
knitr::kable(ycomments[1:10, c('CONTENT', 'CLASS')])
```

You can also go to YouTube and take a look at the comment section.
But please do not get caught in YouTube hell and end up watching videos of monkeys stealing and drinking cocktails from tourists on the beach.
The Google Spam detector has also probably changed a lot since 2015.

[Watch the view-record breaking video "Gangnam Style" here](https://www.youtube.com/watch?v=9bZkp7q19f0&feature=player_embedded)


If you want to play around with the data, you can find the [RData file](https://github.com/christophM/interpretable-ml-book/blob/master/data/ycomments.RData) along with the [R script](https://github.com/christophM/interpretable-ml-book/blob/master/R/get-SpamTube-dataset.R) with some convenience functions in the book's Github repository.

## Risk Factors for Cervical Cancer (Classification) {#cervical}

The cervical cancer dataset contains indicators and risk factors for predicting whether a woman will get cervical cancer.
The features include demographic data (such as age), lifestyle, and medical history.
The data can be downloaded from the [UCI Machine Learning repository](https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29) and is described by K. Fernandes, Cardoso, and Fernandes (2017) [^Fernandes].

The subset of data features used in the later examples are:

- Age in years
- Number of sexual partners
- First sexual intercourse (age in years)
- Number of pregnancies
- Smoking yes (1) or no (1)
- Smoking (in years)
- Hormonal Contraceptives yes (1) or no (0)
- Hormonal Contraceptives (in years)
- IUD: Intrauterine device yes (1) or no (1)
- IUD (in years): Number of years with an intrauterine device
- STDs: Has patient ever had a sexually transmitted disease yes (1) or no (0)?
- STDs (number): Number of sexually transmitted diseases diagnoses
- STDs: Time since first diagnosis
- STDs: Time since last diagnosis
- Biopsy: The Biopsy results "Healthy" or "Cancer". Target outcome.

Since the biopsy serves as the gold standard for diagnosing cervical cancer, the classification task in this book used the biopsy outcome as the target.
Missing values for each column were imputed by the mode (most frequent value), which is probably a bad solution, since the value of the answer could be correlated with the probability that a value is missing.
There is probably a bias because the questions are of a very private nature.
But this is not a book about missing data imputation, so the mode imputation will have to suffice for the examples.

To reproduce the examples of this book with this dataset, find the
[preprocessing script](https://github.com/christophM/interpretable-ml-book/blob/master/R/get-cervical-cancer-dataset.R) and the 
[final RData file](https://github.com/christophM/interpretable-ml-book/blob/master/data/cervical.RData) in the book's Github repository.

[^Fanaee]: Fanaee-T, Hadi, and Joao Gama. 2013. “Event Labeling Combining Ensemble Detectors and Background Knowledge.” Progress in Artificial Intelligence. Springer Berlin Heidelberg, 1–15. doi:10.1007/s13748-013-0040-3.

[^Alberto]: Alberto, Túlio C, Johannes V Lochter, and Tiago A Almeida. 2015. “Tubespam: Comment Spam Filtering on Youtube.” In Machine Learning and Applications (Icmla), 2015 Ieee 14th International Conference on, 138–43. IEEE.

[^Fernandes]: Fernandes, Kelwin, Jaime S Cardoso, and Jessica Fernandes. 2017. “Transfer Learning with Partial Observability Applied to Cervical Cancer Screening.” In Iberian Conference on Pattern Recognition and Image Analysis, 243–50. Springer.
