```{r setup, cache=FALSE, include=FALSE}
devtools::load_all()
is.html = !is.null(output) && output == "html"
only.in.html = "*This chapter is currently only available in this web version. ebook and print will follow.*"

devtools::install_github("viadee/anchorsOnR")
install.packages("../pkg/sbrl_1.2.tar.gz", repos = NULL, type = "source")
```


# Summary {-}
```{r cover, cache=FALSE, eval = is.html, out.width=500, fig.align="center"}
knitr::include_graphics('images/title_page.jpg', dpi = NA)
```

Machine learning has great potential for improving products, processes and research.
But **computers usually do not explain their predictions** which is a barrier to the adoption of machine learning.
This book is about making machine learning models and their decisions interpretable.

After exploring the concepts of interpretability, you will learn about simple, **interpretable models** such as decision trees, decision rules and linear regression.
Later chapters focus on general model-agnostic methods for **interpreting black box models** like feature importance and accumulated local effects and explaining individual predictions with Shapley values and LIME.

All interpretation methods are explained in depth and discussed critically.
How do they work under the hood?
What are their strengths and weaknesses?
How can their outputs be interpreted?
This book will enable you to select and correctly apply the interpretation method that is most suitable for your machine learning project.

The book focuses on machine learning models for tabular data (also called relational or structured data) and less on computer vision and natural language processing tasks.
Reading the book is recommended for machine learning practitioners, data scientists, statisticians, and anyone else interested in making machine learning models interpretable.


`r if(is.html){"You can buy the PDF and e-book version (epub, mobi) [on leanpub.com](https://leanpub.com/interpretable-machine-learning)."}`

`r if(is.html){"You can buy the print version [on lulu.com](http://www.lulu.com/shop/christoph-molnar/interpretable-machine-learning/paperback/product-24036234.html)."}`

**About me:** My name is Christoph Molnar, I'm a statistician and a machine learner.
My goal is to make machine learning interpretable.

Mail: christoph.molnar.ai@gmail.com

Website: [https://christophm.github.io/](https://christophm.github.io/)

Follow me on Twitter! [\@ChristophMolnar](https://twitter.com/ChristophMolnar)

Cover by [\@YvonneDoinel](https://twitter.com/YvonneDoinel)


`r if(is.html){"![Creative Commons License](images/by-nc-sa.png)"}`

`r if(is.html){"This book is licensed under the [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/)."}`



# Preface by the Author {-}

This book started as a side project when I was working as a statistician in clinical research.
I worked 4 days a week, and on my "day off" I worked on side projects.
Eventually, interpretable machine learning became one of my side projects.
At first I had no intention of writing a book.
Instead, I was simply interested in finding out more about interpretable machine learning and was looking for good resources to learn from.
Given the success of machine learning and the importance of interpretability, I expected that there would be tons of books and tutorials on this topic.
But I only found the relevant research papers and a few blog posts scattered around the internet, but nothing with a good overview.
No books, no tutorials, no overview papers, nothing.
This gap inspired me to start this book.
I ended up writing the book I wished was available when I began my study of interpretable machine learning.
My intention with this book was twofold: to learn for myself and to share this new knowledge with others.

<!-- Introduction to Author -->
I received my bachelor's and master's degree in statistics at the LMU Munich, Germany.
Most of my knowledge about machine learning was self-taught through online courses, competitions, side projects and professional activities.
My statistical background was an excellent basis for getting into machine learning, and especially for interpretability.
In statistics, a major focus is on building interpretable regression models.
After I finished my master's degree in statistics, I decided not to pursue a PhD, because I did not enjoy writing my master's thesis.
Writing just stressed me out too much.
So I took jobs as data scientist in a Fintech start-up and as statistician in clinical research.
After these three years in industry I started writing this book and a few months later I started a PhD in interpretable machine learning.
By starting this book, I regained the joy of writing and it helped me to develop a passion for research.

This book covers many techniques of interpretable machine learning.
In the first chapters I introduce the concept of interpretability and motivate why interpretability is necessary.
There are even some short stories!
The book discusses the different properties of explanations and what humans think is a good explanation.
Then we will discuss machine learning models that are inherently interpretable, for example regression models and decision trees.
The main focus of this book is on model-agnostic interpretability methods.
Model-agnostic means that these methods can be applied to any machine learning model and are applied after the model has been trained.
The independence of the model makes model-agnostic methods very flexible and powerful.
Some techniques explain how individual predictions were made, like local interpretable model-agnostic explanations (LIME) and Shapley values.
Other techniques describe the average behavior of the model across a dataset.
Here we learn about the partial dependence plot, accumulated local effects, permutation feature importance and many other methods.
A special category are example-based methods that produce data points as explanations.
Counterfactual explanations, prototypes, influential instances and adversarial examples are example-based methods that are discussed in this book.
The book concludes with some reflections on what the future of interpretable machine learning might look like.

You do not have to read the book from cover to cover, you can jump back and forth and concentrate on the techniques that interest you most.
I only recommend that you start with the introduction and the chapter on interpretability.
Most chapters follow a similar structure and focus on one interpretation method.
The first paragraph summarizes the method.
Then I try to explain the method intuitively without relying on mathematical formulas.
Then we look at the theory of the method to get a deep understanding of how it works.
You will not be spared here, because the theory will contain formulas.
I believe that a new method is best understood using examples.
Therefore, each method is applied to real data.
Some people say that statistician are very critical people.
For me, this is true, because each chapter contains critical discussions about advantages and disadvantages of the respective interpretation method.
This book is not an advertisement for the methods, but it should help you decide whether a method works well for your application or not.
In the last section of each chapter, available software implementations are discussed.

Machine learning has received great attention from many people in research and industry.
Sometimes machine learning is overhyped in the media, but there are many real and impactful applications.
Machine learning is a powerful technology for products, research and automation.
Today machine learning is used, for example,  to detect fraudulent financial transactions, recommend movies to watch and classify images.
It is often crucial that the machine learning models are interpretable.
Interpretability helps the developer to debug and improve the model, build trust in the model, justify model predictions and gain insights.
The increased need for machine learning interpretability is a natural consequence of an increased use of machine learning.
This book has become a valuable resource for many people.
Teaching instructors use the book to introduce their students to the concepts of interpretable machine learning.
I received e-mails from various master and doctoral students who told me that this book was the starting point and most important reference for their theses.
The book has helped applied researchers in the field of ecology, finance, psychology, etc.  who use machine learning to understand their data.
Data scientists from industry told me that they use the "Interpretable Machine Learning" book for their work and recommend it to their colleagues.
I am happy that many people can benefit from this book and become experts in model interpretation.

I would recommend this book to practitioners who want an overview of techniques to make their machine learning models more interpretable.
It is also recommended to students and researchers (and anyone else) who is interested in the topic.
To benefit from this book, you should already have a basic understanding of machine learning.
You should also have a mathematical understanding at university entry level to be able to follow the theory and formulas in this book.
It should also be possible, however, to understand the intuitive description of the method at the beginning of each chapter without mathematics.

I hope you enjoy the book!

