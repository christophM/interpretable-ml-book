```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## Logistic Regression {#logistic}

Logistic regression memodelkan probabilitas untuk masalah klasifikasi dengan dua kemungkinan hasil.
Ini merupakan perpanjangan dari model linear regression untuk masalah klasifikasi.

### What is Wrong with Linear Regression for Classification?

Model linear regression dapat bekerja dengan baik untuk regresi, tetapi gagal untuk klasifikasi.
Mengapa demikian?
Dalam kasus dua kelas, Anda bisa memberi label salah satu kelas dengan 0 dan yang lainnya dengan 1 dan menggunakan linear regression.
Secara teknis ini berfungsi dan sebagian besar program model linier akan memberikan bobot untuk Anda.
Tetapi ada beberapa masalah dengan pendekatan ini:

Model linier tidak menghasilkan probabilitas, tetapi memperlakukan kelas sebagai angka (0 dan 1) dan cocok dengan hyperplane terbaik (untuk fitur tunggal, itu adalah garis) yang meminimalkan jarak antara titik dan hyperplane.
Jadi itu hanya interpolasi antara titik-titik, dan Anda tidak dapat menafsirkannya sebagai probabilitas.

Model linier juga mengekstrapolasi dan memberi Anda nilai di bawah nol dan di atas satu.
Ini adalah pertanda baik bahwa mungkin ada pendekatan yang lebih cerdas untuk klasifikasi.

Karena hasil yang diprediksi bukanlah probabilitas, tetapi interpolasi linier antara titik, tidak ada ambang batas yang berarti di mana Anda dapat membedakan satu kelas dari yang lain.
Ilustrasi yang bagus tentang masalah ini telah diberikan di [Stackoverflow](https://stats.stackexchange.com/questions/22381/why-not-approach-classification-through-regression).

Model linier tidak meluas ke masalah klasifikasi dengan banyak kelas.
Anda harus mulai memberi label pada kelas berikutnya dengan 2, lalu 3, dan seterusnya.
Kelas mungkin tidak memiliki urutan yang berarti, tetapi model linier akan memaksa struktur aneh pada hubungan antara fitur dan prediksi kelas Anda.
Semakin tinggi nilai fitur dengan bobot positif, semakin berkontribusi pada prediksi kelas dengan angka yang lebih tinggi, bahkan jika kelas yang kebetulan mendapatkan angka yang sama tidak lebih dekat dari kelas lainnya.


```{r linear-class-threshold, fig.cap="A linear model classifies tumors as malignant (1) or benign (0) given their size. The lines show the prediction of the linear model. For the data on the left, we can use 0.5 as classification threshold. After introducing a few more malignant tumor cases, the regression line shifts and a threshold of 0.5 no longer separates the classes. Points are slightly jittered to reduce over-plotting. "}
library("ggplot2")
df = data.frame(x = c(1,2,3,8,9,10,11,9),
  y = c(0,0,0,1,1,1,1, 0),
  case = '1) 0.5 threshold ok')

df_extra  = data.frame(x=c(df$x, 7, 7, 7, 20, 19, 5, 5, 4, 4.5),
  y=c(df$y, 1,1,1,1, 1, 1, 1, 1, 1),
  case = '2) 0.5 threshold not ok')

df.lin.log = rbind(df, df_extra)
p1 = ggplot(df.lin.log, aes(x=x,y=y)) +
  geom_point(position = position_jitter(width=0, height=0.02)) +
  geom_smooth(method='lm', se=FALSE) +
  my_theme() +
  scale_y_continuous('', breaks = c(0, 0.5, 1), labels = c('benign tumor', '0.5',  'malignant tumor'), limits = c(-0.1,1.3)) +
  scale_x_continuous('Tumor size') +
  facet_grid(. ~ case) +
  geom_hline(yintercept=0.5, linetype = 3)

p1
```


### Theory

Solusi untuk klasifikasi adalah logistic regression.
Alih-alih memasang garis lurus atau hyperplane, regression models logistik menggunakan fungsi logistik untuk memeras output dari persamaan linier antara 0 dan 1.
Fungsi logistik didefinisikan sebagai:

$$\text{logistic}(\eta)=\frac{1}{1+exp(-\eta)}$$

Dan terlihat seperti ini:

```{r, logistic-function, fig.cap="The logistic function. It outputs numbers between 0 and 1. At input 0, it outputs 0.5."}
logistic = function(x){1 / (1 + exp(-x))}

x = seq(from=-6, to = 6, length.out = 100)
df = data.frame(x = x,
  y = logistic(x))
ggplot(df) + geom_line(aes(x=x,y=y)) + my_theme()
```

Langkah dari linear regression ke logistic regression cukup mudah.
Dalam model linear regression, kami telah memodelkan hubungan antara hasil dan fitur dengan persamaan linier:

$$\hat{y}^{(i)}=\beta_{0}+\beta_{1}x^{(i)}_{1}+\ldots+\beta_{p}x^{(i)}_{p}$$

Untuk klasifikasi, kami lebih suka probabilitas antara 0 dan 1, jadi kami membungkus sisi kanan persamaan ke dalam fungsi logistik.
Ini memaksa output untuk mengasumsikan hanya nilai antara 0 dan 1.

$$P(y^{(i)}=1)=\frac{1}{1+exp(-(\beta_{0}+\beta_{1}x^{(i)}_{1}+\ldots+\beta_{p}x^{(i)}_{p}))}$$

Mari kita lihat kembali contoh ukuran tumor.
Tapi alih-alih model linear regression, kami menggunakan regression models logistik:

```{r logistic-class-threshold, fig.cap="The logistic regression model finds the correct decision boundary between malignant and benign depending on tumor size. The line is the logistic function shifted and squeezed to fit the data."}
logistic1 = glm(y ~ x, family = binomial(), data = df.lin.log[df.lin.log$case == '1) 0.5 threshold ok',])
logistic2 = glm(y ~ x, family = binomial, data = df.lin.log)

lgrid = data.frame(x = seq(from=0, to=20, length.out=100))
lgrid$y1_pred = predict(logistic1, newdata = lgrid, type='response')
lgrid$y2_pred = predict(logistic2 , newdata = lgrid, type='response')
lgrid.m = data.frame(data.table::melt(lgrid, measure.vars = c("y1_pred", "y2_pred")))
colnames(lgrid.m) = c("x", "case", "value")
lgrid.m$case = as.character(lgrid.m$case)
lgrid.m$case[lgrid.m$case == "y1_pred"] = '1) 0.5 threshold ok'
lgrid.m$case[lgrid.m$case == "y2_pred"] = '2) 0.5 threshold ok as well'
df.lin.log$case = as.character(df.lin.log$case)
df.lin.log$case[df.lin.log$case == "2) 0.5 threshold not ok"] = '2) 0.5 threshold ok as well'



p1 = ggplot(df.lin.log, aes(x=x,y=y)) +
  geom_line(aes(x=x, y=value), data = lgrid.m, color='blue', size=1) +
  geom_point(position = position_jitter(width=0, height=0.02)) +
  my_theme() +
  scale_y_continuous('Tumor class', breaks = c(0, 0.5, 1), labels = c('benign tumor', '0.5',  'malignant tumor'), limits = c(-0.1,1.3)) +
  scale_x_continuous('Tumor size') +
  facet_grid(. ~ case) +
  geom_hline(yintercept=0.5, linetype = 3)

p1
```

Klasifikasi bekerja lebih baik dengan logistic regression dan kita dapat menggunakan 0,5 sebagai ambang batas dalam kedua kasus. Pencantuman poin tambahan tidak terlalu mempengaruhi kurva estimasi.

### Interpretation
Interpretasi bobot dalam logistic regression berbeda dari interpretasi bobot dalam linear regression, karena hasil dalam logistic regression adalah probabilitas antara 0 dan 1.
Bobot tidak lagi mempengaruhi probabilitas secara linier.
Jumlah tertimbang ditransformasikan oleh fungsi logistik menjadi probabilitas.
Oleh karena itu kita perlu merumuskan kembali persamaan untuk interpretasi sehingga hanya suku linier yang berada di ruas kanan rumus.

$$log\left(\frac{P(y=1)}{1-P(y=1)}\right)=log\left(\frac{P(y=1)}{P(y=0)}\right)=\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}$$

Kami menyebut istilah dalam fungsi log() "odds" (probabilitas kejadian dibagi dengan probabilitas tidak ada kejadian) dan dibungkus dalam logaritma yang disebut log odds.

Rumus ini menunjukkan bahwa regression models logistik merupakan model linier untuk log odds.
Bagus!
Itu tidak terdengar membantu!
Dengan sedikit mengacak istilah, Anda dapat mengetahui bagaimana prediksi berubah ketika salah satu fitur $x_j$ diubah 1 unit.
Untuk melakukan ini, pertama-tama kita dapat menerapkan fungsi exp() ke kedua sisi persamaan:

$$\frac{P(y=1)}{1-P(y=1)}=odds=exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{p}x_{p}\right)$$

Kemudian kami membandingkan apa yang terjadi ketika kami meningkatkan salah satu nilai fitur sebesar 1.
Tapi alih-alih melihat perbedaannya, kami melihat rasio dari dua prediksi:

$$\frac{odds_{x_j+1}}{odds}=\frac{exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{j}(x_{j}+1)+\ldots+\beta_{p}x_{p}\right)}{exp\left(\beta_{0}+\beta_{1}x_{1}+\ldots+\beta_{j}x_{j}+\ldots+\beta_{p}x_{p}\right)}$$

Kami menerapkan aturan berikut:

$$\frac{exp(a)}{exp(b)}=exp(a-b)$$ 

Dan kami menghapus banyak istilah:

$$\frac{odds_{x_j+1}}{odds}=exp\left(\beta_{j}(x_{j}+1)-\beta_{j}x_{j}\right)=exp\left(\beta_j\right)$$

Pada akhirnya, kami memiliki sesuatu yang sederhana seperti exp() dari bobot fitur.
Perubahan fitur sebesar satu unit mengubah rasio odds (perkalian) dengan faktor $\exp(\beta_j)$.
Kita juga bisa mengartikannya seperti ini:
Perubahan $x_j$ sebesar satu unit meningkatkan rasio odds log dengan nilai bobot yang sesuai.
Kebanyakan orang menafsirkan rasio odds karena memikirkan log() dari sesuatu diketahui sulit di otak.
Menafsirkan rasio odds sudah membutuhkan beberapa kebiasaan.
Misalnya, jika Anda memiliki odds 2, itu berarti probabilitas untuk y=1 dua kali lebih tinggi dari y=0.
Jika Anda memiliki bobot (= rasio odds log) 0,7, maka meningkatkan fitur masing-masing satu unit akan mengalikan peluang dengan exp(0,7) (kira-kira 2) dan peluang berubah menjadi 4.
Tetapi biasanya Anda tidak berurusan dengan peluang dan menafsirkan bobot hanya sebagai rasio peluang.
Karena untuk benar-benar menghitung peluang, Anda perlu menetapkan nilai untuk setiap fitur, yang hanya masuk akal jika Anda ingin melihat satu contoh spesifik dari kumpulan data Anda.

Ini adalah interpretasi untuk regression models logistik dengan tipe fitur yang berbeda:

- Fitur numerik:
Jika Anda meningkatkan nilai fitur $x_{j}$ sebanyak satu unit, perkiraan peluang berubah dengan faktor $\exp(\beta_{j})$
- Fitur kategoris biner:
Salah satu dari dua nilai fitur adalah kategori referensi (dalam beberapa bahasa, yang dikodekan dalam 0).
Mengubah fitur $x_{j}$ dari kategori referensi ke kategori lain akan mengubah perkiraan peluang dengan faktor $\exp(\beta_{j})$.
- Fitur kategoris dengan lebih dari dua kategori:
Salah satu solusi untuk menangani banyak kategori adalah one-hot-encoding, artinya setiap kategori memiliki kolomnya sendiri.
Anda hanya memerlukan kolom L-1 untuk fitur kategoris dengan kategori L, jika tidak maka parameternya berlebihan.
Kategori ke-L kemudian menjadi kategori referensi.
Anda dapat menggunakan pengkodean lain yang dapat digunakan dalam linear regression.
Interpretasi untuk setiap kategori kemudian setara dengan interpretasi fitur biner.
- Intercept $\beta_{0}$:
Ketika semua fitur numerik adalah nol dan fitur kategoris berada pada kategori referensi, perkiraan peluangnya adalah $\exp(\beta_{0})$.
Interpretasi dari bobot intersep biasanya tidak relevan.

### Example

Kami menggunakan regression models logistik untuk memprediksi [kanker serviks](#cervical) berdasarkan beberapa faktor risiko.
Tabel berikut menunjukkan bobot perkiraan, rasio peluang terkait, dan kesalahan standar perkiraan.

```{r logistic-example}
data("cervical")
neat_cervical_names = c('Intercept', 'Hormonal contraceptives y/n',
  'Smokes y/n', 'Num. of pregnancies',
  'Num. of diagnosed STDs',
  'Intrauterine device y/n')

# Fit logistic model for probability of cancer, use few features that are interesting
mod = glm(Biopsy ~ Hormonal.Contraceptives + Smokes + Num.of.pregnancies + STDs..Number.of.diagnosis + IUD,
  data = cervical, family = binomial())
# Print table of coef, exp(coef), std, p-value
coef.table = summary(mod)$coefficients[,c('Estimate', 'Std. Error')]
coef.table = cbind(coef.table, 'Odds ratio' = as.vector(exp(round(coef.table[, c('Estimate')], 2))))
# Interpret one numerical and one factor
rownames(coef.table) = neat_cervical_names
colnames(coef.table)[1] = 'Weight'
kable(coef.table[, c('Weight', 'Odds ratio', 'Std. Error')], digits=2, caption='The results of fitting a logistic regression model on the cervical cancer dataset. Shown are the features used in the model, their estimated weights and corresponding odds ratios, and the standard errors of the estimated weights.')
```

Interpretasi fitur numerik ("Jumlah PMS yang didiagnosis"):
Peningkatan jumlah PMS yang terdiagnosis (penyakit menular seksual) mengubah (meningkatkan) kemungkinan kanker vs. tidak ada kanker dengan faktor `r sprintf('%.2f', coef.table['Num. of diagnosed STDs', 'Odds ratio'])`, saat semua fitur lainnya tetap sama.
Perlu diingat bahwa korelasi tidak menyiratkan sebab-akibat.

Interpretasi fitur kategoris ("Kontrasepsi hormonal y/n"):
Untuk wanita yang menggunakan kontrasepsi hormonal, peluang untuk kanker vs. tidak ada kanker adalah dengan faktor `r sprintf('%.2f', coef.table['Hormonal contraceptives y/n', 'Odds ratio'])` lebih rendah, dibandingkan dengan wanita tanpa kontrasepsi hormonal, mengingat semua fitur lainnya tetap sama.

Seperti dalam model linier, interpretasi selalu datang dengan klausa bahwa 'semua fitur lainnya tetap sama'.



### Advantages and Disadvantages

Banyak pro dan kontra dari [model linear regression](#limo) juga berlaku untuk regression models logistik.
logistic regression telah banyak digunakan oleh banyak orang yang berbeda, tetapi ia berjuang dengan ekspresi yang membatasi (misalnya interaksi harus ditambahkan secara manual) dan model lain mungkin memiliki kinerja prediksi yang lebih baik.

Kelemahan lain dari regression models logistik adalah interpretasinya lebih sulit karena interpretasi bobotnya bersifat perkalian dan tidak aditif.

Logistic regression dapat mengalami **pemisahan lengkap**.
Jika ada fitur yang akan memisahkan kedua kelas secara sempurna, regression models logistik tidak dapat lagi dilatih.
Ini karena bobot untuk fitur itu tidak akan konvergen, karena bobot optimalnya tidak terbatas.
Ini benar-benar agak disayangkan, karena fitur seperti itu sangat berguna.
Tetapi Anda tidak memerlukan machine learning jika Anda memiliki aturan sederhana yang memisahkan kedua kelas.
Masalah pemisahan lengkap dapat diselesaikan dengan memperkenalkan penalty bobot atau mendefinisikan distribusi probabilitas bobot sebelumnya.

Sisi baiknya, regression models logistik tidak hanya model klasifikasi, tetapi juga memberi Anda probabilitas.
Ini adalah keuntungan besar dibandingkan model yang hanya dapat memberikan klasifikasi akhir.
Mengetahui bahwa sebuah instance memiliki probabilitas 99% untuk suatu kelas dibandingkan dengan 51% membuat perbedaan besar.

Logistic regression juga dapat diperluas dari klasifikasi biner ke klasifikasi multi-kelas.
Kemudian disebut multinomial regression.

### Software

Saya menggunakan fungsi `glm` di R untuk semua contoh.
Anda dapat menemukan logistic regression dalam bahasa pemrograman apa pun yang dapat digunakan untuk melakukan analisis data, seperti Python, Java, Stata, Matlab, ...
