```{r, message = FALSE, warning = FALSE, echo = FALSE}
devtools::load_all()
set.seed(42)
```

<!--{pagebreak}-->

## Permutation Feature Importance {#feature-importance}

Permutation feature importance mengukur peningkatan kesalahan prediksi model setelah kami mengubah nilai fitur, yang memutuskan hubungan antara fitur dan hasil sebenarnya.

### Theory

Konsepnya sangat mudah:
Kami mengukur feature importance dengan menghitung peningkatan kesalahan prediksi model setelah mengubah fitur tersebut.
Sebuah fitur "penting" jika mengacak nilainya meningkatkan kesalahan model, karena dalam hal ini model mengandalkan fitur untuk prediksi.
Sebuah fitur dikatakan "tidak penting" jika mengacak nilainya membuat kesalahan model tidak berubah, karena dalam kasus ini model mengabaikan fitur untuk prediksi.
Pengukuran permutation feature importance diperkenalkan oleh Breiman (2001)[^Breiman2001] untuk random forest.
Berdasarkan ide ini, Fisher, Rudin, dan Dominici (2018)[^Fisher2018] mengusulkan versi model-agnostic dari feature importance dan menyebutnya model ketergantungan.
Mereka juga memperkenalkan gagasan yang lebih maju tentang feature importance, misalnya versi (model-specific) yang memperhitungkan bahwa banyak model prediksi dapat memprediksi data dengan baik.
Makalah mereka layak dibaca.

**Algoritme permutation feature importance berdasarkan Fisher, Rudin, dan Dominici (2018):**

Input: Model terlatih f, matriks fitur X, vektor target y, ukuran kesalahan L(y,f).

1. Perkirakan galat model asli e^orig^ = L(y, f(X)) (mis., mean squared error)
2. Untuk setiap fitur j = 1,...,p lakukan:
    - Hasilkan matriks fitur X^perm^ dengan mengubah fitur j dalam data X. Ini memutuskan hubungan antara fitur j dan hasil sebenarnya y.
    - Estimasi kesalahan e^perm^ = L(Y,f(X^perm^)) berdasarkan prediksi data yang diizinkan.
    - Hitung permutation feature importance FI^j^= e^perm^/e^orig^. Atau, perbedaannya dapat digunakan: FI^j^ = e^perm^ - e^orig^
3. Urutkan fitur berdasarkan FI turun.

Fisher, Rudin, dan Dominici (2018) menyarankan dalam makalah mereka untuk membagi dataset menjadi dua dan menukar nilai fitur j dari dua bagian alih-alih mengubah fitur j.
Ini persis sama dengan mengubah fitur j, jika Anda memikirkannya.
Jika Anda menginginkan perkiraan yang lebih akurat, Anda dapat memperkirakan kesalahan permutasi fitur j dengan memasangkan setiap instance dengan nilai fitur j dari setiap instance lainnya (kecuali dengan dirinya sendiri).
Ini memberi Anda kumpulan data berukuran `n(n-1)` untuk memperkirakan kesalahan permutasi, dan ini membutuhkan banyak waktu komputasi.
Saya hanya dapat merekomendasikan penggunaan metode `n(n-1)` jika Anda serius ingin mendapatkan perkiraan yang sangat akurat.


### Should I Compute Importance on Training or Test Data? {#feature-importance-data}


```{r prepare-garbage-svm}
set.seed(1)
n = 200
p = 50
X = data.frame(matrix(rnorm(n*p), nrow = n))
y = rnorm(n)
dat = cbind(X, y)
tsk = makeRegrTask(data = dat, target = "y")

X2 = data.frame(matrix(rnorm(n*p), nrow = n))
y2 = rnorm(n)
dat2 = cbind(X2, y = y2)
tsk2 = makeRegrTask(data = dat2, target = "y")

lrn = makeLearner("regr.svm")
mod = mlr::train(lrn, tsk)
pred = predict(mod, tsk)
perf1 = mlr::performance(pred, measures = list(mlr::mae))

pred2 = predict(mod, tsk2)
perf2 = mlr::performance(pred2, measures = list(mlr::mae))

```


*tl;dr: Saya tidak punya jawaban pasti.*

Menjawab pertanyaan tentang data pelatihan atau pengujian menyentuh pertanyaan mendasar tentang feature importance.
Cara terbaik untuk memahami perbedaan antara feature importance berdasarkan pelatihan vs. berdasarkan data pengujian adalah contoh "ekstrim".
Saya melatih support vector machine untuk memprediksi hasil target acak yang berkelanjutan dengan 50 fitur acak (200 contoh).
Yang saya maksud dengan "acak" adalah hasil target tidak bergantung pada 50 fitur.
Ini seperti memprediksi suhu besok mengingat nomor lotere terbaru.
Jika model "mempelajari" hubungan apa pun, maka model itu terlalu cocok.
Dan faktanya, SVM melakukan overfit pada data pelatihan.
Kesalahan absolut rata-rata (singkat: mae) untuk data pelatihan adalah `r round(perf1,2)` dan untuk data uji `r round(perf2,2)`, yang juga merupakan kesalahan model terbaik yang selalu memprediksi hasil rata-rata dari 0 (mae dari `r round(mean(abs(y2)),2)`).
Dengan kata lain, model SVM adalah sampah.
Nilai apa untuk feature importance yang Anda harapkan untuk 50 fitur dari SVM yang dilebih-lebihkan ini?
Nol karena tidak ada fitur yang berkontribusi pada peningkatan kinerja pada data pengujian yang tidak terlihat?
Atau haruskah kepentingan mencerminkan seberapa besar model bergantung pada masing-masing fitur, terlepas dari apakah hubungan yang dipelajari digeneralisasikan ke data yang tidak terlihat?
Mari kita lihat bagaimana distribusi feature importance untuk data pelatihan dan pengujian berbeda.

```{r feature-imp-sim, fig.cap="Distributions of feature importance values by data type. An SVM was trained on a regression dataset with 50 random features and 200 instances. The SVM overfits the data: Feature importance based on the training data shows many important features. Computed on unseen test data, the feature importances are close to a ratio of one (=unimportant)."}
pred = Predictor$new(mod, cbind(X, y = y), y = "y")
imp = FeatureImp$new(pred, loss = "mae")

pred2 = Predictor$new(mod, cbind(X2, y = y2), y = "y")
imp2 = FeatureImp$new(pred2, loss = "mae")

imp$results$dat.type = "Training data"
imp2$results$dat.type = "Test data"

imp.dat = rbind(imp$results, imp2$results)

ggplot(imp.dat) + geom_boxplot(aes(x = dat.type, y = importance)) + 
  scale_y_continuous("Feature importance of all features") + 
  scale_x_discrete("")
```

Tidak jelas bagi saya mana dari dua hasil yang lebih diinginkan.
Jadi saya akan mencoba membuat kasus untuk kedua versi dan membiarkan Anda memutuskan sendiri.

**Kasus untuk data uji**

Ini adalah kasus sederhana:
Estimasi kesalahan model berdasarkan data pelatihan adalah sampah feature importance bergantung pada perkiraan kesalahan model feature importance berdasarkan data pelatihan adalah sampah.
Sungguh, ini adalah salah satu hal pertama yang Anda pelajari dalam machine learning:
Jika Anda mengukur kesalahan model (atau kinerja) pada data yang sama di mana model dilatih, pengukuran biasanya terlalu optimis, yang berarti bahwa model tersebut tampaknya bekerja jauh lebih baik daripada kenyataannya.
Dan karena permutation feature importance bergantung pada pengukuran kesalahan model, kita harus menggunakan data uji yang tidak terlihat.
Feature importance berdasarkan data pelatihan membuat kita keliru percaya bahwa feature importance untuk prediksi, padahal pada kenyataannya model hanya overfitting dan fitur tidak penting sama sekali.

**Kasus untuk data pelatihan**

```{r garbage-svm-mvp}
max.imp = imp$results[imp$results$importance == max(imp$results$importance),]
```

Argumen untuk menggunakan data pelatihan agak lebih sulit untuk dirumuskan, tetapi IMHO sama menariknya dengan argumen untuk menggunakan data uji.
Kami melihat lagi SVM sampah kami.
Berdasarkan data pelatihan, fitur yang paling penting adalah `r max.imp$feature`.
Mari kita lihat partial dependence plot fitur `r max.imp$feature`.
Partial dependence plot menunjukkan bagaimana output model berubah berdasarkan perubahan fitur dan tidak bergantung pada kesalahan generalisasi.
Tidak masalah apakah PDP dihitung dengan data pelatihan atau uji.

```{r garbage-svm-pdp, fig.cap=sprintf("PDP of feature %s, which is the most important feature according to the feature importance based on the training data. The plot shows how the SVM depends on this feature to make predictions", max.imp$feature)}
pdp = FeatureEffect$new(pred2, max.imp$feature, method = "pdp")
pdp$plot()
```

Plot dengan jelas menunjukkan bahwa SVM telah belajar untuk mengandalkan fitur `r max.imp$feature` untuk prediksinya, tetapi menurut feature importance berdasarkan data pengujian (`r round(imp2$results[imp2 $results$feature == max.imp$feature, "importance"], 2)`), tidak penting.
Berdasarkan data pelatihan, kepentingannya adalah `r round(max.imp$importance, 2)`, yang mencerminkan bahwa model telah belajar menggunakan fitur ini.
Feature importance berdasarkan data pelatihan memberi tahu kita fitur mana yang penting untuk model dalam arti bahwa fitur tersebut bergantung pada fitur tersebut untuk membuat prediksi.

Sebagai bagian dari kasus penggunaan data pelatihan, saya ingin memperkenalkan argumen yang menentang data pengujian.
Dalam praktiknya, Anda ingin menggunakan semua data Anda untuk melatih model Anda untuk mendapatkan model terbaik pada akhirnya.
Ini berarti tidak ada data uji yang tidak digunakan yang tersisa untuk menghitung feature importance.
Anda memiliki masalah yang sama ketika Anda ingin memperkirakan kesalahan generalisasi model Anda.
Jika Anda akan menggunakan validasi silang (bersarang) untuk estimasi feature importance, Anda akan memiliki masalah bahwa feature importance tidak dihitung pada model akhir dengan semua data, tetapi pada model dengan himpunan bagian dari data yang mungkin berperilaku berbeda.

Pada akhirnya, Anda perlu memutuskan apakah Anda ingin mengetahui seberapa besar model bergantung pada setiap fitur untuk membuat prediksi (-> data pelatihan) atau seberapa besar fitur berkontribusi pada kinerja model pada data yang tidak terlihat (-> data uji ).
Sejauh pengetahuan saya, tidak ada penelitian yang membahas pertanyaan pelatihan vs. data uji.
Ini akan membutuhkan pemeriksaan yang lebih menyeluruh daripada contoh "garbage-SVM" saya.
Kami membutuhkan lebih banyak penelitian dan lebih banyak pengalaman dengan alat-alat ini untuk mendapatkan pemahaman yang lebih baik.

Selanjutnya, kita akan melihat beberapa contoh.
Saya mendasarkan perhitungan pentingnya pada data pelatihan, karena saya harus memilih satu dan menggunakan data pelatihan membutuhkan beberapa baris kode lebih sedikit.

### Example and Interpretation

Saya menunjukkan contoh untuk klasifikasi dan regresi.

**Kanker serviks (klasifikasi)**

Kami menyesuaikan model random forest untuk memprediksi [kanker serviks](#cervical).
Kami mengukur peningkatan kesalahan sebesar 1-AUC (1 dikurangi area di bawah kurva ROC).
Fitur yang terkait dengan peningkatan kesalahan model dengan faktor 1 (= tidak ada perubahan) tidak penting untuk memprediksi kanker serviks.

```{r}
library('mlr')
library('iml')
data("cervical")
task = makeClassifTask(data = cervical, target = "Biopsy", positive = "Cancer")
learner = makeLearner('classif.randomForest', predict.type = 'prob')
mod = mlr::train(learner, task)
predictor = Predictor$new(mod, data = cervical[-which(names(cervical) == "Biopsy")], y = (cervical$Biopsy == "Cancer"), class = "Cancer")
auc_error = function(actual, predicted) 1 - Metrics::auc(actual, predicted)
importance = FeatureImp$new(predictor, loss = auc_error)
imp.dat = data.frame(importance$results[c("feature", "permutation.error", "importance")])
most_imp = imp.dat$feature[imp.dat$importance == max(imp.dat$importance)]
```

```{r importance-cervical, fig.cap = sprintf("The importance of each of the features for predicting cervical cancer with a random forest. The most important feature was %s. Permuting %s resulted in an increase in 1-AUC by a factor of %.2f", most_imp, most_imp, max(imp.dat$importance))}
plot(importance) +
  scale_x_continuous("Feature importance (loss: 1 - AUC)") +
   scale_y_discrete("")
```


Fitur dengan kepentingan tertinggi adalah `r imp.dat[1, 'feature']` terkait dengan peningkatan kesalahan `r round(imp.dat[1,'importance'], 2)` setelah permutasi .

**Berbagi sepeda (regresi)**

Kami menyesuaikan model support vector machine untuk memprediksi [jumlah sepeda yang disewa](#bike-data), dengan kondisi cuaca dan informasi kalender.
Sebagai pengukuran kesalahan, kami menggunakan kesalahan absolut rata-rata.


```{r}
data("bike")
task = makeRegrTask(data = bike, target = "cnt")
learner = makeLearner('regr.svm')
mod = mlr::train(learner, task)
predictor = Predictor$new(mod, data = bike[-which(names(bike) == "cnt")], y = bike$cnt)
importance = FeatureImp$new(predictor, loss = 'mae')
imp.dat = importance$results
best = which(imp.dat$importance == max(imp.dat$importance))
worst = which(imp.dat$importance == min(imp.dat$importance)) 
```


```{r importance-bike, fig.cap = sprintf("The importance for each of the features in predicting bike counts with a support vector machine. The most important feature was %s, the least important was %s.", imp.dat$feature[best], imp.dat$feature[worst])}
plot(importance) +
   scale_y_discrete("")
```


### Advantages

**Interpretasi yang bagus**: feature importance adalah peningkatan kesalahan model ketika informasi fitur dihancurkan.

Feature importance memberikan **wawasan global yang sangat padat** tentang perilaku model.

Aspek positif dari penggunaan rasio kesalahan alih-alih perbedaan kesalahan adalah bahwa pengukuran feature importance **dapat dibandingkan di berbagai masalah**.

Ukuran kepentingan secara otomatis **memperhitungkan semua interaksi** dengan fitur lain.
Dengan mengubah fitur tersebut, Anda juga menghancurkan efek interaksi dengan fitur lainnya.
Ini berarti bahwa permutation feature importance memperhitungkan efek fitur utama dan efek interaksi pada kinerja model.
Ini juga merupakan loss karena pentingnya interaksi antara dua fitur termasuk dalam pengukuran kepentingan dari kedua fitur.
Ini berarti bahwa feature importance tidak menambah total penurunan kinerja, tetapi jumlahnya lebih besar.
Hanya jika tidak ada interaksi antara fitur, seperti dalam model linier, kepentingannya bertambah kira-kira.

Permutation feature importance **tidak memerlukan pelatihan ulang model**.
Beberapa metode lain menyarankan untuk menghapus fitur, melatih kembali model, dan kemudian membandingkan kesalahan model.
Karena pelatihan ulang model machine learning dapat memakan waktu lama, "hanya" mengubah permutasi fitur dapat menghemat banyak waktu.
Metode urgensi yang melatih kembali model dengan subset fitur tampak intuitif pada pandangan pertama, tetapi model dengan data yang dikurangi tidak ada artinya untuk urgensi fitur.
Kami tertarik pada feature importance model tetap.
Pelatihan ulang dengan kumpulan data yang dikurangi menciptakan model yang berbeda dari yang kami minati.
Misalkan Anda melatih sparse linear models (dengan Lasso) dengan sejumlah fitur tetap dengan bobot bukan nol.
Dataset memiliki 100 fitur, Anda mengatur jumlah bobot bukan nol menjadi 5.
Anda menganalisis pentingnya salah satu fitur yang memiliki bobot bukan nol.
Anda menghapus fitur dan melatih kembali modelnya.
Performa model tetap sama karena fitur lain yang sama baiknya mendapat bobot bukan nol dan kesimpulan Anda adalah bahwa fitur tersebut tidak penting.
Contoh lain:
Modelnya adalah decision trees dan kami menganalisis feature importance yang dipilih sebagai pemisahan pertama.
Anda menghapus fitur dan melatih kembali modelnya.
Karena fitur lain dipilih sebagai pemisahan pertama, seluruh pohon bisa sangat berbeda, yang berarti bahwa kami membandingkan tingkat kesalahan (berpotensi) pohon yang sama sekali berbeda untuk memutuskan seberapa penting fitur tersebut untuk salah satu pohon.

### Disadvantages

Sangat **tidak jelas apakah Anda harus menggunakan data pelatihan atau pengujian** untuk menghitung feature importance.

Permutation feature importance **terkait dengan kesalahan model**.
Ini pada dasarnya tidak buruk, tetapi dalam beberapa kasus bukan yang Anda butuhkan.
Dalam beberapa kasus, Anda mungkin lebih suka mengetahui seberapa besar variasi keluaran model untuk suatu fitur tanpa mempertimbangkan apa artinya bagi kinerja.
Misalnya, Anda ingin mengetahui seberapa kuat keluaran model Anda saat seseorang memanipulasi fitur.
Dalam hal ini, Anda tidak akan tertarik pada seberapa besar penurunan performa model saat fitur di- permutasi, tetapi seberapa banyak varians output model yang dijelaskan oleh setiap fitur.
Varians model (dijelaskan oleh fitur) dan feature importance berkorelasi kuat ketika model digeneralisasi dengan baik (yaitu tidak overfit).

Anda **membutuhkan akses ke hasil yang sebenarnya**.
Jika seseorang hanya memberi Anda model dan data yang tidak berlabel -- tetapi bukan hasil yang sebenarnya -- Anda tidak dapat menghitung permutation feature importance.

Permutation feature importance tergantung pada pengocokan fitur, yang menambahkan keacakan pada pengukuran.
Ketika permutasi diulang, **hasilnya mungkin sangat berbeda**.
Mengulangi permutasi dan merata-ratakan ukuran kepentingan di atas pengulangan menstabilkan ukuran, tetapi meningkatkan waktu komputasi.

Jika fitur berkorelasi, permutation feature importance **dapat dibias oleh instance data yang tidak realistis**.
Masalahnya sama dengan [partial dependence plot](#pdp):
Permutasi fitur menghasilkan contoh data yang tidak mungkin ketika dua atau lebih fitur dikorelasikan.
Ketika mereka berkorelasi positif (seperti tinggi dan berat seseorang) dan saya mengacak salah satu fitur, saya membuat instance baru yang tidak mungkin atau bahkan tidak mungkin secara fisik (misalnya 2 meter orang dengan berat 30 kg), namun saya menggunakan instance baru ini untuk mengukur pentingnya.
Dengan kata lain, untuk permutation feature importance dari fitur yang berkorelasi, kami mempertimbangkan seberapa besar kinerja model menurun ketika kami menukar fitur dengan nilai yang tidak akan pernah kami amati dalam kenyataan.
Periksa apakah fitur berkorelasi kuat dan berhati-hatilah dengan interpretasi feature importance jika memang demikian.

Hal rumit lainnya:
**Menambahkan fitur yang berkorelasi dapat mengurangi feature importance terkait** dengan membagi kepentingan di antara kedua fitur tersebut.
Biarkan saya memberi Anda contoh tentang apa yang saya maksud dengan feature importance "pemisahan":
Kami ingin memprediksi kemungkinan hujan dan menggunakan suhu pada pukul 8:00 pagi hari sebelumnya sebagai fitur bersama dengan fitur lain yang tidak berkorelasi.
Saya melatih random forest dan ternyata suhu adalah fitur yang paling penting dan semuanya baik-baik saja dan saya tidur nyenyak malam berikutnya.
Sekarang bayangkan skenario lain di mana saya juga menyertakan suhu pada jam 9:00 pagi sebagai fitur yang sangat berkorelasi dengan suhu pada jam 8:00 pagi.
Suhu pada jam 9:00 pagi tidak memberi saya banyak informasi tambahan jika saya sudah mengetahui suhu pada jam 8:00 pagi.
Tetapi memiliki lebih banyak fitur selalu bagus, bukan?
Saya melatih random forest dengan dua fitur suhu dan fitur yang tidak berkorelasi.
Beberapa pohon di random forest mengambil suhu 8:00 pagi, yang lain suhu 9:00 pagi, lagi yang lain keduanya dan lagi yang lain tidak sama sekali.
Kedua fitur suhu bersama-sama memiliki sedikit lebih penting daripada fitur suhu tunggal sebelumnya, tetapi alih-alih berada di urutan teratas daftar fitur penting, masing-masing suhu sekarang berada di tengah.
Dengan memperkenalkan fitur yang berkorelasi, saya menendang fitur yang paling penting dari puncak tangga kepentingan menjadi biasa-biasa saja.
Di satu sisi ini baik-baik saja, karena ini hanya mencerminkan perilaku model machine learning yang mendasarinya, di sini random forest.
Suhu pukul 08:00 menjadi kurang penting karena model sekarang dapat mengandalkan pengukuran pukul 09:00 juga.
Di sisi lain, itu membuat interpretasi feature importance jauh lebih sulit.
Bayangkan Anda ingin memeriksa fitur untuk kesalahan pengukuran.
Cek itu mahal dan Anda memutuskan untuk memeriksa hanya 3 fitur terpenting.
Dalam kasus pertama Anda akan memeriksa suhu, dalam kasus kedua Anda tidak akan menyertakan fitur suhu hanya karena mereka sekarang berbagi kepentingan.
Meskipun nilai kepentingan mungkin masuk akal pada tingkat perilaku model, akan membingungkan jika Anda memiliki fitur yang berkorelasi.


### Software and Alternatives

Paket `iml` R digunakan sebagai contoh.
Paket R `DALEX` dan `vip`, serta library Python `alibi`, `scikit-learn` dan `rfpimp`, juga mengimplementasikan permutation feature importance model-agnostic.

Algoritme yang disebut [PIMP](https://academic.oup.com/bioinformatics/article/26/10/1340/193348) mengadaptasi algoritme urgensi fitur untuk memberikan p-value untuk urgensi.


[^Breiman2001]: Breiman, Leo.“Random Forests.” Machine Learning 45 (1). Springer: 5-32 (2001).

[^Fisher2018]: Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. “All Models are Wrong, but Many are Useful: Learning a Variable's Importance by Studying an Entire Class of Prediction Models Simultaneously.” http://arxiv.org/abs/1801.01489 (2018).

