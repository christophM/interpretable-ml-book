<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-11-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="the-future-of-machine-learning.html">
<link rel="next" href="contribute.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>2.1</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>2.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="2.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>2.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a><ul>
<li class="chapter" data-level="3.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>3.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="3.2" data-path="criteria-for-interpretability-methods.html"><a href="criteria-for-interpretability-methods.html"><i class="fa fa-check"></i><b>3.2</b> Criteria for Interpretability Methods</a></li>
<li class="chapter" data-level="3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>3.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="3.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>3.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="3.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>3.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="3.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>3.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="3.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>3.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="3.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>3.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>3.4</b> Evaluating Interpretability</a></li>
<li class="chapter" data-level="3.5" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>3.5</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="3.5.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>3.5.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="3.5.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>3.5.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Datasets</a><ul>
<li class="chapter" data-level="4.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>4.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="4.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>4.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="4.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>4.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable Models</a><ul>
<li class="chapter" data-level="5.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.1</b> Linear Regression Model</a><ul>
<li class="chapter" data-level="5.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.1.2" data-path="limo.html"><a href="limo.html#interpretation-example"><i class="fa fa-check"></i><b>5.1.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="5.1.3" data-path="limo.html"><a href="limo.html#interpretation-templates"><i class="fa fa-check"></i><b>5.1.3</b> Interpretation Templates</a></li>
<li class="chapter" data-level="5.1.4" data-path="limo.html"><a href="limo.html#visual-parameter-interpretation"><i class="fa fa-check"></i><b>5.1.4</b> Visual Parameter Interpretation</a></li>
<li class="chapter" data-level="5.1.5" data-path="limo.html"><a href="limo.html#explaining-single-predictions"><i class="fa fa-check"></i><b>5.1.5</b> Explaining Single Predictions</a></li>
<li class="chapter" data-level="5.1.6" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>5.1.6</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="5.1.7" data-path="limo.html"><a href="limo.html#the-disadvantages-of-linear-models"><i class="fa fa-check"></i><b>5.1.7</b> The disadvantages of linear models</a></li>
<li class="chapter" data-level="5.1.8" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>5.1.8</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="5.1.9" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>5.1.9</b> Sparse Linear Models</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>5.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>5.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic.html"><a href="logistic.html#logistic-regression"><i class="fa fa-check"></i><b>5.2.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>5.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.4" data-path="logistic.html"><a href="logistic.html#example"><i class="fa fa-check"></i><b>5.2.4</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>5.3</b> Linear Model 2.0 - GLMs, GAMs and more</a><ul>
<li class="chapter" data-level="5.3.1" data-path="extend-lm.html"><a href="extend-lm.html#non-gaussian-outcomes---glms"><i class="fa fa-check"></i><b>5.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="5.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>5.3.2</b> Interactions</a></li>
<li class="chapter" data-level="5.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>5.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="5.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages"><i class="fa fa-check"></i><b>5.3.4</b> Advantages</a></li>
<li class="chapter" data-level="5.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages"><i class="fa fa-check"></i><b>5.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>5.3.6</b> Further extensions</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>5.4</b> Decision Tree</a><ul>
<li class="chapter" data-level="5.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>5.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.4.2" data-path="tree.html"><a href="tree.html#interpretation-example-1"><i class="fa fa-check"></i><b>5.4.2</b> Interpretation Example</a></li>
<li class="chapter" data-level="5.4.3" data-path="tree.html"><a href="tree.html#advantages-1"><i class="fa fa-check"></i><b>5.4.3</b> Advantages</a></li>
<li class="chapter" data-level="5.4.4" data-path="tree.html"><a href="tree.html#disadvantages-1"><i class="fa fa-check"></i><b>5.4.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>5.5</b> Decision Rules (IF-THEN)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>5.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="5.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>5.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="5.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>5.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="5.5.4" data-path="rules.html"><a href="rules.html#advantages-2"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="rules.html"><a href="rules.html#disadvantages-2"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>5.6</b> RuleFit</a><ul>
<li class="chapter" data-level="5.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>5.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="5.6.2" data-path="rulefit.html"><a href="rulefit.html#guidelines"><i class="fa fa-check"></i><b>5.6.2</b> Guidelines</a></li>
<li class="chapter" data-level="5.6.3" data-path="rulefit.html"><a href="rulefit.html#theory"><i class="fa fa-check"></i><b>5.6.3</b> Theory</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>5.7</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="5.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.7.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="5.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>5.7.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="5.7.3" data-path="other-interpretable.html"><a href="other-interpretable.html#and-so-many-more"><i class="fa fa-check"></i><b>5.7.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="6.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>6.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="6.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>6.1.1</b> Examples</a></li>
<li class="chapter" data-level="6.1.2" data-path="pdp.html"><a href="pdp.html#advantages-3"><i class="fa fa-check"></i><b>6.1.2</b> Advantages</a></li>
<li class="chapter" data-level="6.1.3" data-path="pdp.html"><a href="pdp.html#disadvantages-3"><i class="fa fa-check"></i><b>6.1.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>6.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="ice.html"><a href="ice.html#example-1"><i class="fa fa-check"></i><b>6.2.1</b> Example</a></li>
<li class="chapter" data-level="6.2.2" data-path="ice.html"><a href="ice.html#advantages-4"><i class="fa fa-check"></i><b>6.2.2</b> Advantages</a></li>
<li class="chapter" data-level="6.2.3" data-path="ice.html"><a href="ice.html#disadvantages-4"><i class="fa fa-check"></i><b>6.2.3</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>6.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="6.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>6.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="6.3.2" data-path="ale.html"><a href="ale.html#theory-1"><i class="fa fa-check"></i><b>6.3.2</b> Theory</a></li>
<li class="chapter" data-level="6.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>6.3.3</b> Estimation</a></li>
<li class="chapter" data-level="6.3.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>6.3.4</b> Examples</a></li>
<li class="chapter" data-level="6.3.5" data-path="ale.html"><a href="ale.html#advantages-5"><i class="fa fa-check"></i><b>6.3.5</b> Advantages</a></li>
<li class="chapter" data-level="6.3.6" data-path="ale.html"><a href="ale.html#disadvantages-5"><i class="fa fa-check"></i><b>6.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>6.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>6.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="6.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>6.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="6.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>6.4.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="6.4.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>6.4.3</b> Examples</a></li>
<li class="chapter" data-level="6.4.4" data-path="interaction.html"><a href="interaction.html#advantages-6"><i class="fa fa-check"></i><b>6.4.4</b> Advantages</a></li>
<li class="chapter" data-level="6.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-6"><i class="fa fa-check"></i><b>6.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="6.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>6.4.6</b> Implementations</a></li>
<li class="chapter" data-level="6.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>6.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>6.5</b> Feature Importance</a><ul>
<li class="chapter" data-level="6.5.1" data-path="feature-importance.html"><a href="feature-importance.html#the-theory"><i class="fa fa-check"></i><b>6.5.1</b> The Theory</a></li>
<li class="chapter" data-level="6.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>6.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="6.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>6.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="6.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-7"><i class="fa fa-check"></i><b>6.5.4</b> Advantages</a></li>
<li class="chapter" data-level="6.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-7"><i class="fa fa-check"></i><b>6.5.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>6.6</b> Global Surrogate Models</a><ul>
<li class="chapter" data-level="6.6.1" data-path="global.html"><a href="global.html#theory-2"><i class="fa fa-check"></i><b>6.6.1</b> Theory</a></li>
<li class="chapter" data-level="6.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>6.6.2</b> Example</a></li>
<li class="chapter" data-level="6.6.3" data-path="global.html"><a href="global.html#advantages-8"><i class="fa fa-check"></i><b>6.6.3</b> Advantages</a></li>
<li class="chapter" data-level="6.6.4" data-path="global.html"><a href="global.html#disadvantages-8"><i class="fa fa-check"></i><b>6.6.4</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>6.7</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="6.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>6.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="6.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>6.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="6.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>6.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="6.7.4" data-path="lime.html"><a href="lime.html#advantages-9"><i class="fa fa-check"></i><b>6.7.4</b> Advantages</a></li>
<li class="chapter" data-level="6.7.5" data-path="lime.html"><a href="lime.html#disadvantages-9"><i class="fa fa-check"></i><b>6.7.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>6.8</b> Shapley Value Explanations</a><ul>
<li class="chapter" data-level="6.8.1" data-path="shapley.html"><a href="shapley.html#the-general-idea"><i class="fa fa-check"></i><b>6.8.1</b> The general idea</a></li>
<li class="chapter" data-level="6.8.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>6.8.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="6.8.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>6.8.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="6.8.4" data-path="shapley.html"><a href="shapley.html#advantages-10"><i class="fa fa-check"></i><b>6.8.4</b> Advantages</a></li>
<li class="chapter" data-level="6.8.5" data-path="shapley.html"><a href="shapley.html#disadvantages-10"><i class="fa fa-check"></i><b>6.8.5</b> Disadvantages</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>7</b> Example-based Explanations</a><ul>
<li class="chapter" data-level="7.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>7.1</b> Counterfactual explanations</a><ul>
<li class="chapter" data-level="7.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>7.1.1</b> Generating counterfactual explanations</a></li>
<li class="chapter" data-level="7.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>7.1.2</b> Examples</a></li>
<li class="chapter" data-level="7.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-11"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-11"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>7.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>7.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="7.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>7.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="7.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>7.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>7.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="7.3.1" data-path="proto.html"><a href="proto.html#theory-3"><i class="fa fa-check"></i><b>7.3.1</b> Theory</a></li>
<li class="chapter" data-level="7.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>7.3.2</b> Examples</a></li>
<li class="chapter" data-level="7.3.3" data-path="proto.html"><a href="proto.html#advantages-12"><i class="fa fa-check"></i><b>7.3.3</b> Advantages</a></li>
<li class="chapter" data-level="7.3.4" data-path="proto.html"><a href="proto.html#disadvantages-12"><i class="fa fa-check"></i><b>7.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>7.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>7.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="7.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>7.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="7.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>7.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="7.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>7.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="7.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>7.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="7.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>7.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>8</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="8.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>8.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="8.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>8.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>9</b> Contribute</a></li>
<li class="chapter" data-level="10" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>10</b> Citation</a></li>
<li class="chapter" data-level="11" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>11</b> Acknowledgements</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-future-of-interpretability" class="section level2">
<h2><span class="header-section-number">8.2</span> The Future of Interpretability</h2>
<p>Let’s take a look at where machine learning interpretability might be going.</p>
<p><strong>The focus will be on model-agnostic interpretability tools.</strong></p>
<p>It is way easier to automate interpretability if it is decoupled from the underlying machine learning model. The advantage of model-agnostic interpretability is the modularity: We can easily replace the underlying machine learning model. We can just as easily replace the interpretability method. For these reasons, model-agnostic methods will scale much better. That’s why I believe that model-agnostic methods will become more dominant in the long term. But intrinsically interpretable methods will also have their place.</p>
<p><strong>Machine learning will be automatic and so will be interpretability.</strong></p>
<p>An already visible trend is the complete automation of model fitting: That includes the automated engineering and selection of features, automated hyperparameter optimization, comparison of different models, and ensembling or stacking of the models. The result is the best possible prediction model. When we use model-agnostic interpretation methods, we can automatically apply them on any model that emerges from the automated machine learning process. In a way, we can automate this second step as well: Automatically compute the feature importance, plot the partial dependence, fit a surrogate model and so on. Nobody stops you from automatically computing all these model interpretations. Humans will still be needed for the actual interpretation. Imagine yourself: You only upload a dataset, specify the prediction goal and, at the push of a button, the best prediction model is fitted and the program spits out all interpretations of the model. Solutions already exist and I argue that it will be sufficient for many applications to use these automated machine learning services. Today anyone can build websites without knowing HTML, CSS and Javascript but there are still web developers around. Similarly, I believe anyone will be able to train machine learning models without knowing how to program and there will still be a need for machine learning experts.</p>
<p><strong>We don’t analyze data, we analyze models.</strong></p>
<p>The raw data itself is always useless (I exaggerate on purpose). I don’t care about the data; I do care about the knowledge distilled from the data. Interpretable machine learning is a great way to distill knowledge from data. You can probe the model extensively, the model automatically recognizes if and how features are relevant to the prediction (many models have built-in feature selection), the model can automatically recognize how the relationships are represented the best and - if trained correctly - the final model is the best possible approximation to reality.</p>
<p>Many analytical tools are already based on data models (because they are based on distribution assumptions):</p>
<ul>
<li>Simple hypothesis tests like Student’s t-test.</li>
<li>Hypothesis tests with adjustments for confounders (usually GLMs)</li>
<li>Analysis of Variance (ANOVA)</li>
<li>The correlation coefficient (the standardized linear regression coefficient is the same as Pearson’s correlation coefficient)</li>
<li>…</li>
</ul>
<p>So what I am telling you here is actually nothing new. So why switch from analyzing assumption-based, transparent models to analyzing assumption-free black box models? Because making all these assumptions is problematic: They are usually wrong (unless you believe that most of the world follows a Gaussian distribution), difficult to check, very restricting for the relationships the model can represent and hard to automate. Assumption-based models typically have worse predictive performance on untouched test data than black box machine learning models. This is only true for big data sets, since interpretable models with good assumptions will perform better than black box models with many parameters. The black box machine learning approach needs a lot of data to work well. Because of the digitization of everything, we will have bigger and bigger datasets and therefore the approach of machine learning becomes more attractive: We don’t make assumptions, we approximate reality as closely as possible (while avoiding overfitting on the training data). I argue that we should develop all the tools that we have in statistics to answer questions (hypothesis tests, correlation measures, interaction measures, visualization tools, confidence intervals, p-values, prediction intervals, probability distributions) and rewrite them for black box models. In a way, this is already happening:</p>
<ul>
<li>Let’s take a classic linear model: The standardized regression coefficient is already a feature importance measure. With the <a href="feature-importance.html#feature-importance">permutation feature importance measure</a>, we have a tool that works with any model.</li>
<li>In a linear model, the coefficients measures the effect of a single feature on the predicted outcome. The generalized version of this is the <a href="pdp.html#pdp">partial dependence plot</a>.</li>
<li>Test whether A or B is better: For this we can also use partial dependence functions. What we don’t have yet (to the best of my best knowledge) are statistical tests for arbitrary black box models.</li>
</ul>
<p><strong>The data scientists will automate themselves.</strong></p>
<p>I believe that data scientists will eventually automate themselves out of the job for many analysis and forecasting tasks. For this to happen the tasks must be well-defined and there must to be some processes and routine around them. Today, these routines and processes are missing, but data scientists and colleagues are working on them. As machine learning becomes an integral part of many industries and institutions, many of the tasks that are currently being figured out will be automated.</p>
<p><strong>Robots and programs will explain themselves.</strong></p>
<p>We need more intuitive interfaces to machines and programs that make heavy use of machine learning. Some examples: A self-driving car that reports why it stopped abruptly (“70% probability that a kid will cross the road”); A credit default program that explains to a bank employee why a credit application was rejected (“Applicant has too many credit cards and is employed in an unstable job.”); A robot arm that explains why it moved the item from the conveyor belt into the trash bin (“The item has a craze at the bottom.”).</p>
<p><strong>Interpretability could boost machine intelligence research.</strong></p>
<p>I can imagine that by doing more research on how programs and machines can explain themselves, we can improve improve our understanding of intelligence and we will become better at creating intelligent machines.</p>
<p>In the end, all these predictions are speculations we have to see what the future really brings. Form your own opinion and continue learning!</p>

</div>
<!-- </div> -->
            </section>

          </div>
        </div>
      </div>
<a href="the-future-of-machine-learning.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="contribute.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/07-future.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
