<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8.3 Feature Interaction | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="8.3 Feature Interaction | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8.3 Feature Interaction | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2021-10-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ale.html"/>
<link rel="next" href="decomposition.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="1" data-path="preface-by-the-author.html"><a href="preface-by-the-author.html"><i class="fa fa-check"></i><b>1</b> Preface by the Author</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>2.1</b> Story Time</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>2.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="2.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>2.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>3</b> Interpretability</a><ul>
<li class="chapter" data-level="3.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>3.1</b> Importance of Interpretability</a></li>
<li class="chapter" data-level="3.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>3.2</b> Taxonomy of Interpretability Methods</a></li>
<li class="chapter" data-level="3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>3.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="3.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>3.3.1</b> Algorithm Transparency</a></li>
<li class="chapter" data-level="3.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>3.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="3.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>3.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="3.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>3.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="3.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>3.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="evaluation-of-interpretability.html"><a href="evaluation-of-interpretability.html"><i class="fa fa-check"></i><b>3.4</b> Evaluation of Interpretability</a></li>
<li class="chapter" data-level="3.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>3.5</b> Properties of Explanations</a></li>
<li class="chapter" data-level="3.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>3.6</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="3.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>3.6.1</b> What Is an Explanation?</a></li>
<li class="chapter" data-level="3.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>3.6.2</b> What Is a Good Explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>4</b> Datasets</a><ul>
<li class="chapter" data-level="4.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>4.1</b> Bike Rentals (Regression)</a></li>
<li class="chapter" data-level="4.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>4.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="4.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>4.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>5</b> Interpretable Models</a><ul>
<li class="chapter" data-level="5.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>5.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="5.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>5.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>5.1.2</b> Example</a></li>
<li class="chapter" data-level="5.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>5.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="5.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>5.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="5.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>5.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="5.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>5.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="5.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>5.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="5.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>5.1.8</b> Advantages</a></li>
<li class="chapter" data-level="5.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>5.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>5.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="5.2.1" data-path="logistic.html"><a href="logistic.html#what-is-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>5.2.1</b> What is Wrong with Linear Regression for Classification?</a></li>
<li class="chapter" data-level="5.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>5.2.2</b> Theory</a></li>
<li class="chapter" data-level="5.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>5.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="5.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>5.2.4</b> Example</a></li>
<li class="chapter" data-level="5.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>5.2.5</b> Advantages and Disadvantages</a></li>
<li class="chapter" data-level="5.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>5.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>5.3</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="5.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>5.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="5.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>5.3.2</b> Interactions</a></li>
<li class="chapter" data-level="5.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>5.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="5.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>5.3.4</b> Advantages</a></li>
<li class="chapter" data-level="5.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>5.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>5.3.6</b> Software</a></li>
<li class="chapter" data-level="5.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>5.3.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>5.4</b> Decision Tree</a><ul>
<li class="chapter" data-level="5.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>5.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="5.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>5.4.2</b> Example</a></li>
<li class="chapter" data-level="5.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>5.4.3</b> Advantages</a></li>
<li class="chapter" data-level="5.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>5.4.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>5.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>5.5</b> Decision Rules</a><ul>
<li class="chapter" data-level="5.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>5.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="5.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>5.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="5.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>5.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="5.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>5.6</b> RuleFit</a><ul>
<li class="chapter" data-level="5.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>5.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="5.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>5.6.2</b> Theory</a></li>
<li class="chapter" data-level="5.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>5.6.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>5.7</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="5.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>5.7.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="5.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>5.7.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>6</b> Model-Agnostic Methods</a></li>
<li class="chapter" data-level="7" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>7</b> Example-Based Explanations</a></li>
<li class="chapter" data-level="8" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>8</b> Global Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>8.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="pdp.html"><a href="pdp.html#pdp-based-feature-importance"><i class="fa fa-check"></i><b>8.1.1</b> PDP-based Feature Importance</a></li>
<li class="chapter" data-level="8.1.2" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>8.1.2</b> Examples</a></li>
<li class="chapter" data-level="8.1.3" data-path="pdp.html"><a href="pdp.html#advantages-5"><i class="fa fa-check"></i><b>8.1.3</b> Advantages</a></li>
<li class="chapter" data-level="8.1.4" data-path="pdp.html"><a href="pdp.html#disadvantages-5"><i class="fa fa-check"></i><b>8.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.1.5" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>8.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>8.2</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="8.2.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>8.2.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="8.2.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>8.2.2</b> Theory</a></li>
<li class="chapter" data-level="8.2.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>8.2.3</b> Estimation</a></li>
<li class="chapter" data-level="8.2.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>8.2.4</b> Examples</a></li>
<li class="chapter" data-level="8.2.5" data-path="ale.html"><a href="ale.html#advantages-6"><i class="fa fa-check"></i><b>8.2.5</b> Advantages</a></li>
<li class="chapter" data-level="8.2.6" data-path="ale.html"><a href="ale.html#disadvantages-6"><i class="fa fa-check"></i><b>8.2.6</b> Disadvantages</a></li>
<li class="chapter" data-level="8.2.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>8.2.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>8.3</b> Feature Interaction</a><ul>
<li class="chapter" data-level="8.3.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>8.3.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="8.3.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>8.3.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="8.3.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>8.3.3</b> Examples</a></li>
<li class="chapter" data-level="8.3.4" data-path="interaction.html"><a href="interaction.html#advantages-7"><i class="fa fa-check"></i><b>8.3.4</b> Advantages</a></li>
<li class="chapter" data-level="8.3.5" data-path="interaction.html"><a href="interaction.html#disadvantages-7"><i class="fa fa-check"></i><b>8.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.3.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>8.3.6</b> Implementations</a></li>
<li class="chapter" data-level="8.3.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>8.3.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>8.4</b> Functional Decompositon</a><ul>
<li class="chapter" data-level="8.4.1" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-i"><i class="fa fa-check"></i><b>8.4.1</b> How not to Compute the Components I</a></li>
<li class="chapter" data-level="8.4.2" data-path="decomposition.html"><a href="decomposition.html#functional-decomposition"><i class="fa fa-check"></i><b>8.4.2</b> Functional Decomposition</a></li>
<li class="chapter" data-level="8.4.3" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-ii"><i class="fa fa-check"></i><b>8.4.3</b> How not to Compute the Components II</a></li>
<li class="chapter" data-level="8.4.4" data-path="decomposition.html"><a href="decomposition.html#functional-anova"><i class="fa fa-check"></i><b>8.4.4</b> Functional ANOVA</a></li>
<li class="chapter" data-level="8.4.5" data-path="decomposition.html"><a href="decomposition.html#generalized-functional-anova-for-dependent-features"><i class="fa fa-check"></i><b>8.4.5</b> Generalized Functional ANOVA for Dependent Features</a></li>
<li class="chapter" data-level="8.4.6" data-path="decomposition.html"><a href="decomposition.html#accumulated-local-effect-plots"><i class="fa fa-check"></i><b>8.4.6</b> Accumulated Local Effect Plots</a></li>
<li class="chapter" data-level="8.4.7" data-path="decomposition.html"><a href="decomposition.html#statistical-regression-models"><i class="fa fa-check"></i><b>8.4.7</b> Statistical Regression Models</a></li>
<li class="chapter" data-level="8.4.8" data-path="decomposition.html"><a href="decomposition.html#bonus-partial-dependence-plot"><i class="fa fa-check"></i><b>8.4.8</b> Bonus: Partial Dependence Plot</a></li>
<li class="chapter" data-level="8.4.9" data-path="decomposition.html"><a href="decomposition.html#advantages-8"><i class="fa fa-check"></i><b>8.4.9</b> Advantages</a></li>
<li class="chapter" data-level="8.4.10" data-path="decomposition.html"><a href="decomposition.html#disadvantages-8"><i class="fa fa-check"></i><b>8.4.10</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>8.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="8.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-3"><i class="fa fa-check"></i><b>8.5.1</b> Theory</a></li>
<li class="chapter" data-level="8.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>8.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="8.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>8.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="8.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-9"><i class="fa fa-check"></i><b>8.5.4</b> Advantages</a></li>
<li class="chapter" data-level="8.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-9"><i class="fa fa-check"></i><b>8.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>8.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>8.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="8.6.1" data-path="global.html"><a href="global.html#theory-4"><i class="fa fa-check"></i><b>8.6.1</b> Theory</a></li>
<li class="chapter" data-level="8.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>8.6.2</b> Example</a></li>
<li class="chapter" data-level="8.6.3" data-path="global.html"><a href="global.html#advantages-10"><i class="fa fa-check"></i><b>8.6.3</b> Advantages</a></li>
<li class="chapter" data-level="8.6.4" data-path="global.html"><a href="global.html#disadvantages-10"><i class="fa fa-check"></i><b>8.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.6.5" data-path="global.html"><a href="global.html#software-3"><i class="fa fa-check"></i><b>8.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>8.7</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="8.7.1" data-path="proto.html"><a href="proto.html#theory-5"><i class="fa fa-check"></i><b>8.7.1</b> Theory</a></li>
<li class="chapter" data-level="8.7.2" data-path="proto.html"><a href="proto.html#examples-3"><i class="fa fa-check"></i><b>8.7.2</b> Examples</a></li>
<li class="chapter" data-level="8.7.3" data-path="proto.html"><a href="proto.html#advantages-11"><i class="fa fa-check"></i><b>8.7.3</b> Advantages</a></li>
<li class="chapter" data-level="8.7.4" data-path="proto.html"><a href="proto.html#disadvantages-11"><i class="fa fa-check"></i><b>8.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.7.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>8.7.5</b> Code and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>9</b> Local Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="9.1" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>9.1</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="9.1.1" data-path="ice.html"><a href="ice.html#examples-4"><i class="fa fa-check"></i><b>9.1.1</b> Examples</a></li>
<li class="chapter" data-level="9.1.2" data-path="ice.html"><a href="ice.html#advantages-12"><i class="fa fa-check"></i><b>9.1.2</b> Advantages</a></li>
<li class="chapter" data-level="9.1.3" data-path="ice.html"><a href="ice.html#disadvantages-12"><i class="fa fa-check"></i><b>9.1.3</b> Disadvantages</a></li>
<li class="chapter" data-level="9.1.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>9.1.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>9.2</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="9.2.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>9.2.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="9.2.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>9.2.2</b> LIME for Text</a></li>
<li class="chapter" data-level="9.2.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>9.2.3</b> LIME for Images</a></li>
<li class="chapter" data-level="9.2.4" data-path="lime.html"><a href="lime.html#advantages-13"><i class="fa fa-check"></i><b>9.2.4</b> Advantages</a></li>
<li class="chapter" data-level="9.2.5" data-path="lime.html"><a href="lime.html#disadvantages-13"><i class="fa fa-check"></i><b>9.2.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>9.3</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="9.3.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>9.3.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="9.3.2" data-path="counterfactual.html"><a href="counterfactual.html#example-8"><i class="fa fa-check"></i><b>9.3.2</b> Example</a></li>
<li class="chapter" data-level="9.3.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-14"><i class="fa fa-check"></i><b>9.3.3</b> Advantages</a></li>
<li class="chapter" data-level="9.3.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-14"><i class="fa fa-check"></i><b>9.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="9.3.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>9.3.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>9.4</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="9.4.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>9.4.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="9.4.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>9.4.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="9.4.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>9.4.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="9.4.4" data-path="anchors.html"><a href="anchors.html#advantages-15"><i class="fa fa-check"></i><b>9.4.4</b> Advantages</a></li>
<li class="chapter" data-level="9.4.5" data-path="anchors.html"><a href="anchors.html#disadvantages-15"><i class="fa fa-check"></i><b>9.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="9.4.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>9.4.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9.5</b> Shapley Values</a><ul>
<li class="chapter" data-level="9.5.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>9.5.1</b> General Idea</a></li>
<li class="chapter" data-level="9.5.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>9.5.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="9.5.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>9.5.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="9.5.4" data-path="shapley.html"><a href="shapley.html#advantages-16"><i class="fa fa-check"></i><b>9.5.4</b> Advantages</a></li>
<li class="chapter" data-level="9.5.5" data-path="shapley.html"><a href="shapley.html#disadvantages-16"><i class="fa fa-check"></i><b>9.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="9.5.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>9.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>9.6</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="9.6.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>9.6.1</b> Definition</a></li>
<li class="chapter" data-level="9.6.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>9.6.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="9.6.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>9.6.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="9.6.4" data-path="shap.html"><a href="shap.html#examples-5"><i class="fa fa-check"></i><b>9.6.4</b> Examples</a></li>
<li class="chapter" data-level="9.6.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>9.6.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="9.6.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>9.6.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="9.6.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>9.6.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="9.6.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>9.6.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="9.6.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>9.6.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="9.6.10" data-path="shap.html"><a href="shap.html#advantages-17"><i class="fa fa-check"></i><b>9.6.10</b> Advantages</a></li>
<li class="chapter" data-level="9.6.11" data-path="shap.html"><a href="shap.html#disadvantages-17"><i class="fa fa-check"></i><b>9.6.11</b> Disadvantages</a></li>
<li class="chapter" data-level="9.6.12" data-path="shap.html"><a href="shap.html#software-4"><i class="fa fa-check"></i><b>9.6.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>10</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="10.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>10.1</b> Learned Features</a><ul>
<li class="chapter" data-level="10.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>10.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="10.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>10.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="10.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-18"><i class="fa fa-check"></i><b>10.1.3</b> Advantages</a></li>
<li class="chapter" data-level="10.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-18"><i class="fa fa-check"></i><b>10.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="10.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>10.1.5</b> Software and Further Material</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html"><i class="fa fa-check"></i><b>10.2</b> Pixel Attribution (Saliency Maps)</a><ul>
<li class="chapter" data-level="10.2.1" data-path="pixel-attribution.html"><a href="pixel-attribution.html#vanilla-gradient-saliency-maps"><i class="fa fa-check"></i><b>10.2.1</b> Vanilla Gradient (Saliency Maps)</a></li>
<li class="chapter" data-level="10.2.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html#deconvnet"><i class="fa fa-check"></i><b>10.2.2</b> DeconvNet</a></li>
<li class="chapter" data-level="10.2.3" data-path="pixel-attribution.html"><a href="pixel-attribution.html#grad-cam"><i class="fa fa-check"></i><b>10.2.3</b> Grad-CAM</a></li>
<li class="chapter" data-level="10.2.4" data-path="pixel-attribution.html"><a href="pixel-attribution.html#guided-grad-cam"><i class="fa fa-check"></i><b>10.2.4</b> Guided Grad-CAM</a></li>
<li class="chapter" data-level="10.2.5" data-path="pixel-attribution.html"><a href="pixel-attribution.html#smoothgrad"><i class="fa fa-check"></i><b>10.2.5</b> SmoothGrad</a></li>
<li class="chapter" data-level="10.2.6" data-path="pixel-attribution.html"><a href="pixel-attribution.html#examples-6"><i class="fa fa-check"></i><b>10.2.6</b> Examples</a></li>
<li class="chapter" data-level="10.2.7" data-path="pixel-attribution.html"><a href="pixel-attribution.html#advantages-19"><i class="fa fa-check"></i><b>10.2.7</b> Advantages</a></li>
<li class="chapter" data-level="10.2.8" data-path="pixel-attribution.html"><a href="pixel-attribution.html#disadvantages-19"><i class="fa fa-check"></i><b>10.2.8</b> Disadvantages</a></li>
<li class="chapter" data-level="10.2.9" data-path="pixel-attribution.html"><a href="pixel-attribution.html#software-5"><i class="fa fa-check"></i><b>10.2.9</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html"><i class="fa fa-check"></i><b>10.3</b> Detecting Concepts</a><ul>
<li class="chapter" data-level="10.3.1" data-path="detecting-concepts.html"><a href="detecting-concepts.html#tcav-testing-with-concept-activation-vectors"><i class="fa fa-check"></i><b>10.3.1</b> TCAV: Testing with Concept Activation Vectors</a></li>
<li class="chapter" data-level="10.3.2" data-path="detecting-concepts.html"><a href="detecting-concepts.html#example-9"><i class="fa fa-check"></i><b>10.3.2</b> Example</a></li>
<li class="chapter" data-level="10.3.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html#advantages-20"><i class="fa fa-check"></i><b>10.3.3</b> Advantages</a></li>
<li class="chapter" data-level="10.3.4" data-path="detecting-concepts.html"><a href="detecting-concepts.html#disadvantages-20"><i class="fa fa-check"></i><b>10.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="10.3.5" data-path="detecting-concepts.html"><a href="detecting-concepts.html#bonus-other-concept-based-approaches"><i class="fa fa-check"></i><b>10.3.5</b> Bonus: Other Concept-based Approaches</a></li>
<li class="chapter" data-level="10.3.6" data-path="detecting-concepts.html"><a href="detecting-concepts.html#software-6"><i class="fa fa-check"></i><b>10.3.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>10.4</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="10.4.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>10.4.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="10.4.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>10.4.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>10.5</b> Influential Instances</a><ul>
<li class="chapter" data-level="10.5.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>10.5.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="10.5.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>10.5.2</b> Influence Functions</a></li>
<li class="chapter" data-level="10.5.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="10.5.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>10.5.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="10.5.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-6"><i class="fa fa-check"></i><b>10.5.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>11</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="11.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>11.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="11.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>11.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>12</b> Contribute to the Book</a></li>
<li class="chapter" data-level="13" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>13</b> Citing this Book</a></li>
<li class="chapter" data-level="14" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>14</b> Translations</a></li>
<li class="chapter" data-level="15" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>15</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used.html"><a href="r-packages-used.html"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interaction" class="section level2">
<h2><span class="header-section-number">8.3</span> Feature Interaction</h2>
<p>When features interact with each other in a prediction model, the prediction cannot be expressed as the sum of the feature effects, because the effect of one feature depends on the value of the other feature.
Aristotle’s predicate “The whole is greater than the sum of its parts” applies in the presence of interactions.</p>
<div id="feature-interaction" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Feature Interaction?</h3>
<p>If a machine learning model makes a prediction based on two features, we can decompose the prediction into four terms:
a constant term, a term for the first feature, a term for the second feature and a term for the interaction between the two features.<br />
The interaction between two features is the change in the prediction that occurs by varying the features after considering the individual feature effects.</p>
<p>For example, a model predicts the value of a house, using house size (big or small) and location (good or bad) as features, which yields four possible predictions:</p>
<table>
<thead>
<tr class="header">
<th align="right">Location</th>
<th align="right">Size</th>
<th align="right">Prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">good</td>
<td align="right">big</td>
<td align="right">300,000</td>
</tr>
<tr class="even">
<td align="right">good</td>
<td align="right">small</td>
<td align="right">200,000</td>
</tr>
<tr class="odd">
<td align="right">bad</td>
<td align="right">big</td>
<td align="right">250,000</td>
</tr>
<tr class="even">
<td align="right">bad</td>
<td align="right">small</td>
<td align="right">150,000</td>
</tr>
</tbody>
</table>
<p>We decompose the model prediction into the following parts:
A constant term (150,000), an effect for the size feature (+100,000 if big; +0 if small) and an effect for the location (+50,000 if good; +0 if bad).
This decomposition fully explains the model predictions.
There is no interaction effect, because the model prediction is a sum of the single feature effects for size and location.
When you make a small house big, the prediction always increases by 100,000, regardless of location.
Also, the difference in prediction between a good and a bad location is 50,000, regardless of size.</p>
<p>Let’s now look at an example with interaction:</p>
<table>
<thead>
<tr class="header">
<th align="right">Location</th>
<th align="right">Size</th>
<th align="right">Prediction</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">good</td>
<td align="right">big</td>
<td align="right">400,000</td>
</tr>
<tr class="even">
<td align="right">good</td>
<td align="right">small</td>
<td align="right">200,000</td>
</tr>
<tr class="odd">
<td align="right">bad</td>
<td align="right">big</td>
<td align="right">250,000</td>
</tr>
<tr class="even">
<td align="right">bad</td>
<td align="right">small</td>
<td align="right">150,000</td>
</tr>
</tbody>
</table>
<p>We decompose the prediction table into the following parts:
A constant term (150,000), an effect for the size feature (+100,000 if big, +0 if small) and an effect for the location (+50,000 if good, +0 if bad).
For this table we need an additional term for the interaction: +100,000 if the house is big and in a good location.
This is an interaction between size and location, because in this case the difference in prediction between a big and a small house depends on the location.</p>
<p>One way to estimate the interaction strength is to measure how much of the variation of the prediction depends on the interaction of the features.
This measurement is called H-statistic, introduced by Friedman and Popescu (2008)<a href="#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a>.</p>
</div>
<div id="theory-friedmans-h-statistic" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Theory: Friedman’s H-statistic</h3>
<p>We are going to deal with two cases:
First, a two-way interaction measure that tells us whether and to what extent two features in the model interact with each other;
second, a total interaction measure that tells us whether and to what extent a feature interacts in the model with all the other features.
In theory, arbitrary interactions between any number of features can be measured, but these two are the most interesting cases.</p>
<p>If two features do not interact, we can decompose the <a href="pdp.html#pdp">partial dependence function</a> as follows (assuming the partial dependence functions are centered at zero):</p>
<p><span class="math display">\[PD_{jk}(x_j,x_k)=PD_j(x_j)+PD_k(x_k)\]</span></p>
<p>where <span class="math inline">\(PD_{jk}(x_j,x_k)\)</span> is the 2-way partial dependence function of both features and <span class="math inline">\(PD_j(x_j)\)</span> and <span class="math inline">\(PD_k(x_k)\)</span> the partial dependence functions of the single features.</p>
<p>Likewise, if a feature has no interaction with any of the other features, we can express the prediction function <span class="math inline">\(\hat{f}(x)\)</span> as a sum of partial dependence functions, where the first summand depends only on j and the second on all other features except j:</p>
<p><span class="math display">\[\hat{f}(x)=PD_j(x_j)+PD_{-j}(x_{-j})\]</span></p>
<p>where <span class="math inline">\(PD_{-j}(x_{-j})\)</span> is the partial dependence function that depends on all features except the j-th feature.</p>
<p>This decomposition expresses the partial dependence (or full prediction) function without interactions (between features j and k, or respectively j and all other features).
In a next step, we measure the difference between the observed partial dependence function and the decomposed one without interactions.
We calculate the variance of the output of the partial dependence (to measure the interaction between two features) or of the entire function (to measure the interaction between a feature and all other features).
The amount of the variance explained by the interaction (difference between observed and no-interaction PD) is used as interaction strength statistic.
The statistic is 0 if there is no interaction at all and 1 if all of the variance of the <span class="math inline">\(PD_{jk}\)</span> or <span class="math inline">\(\hat{f}\)</span> is explained by the sum of the partial dependence functions.
An interaction statistic of 1 between two features means that each single PD function is constant and the effect on the prediction only comes through the interaction.
The H-statistic can also be larger than 1, which is more difficult to interpret.
This can happen when the variance of the 2-way interaction is larger than the variance of the 2-dimensional partial dependence plot.</p>
<p>Mathematically, the H-statistic proposed by Friedman and Popescu for the interaction between feature j and k is:</p>
<p><span class="math display">\[H^2_{jk} = \frac{\sum_{i=1}^n\left[PD_{jk}(x_{j}^{(i)},x_k^{(i)})-PD_j(x_j^{(i)}) - PD_k(x_{k}^{(i)})\right]^2}{\sum_{i=1}^n{PD}^2_{jk}(x_j^{(i)},x_k^{(i)})}\]</span></p>
<p>The same applies to measuring whether a feature j interacts with any other feature:</p>
<p><span class="math display">\[H^2_{j}=\frac{\sum_{i=1}^n\left[\hat{f}(x^{(i)})-PD_j(x_j^{(i)})-PD_{-j}(x_{-j}^{(i)})\right]^2}{\sum_{i=1}^n\hat{f}^2(x^{(i)})}\]</span></p>
<p>The H-statistic is expensive to evaluate, because it iterates over all data points and at each point the partial dependence has to be evaluated which in turn is done with all n data points.
In the worst case, we need 2n<sup>2</sup> calls to the machine learning models predict function to compute the two-way H-statistic (j vs. k) and 3n<sup>2</sup> for the total H-statistic (j vs. all).
To speed up the computation, we can sample from the n data points.
This has the disadvantage of increasing the variance of the partial dependence estimates, which makes the H-statistic unstable.
So if you are using sampling to reduce the computational burden, make sure to sample enough data points.</p>
<p>Friedman and Popescu also propose a test statistic to evaluate whether the H-statistic differs significantly from zero.
The null hypothesis is the absence of interaction.
To generate the interaction statistic under the null hypothesis, you must be able to adjust the model so that it has no interaction between feature j and k or all others.
This is not possible for all types of models.
Therefore this test is model-specific, not model-agnostic, and as such not covered here.</p>
<p>The interaction strength statistic can also be applied in a classification setting if the prediction is a probability.</p>
</div>
<div id="examples-2" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Examples</h3>
<p>Let us see what feature interactions look like in practice!
We measure the interaction strength of features in a support vector machine that predicts the number of <a href="bike-data.html#bike-data">rented bikes</a> based on weather and calendrical features.
The following plot shows the feature interaction H-statistic:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interaction-bike"></span>
<img src="images/interaction-bike-1.png" alt="The interaction strength (H-statistic) for each feature with all other features for a support vector machine predicting bicycle rentals. Overall, the interaction effects between the features are very weak (below 10\% of variance explained per feature)." width="\textwidth" />
<p class="caption">
FIGURE 8.19: The interaction strength (H-statistic) for each feature with all other features for a support vector machine predicting bicycle rentals. Overall, the interaction effects between the features are very weak (below 10% of variance explained per feature).
</p>
</div>
<p>In the next example, we calculate the interaction statistic for a classification problem.
We analyze the interactions between features in a random forest trained to predict <a href="cervical.html#cervical">cervical cancer</a>, given some risk factors.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interaction-cervical-include"></span>
<img src="images/interaction-cervical-1.png" alt="The interaction strength (H-statistic) for each feature with all other features for a random forest predicting the probability of cervical cancer. The years on hormonal contraceptives has the highest relative interaction effect with all other features, followed by the number of pregnancies." width="\textwidth" />
<p class="caption">
FIGURE 8.20: The interaction strength (H-statistic) for each feature with all other features for a random forest predicting the probability of cervical cancer. The years on hormonal contraceptives has the highest relative interaction effect with all other features, followed by the number of pregnancies.
</p>
</div>
<p>After looking at the feature interactions of each feature with all other features, we can select one of the features and dive deeper into all the 2-way interactions between the selected feature and the other features.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interaction2-cervical-age-include"></span>
<img src="images/interaction2-cervical-age-1.png" alt="The 2-way interaction strengths (H-statistic) between number of pregnancies and each other feature. There is a strong interaction between the number of pregnancies and the age." width="\textwidth" />
<p class="caption">
FIGURE 8.21: The 2-way interaction strengths (H-statistic) between number of pregnancies and each other feature. There is a strong interaction between the number of pregnancies and the age.
</p>
</div>
</div>
<div id="advantages-7" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Advantages</h3>
<p>The interaction H-statistic has an <strong>underlying theory</strong> through the partial dependence decomposition.</p>
<p>The H-statistic has a <strong>meaningful interpretation</strong>:
The interaction is defined as the share of variance that is explained by the interaction.</p>
<p>Since the statistic is <strong>dimensionless</strong>, it is comparable across features and even across models.</p>
<p>The statistic <strong>detects all kinds of interactions</strong>, regardless of their particular form.</p>
<p>With the H-statistic it is also possible to analyze arbitrary <strong>higher interactions</strong> such as the interaction strength between 3 or more features.</p>
</div>
<div id="disadvantages-7" class="section level3">
<h3><span class="header-section-number">8.3.5</span> Disadvantages</h3>
<p>The first thing you will notice:
The interaction H-statistic takes a long time to compute, because it is <strong>computationally expensive</strong>.</p>
<p>The computation involves estimating marginal distributions.
These <strong>estimates also have a certain variance</strong> if we do not use all data points.
This means that as we sample points, the estimates also vary from run to run and the <strong>results can be unstable</strong>.
I recommend repeating the H-statistic computation a few times to see if you have enough data to get a stable result.</p>
<p>It is unclear whether an interaction is significantly greater than 0.
We would need to conduct a statistical test, but this <strong>test is not (yet) available in a model-agnostic version</strong>.</p>
<p>Concerning the test problem, it is difficult to say when the H-statistic is large enough for us to consider an interaction “strong”.</p>
<p>Also, the H-statistics can be larger than 1, which makes the interpretation difficult.</p>
<p>When the total effect of two features is weak, but mostly consists of interactions, than the H-statistic will be very large.
This can be easily overinterpreted as a strong interaction effect, when in reality both features play a minor role in the model.</p>
<p>The H-statistic tells us the strength of interactions, but it does not tell us how the interactions look like.
That is what <a href="pdp.html#pdp">partial dependence plots</a> are for.
A meaningful workflow is to measure the interaction strengths and then create 2D-partial dependence plots for the interactions you are interested in.</p>
<p>The H-statistic cannot be used meaningfully if the inputs are pixels.
So the technique is not useful for image classifier.</p>
<p>The interaction statistic works under the assumption that we can shuffle features independently.
If the features correlate strongly, the assumption is violated and <strong>we integrate over feature combinations that are very unlikely in reality</strong>.
That is the same problem that partial dependence plots have.
You cannot say in general if it leads to overestimation or underestimation.</p>
<p>Sometimes the results are strange and for small simulations <strong>do not yield the expected results</strong>.
But this is more of an anecdotal observation.</p>
</div>
<div id="implementations" class="section level3">
<h3><span class="header-section-number">8.3.6</span> Implementations</h3>
<p>For the examples in this book, I used the R package <code>iml</code>, which is available on <a href="https://cran.r-project.org/web/packages/iml">CRAN</a> and the development version on <a href="https://github.com/christophM/iml">Github</a>.
There are other implementations, which focus on specific models:
The R package <a href="https://cran.r-project.org/web/packages/pre/index.html">pre</a> implements <a href="rulefit.html#rulefit">RuleFit</a> and H-statistic.
The R package <a href="https://github.com/gbm-developers/gbm3">gbm</a> implements gradient boosted models and H-statistic.</p>
</div>
<div id="alternatives" class="section level3">
<h3><span class="header-section-number">8.3.7</span> Alternatives</h3>
<p>The H-statistic is not the only way to measure interactions:</p>
<p>Variable Interaction Networks (VIN) by Hooker (2004)<a href="#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a> is an approach that decomposes the prediction function into main effects and feature interactions.
The interactions between features are then visualized as a network.
Unfortunately no software is available yet.</p>
<p>Partial dependence based feature interaction by Greenwell et. al (2018)<a href="#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a> measures the interaction between two features.
This approach measures the feature importance (defined as the variance of the partial dependence function) of one feature conditional on different, fixed points of the other feature.
If the variance is high, then the features interact with each other, if it is zero, they do not interact.
The corresponding R package <code>vip</code> is available on <a href="https://github.com/koalaverse/vip">Github</a>.
The package also covers partial dependence plots and feature importance.</p>

<!--{pagebreak}-->
<!-- TODOs

- Find good chapter position. Maybe after PDP and ALE?
- Research paper that cite  Generalized functional anova diagnostics for high-dimensional functions of dependent variables.
-->
</div>
</div>
<div class="footnotes">
<hr />
<ol start="35">
<li id="fn35"><p>Friedman, Jerome H, and Bogdan E Popescu. “Predictive learning via rule ensembles.” The Annals of Applied Statistics. JSTOR, 916–54. (2008).<a href="interaction.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>Hooker, Giles. “Discovering additive structure in black box functions.” Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining. (2004).<a href="interaction.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>Greenwell, Brandon M., Bradley C. Boehmke, and Andrew J. McCarthy. “A simple and effective model-based variable importance measure.” arXiv preprint arXiv:1805.04755 (2018).<a href="interaction.html#fnref37" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ale.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="decomposition.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/manuscript/05.5-agnostic-interaction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["interpretable-ml.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
