<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners on how to make machine learning decisions more interpretable." />
  

<meta name="author" content="Christoph Molnar">


<meta name="date" content="2018-11-29">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="simple.html">
<link rel="next" href="logistic.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> Storytime</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> The Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>2.2</b> Taxonomy of Interpretability Methods</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>2.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluating-interpretability.html"><a href="evaluating-interpretability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluating Interpretability</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> Properties of Explanations</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.6.1</b> What is an explanation?</a></li>
<li class="chapter" data-level="2.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.6.2</b> What is a “good” explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Sharing Counts (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression Model</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explaining-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explaining Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Coding Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#whats-wrong-with-linear-regression-models-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What’s Wrong with Linear Regression Models for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>4.2.2</b> Theory</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
<li class="chapter" data-level="4.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>4.2.5</b> Advantages and Disadvantages</a></li>
<li class="chapter" data-level="4.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>4.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.3</b> Linear Model 2.0 - GLMs, GAMs and more</a><ul>
<li class="chapter" data-level="4.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.3.2</b> Interactions</a></li>
<li class="chapter" data-level="4.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.3.4</b> Advantages</a></li>
<li class="chapter" data-level="4.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>4.3.6</b> Software</a></li>
<li class="chapter" data-level="4.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.3.7</b> Further extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.4</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>4.4.2</b> Example</a></li>
<li class="chapter" data-level="4.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>4.4.3</b> Advantages</a></li>
<li class="chapter" data-level="4.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>4.4.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>4.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.5</b> Decision Rules (IF-THEN)</a><ul>
<li class="chapter" data-level="4.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>4.5.4</b> Advantages</a></li>
<li class="chapter" data-level="4.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>4.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.6</b> RuleFit</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>4.6.2</b> Theory</a></li>
<li class="chapter" data-level="4.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>4.6.3</b> Advantages</a></li>
<li class="chapter" data-level="4.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>4.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.6.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.7</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.7.1</b> Naive Bayes classifier</a></li>
<li class="chapter" data-level="4.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbours"><i class="fa fa-check"></i><b>4.7.2</b> K-Nearest Neighbours</a></li>
<li class="chapter" data-level="4.7.3" data-path="other-interpretable.html"><a href="other-interpretable.html#and-so-many-more"><i class="fa fa-check"></i><b>4.7.3</b> And so many more …</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="5.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>5.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="5.1.1" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>5.1.1</b> Examples</a></li>
<li class="chapter" data-level="5.1.2" data-path="pdp.html"><a href="pdp.html#advantages-5"><i class="fa fa-check"></i><b>5.1.2</b> Advantages</a></li>
<li class="chapter" data-level="5.1.3" data-path="pdp.html"><a href="pdp.html#disadvantages-5"><i class="fa fa-check"></i><b>5.1.3</b> Disadvantages</a></li>
<li class="chapter" data-level="5.1.4" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>5.1.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>5.2</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="5.2.1" data-path="ice.html"><a href="ice.html#example-3"><i class="fa fa-check"></i><b>5.2.1</b> Example</a></li>
<li class="chapter" data-level="5.2.2" data-path="ice.html"><a href="ice.html#advantages-6"><i class="fa fa-check"></i><b>5.2.2</b> Advantages</a></li>
<li class="chapter" data-level="5.2.3" data-path="ice.html"><a href="ice.html#disadvantages-6"><i class="fa fa-check"></i><b>5.2.3</b> Disadvantages</a></li>
<li class="chapter" data-level="5.2.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>5.2.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>5.3</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>5.3.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="5.3.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>5.3.2</b> Theory</a></li>
<li class="chapter" data-level="5.3.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>5.3.3</b> Estimation</a></li>
<li class="chapter" data-level="5.3.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>5.3.4</b> Examples</a></li>
<li class="chapter" data-level="5.3.5" data-path="ale.html"><a href="ale.html#advantages-7"><i class="fa fa-check"></i><b>5.3.5</b> Advantages</a></li>
<li class="chapter" data-level="5.3.6" data-path="ale.html"><a href="ale.html#disadvantages-7"><i class="fa fa-check"></i><b>5.3.6</b> Disadvantages</a></li>
<li class="chapter" data-level="5.3.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>5.3.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>5.4</b> Feature Interaction</a><ul>
<li class="chapter" data-level="5.4.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>5.4.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="5.4.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>5.4.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="5.4.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>5.4.3</b> Examples</a></li>
<li class="chapter" data-level="5.4.4" data-path="interaction.html"><a href="interaction.html#advantages-8"><i class="fa fa-check"></i><b>5.4.4</b> Advantages</a></li>
<li class="chapter" data-level="5.4.5" data-path="interaction.html"><a href="interaction.html#disadvantages-8"><i class="fa fa-check"></i><b>5.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.4.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>5.4.6</b> Implementations</a></li>
<li class="chapter" data-level="5.4.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>5.4.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>5.5</b> Feature Importance</a><ul>
<li class="chapter" data-level="5.5.1" data-path="feature-importance.html"><a href="feature-importance.html#the-theory"><i class="fa fa-check"></i><b>5.5.1</b> The Theory</a></li>
<li class="chapter" data-level="5.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>5.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="5.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>5.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="5.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-9"><i class="fa fa-check"></i><b>5.5.4</b> Advantages</a></li>
<li class="chapter" data-level="5.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-9"><i class="fa fa-check"></i><b>5.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>5.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>5.6</b> Global Surrogate Models</a><ul>
<li class="chapter" data-level="5.6.1" data-path="global.html"><a href="global.html#theory-3"><i class="fa fa-check"></i><b>5.6.1</b> Theory</a></li>
<li class="chapter" data-level="5.6.2" data-path="global.html"><a href="global.html#example-5"><i class="fa fa-check"></i><b>5.6.2</b> Example</a></li>
<li class="chapter" data-level="5.6.3" data-path="global.html"><a href="global.html#advantages-10"><i class="fa fa-check"></i><b>5.6.3</b> Advantages</a></li>
<li class="chapter" data-level="5.6.4" data-path="global.html"><a href="global.html#disadvantages-10"><i class="fa fa-check"></i><b>5.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="5.6.5" data-path="global.html"><a href="global.html#software-3"><i class="fa fa-check"></i><b>5.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>5.7</b> Local Surrogate Models (LIME)</a><ul>
<li class="chapter" data-level="5.7.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>5.7.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="5.7.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>5.7.2</b> LIME for Text</a></li>
<li class="chapter" data-level="5.7.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>5.7.3</b> LIME for Images</a></li>
<li class="chapter" data-level="5.7.4" data-path="lime.html"><a href="lime.html#advantages-11"><i class="fa fa-check"></i><b>5.7.4</b> Advantages</a></li>
<li class="chapter" data-level="5.7.5" data-path="lime.html"><a href="lime.html#disadvantages-11"><i class="fa fa-check"></i><b>5.7.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.7.6" data-path="lime.html"><a href="lime.html#software-4"><i class="fa fa-check"></i><b>5.7.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>5.8</b> Shapley Value Explanations</a><ul>
<li class="chapter" data-level="5.8.1" data-path="shapley.html"><a href="shapley.html#the-general-idea"><i class="fa fa-check"></i><b>5.8.1</b> The general idea</a></li>
<li class="chapter" data-level="5.8.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>5.8.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="5.8.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>5.8.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="5.8.4" data-path="shapley.html"><a href="shapley.html#advantages-12"><i class="fa fa-check"></i><b>5.8.4</b> Advantages</a></li>
<li class="chapter" data-level="5.8.5" data-path="shapley.html"><a href="shapley.html#disadvantages-12"><i class="fa fa-check"></i><b>5.8.5</b> Disadvantages</a></li>
<li class="chapter" data-level="5.8.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>5.8.6</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-based Explanations</a><ul>
<li class="chapter" data-level="6.1" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>6.1</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="6.1.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>6.1.1</b> Generating counterfactual explanations</a></li>
<li class="chapter" data-level="6.1.2" data-path="counterfactual.html"><a href="counterfactual.html#examples-3"><i class="fa fa-check"></i><b>6.1.2</b> Examples</a></li>
<li class="chapter" data-level="6.1.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-13"><i class="fa fa-check"></i><b>6.1.3</b> Advantages</a></li>
<li class="chapter" data-level="6.1.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-13"><i class="fa fa-check"></i><b>6.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.1.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>6.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>6.2</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="6.2.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>6.2.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="6.2.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>6.2.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>6.3</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="6.3.1" data-path="proto.html"><a href="proto.html#theory-4"><i class="fa fa-check"></i><b>6.3.1</b> Theory</a></li>
<li class="chapter" data-level="6.3.2" data-path="proto.html"><a href="proto.html#examples-4"><i class="fa fa-check"></i><b>6.3.2</b> Examples</a></li>
<li class="chapter" data-level="6.3.3" data-path="proto.html"><a href="proto.html#advantages-14"><i class="fa fa-check"></i><b>6.3.3</b> Advantages</a></li>
<li class="chapter" data-level="6.3.4" data-path="proto.html"><a href="proto.html#disadvantages-14"><i class="fa fa-check"></i><b>6.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="6.3.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>6.3.5</b> Code and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>6.4</b> Influential Instances</a><ul>
<li class="chapter" data-level="6.4.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>6.4.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="6.4.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>6.4.2</b> Influence Functions</a></li>
<li class="chapter" data-level="6.4.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>6.4.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="6.4.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>6.4.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>7</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="7.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>7.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="7.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>7.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>8</b> Contribute</a></li>
<li class="chapter" data-level="9" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>9</b> Citation</a></li>
<li class="chapter" data-level="10" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>10</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="limo" class="section level2">
<h2><span class="header-section-number">4.1</span> Linear Regression Model</h2>
<p>A linear regression model predicts the target as a weighted sum of the feature inputs. The linearity of the learned relationship makes the interpretation easy. Linear regression models have been used for a long time by statisticians, computer scientists, and other people tackling quantitative problems.</p>
<p>Linear models can be used to model the dependency of a regression target <span class="math inline">\(y\)</span> on <span class="math inline">\(p\)</span> features <span class="math inline">\(x\)</span>. The learned relationships are linear and, for a singular instance <span class="math inline">\(i\)</span>, can be written as:</p>
<p><span class="math display">\[y_{i}=\beta_{0}+\beta_{1}x_{i1}+\ldots+\beta_{p}x_{ip}+\epsilon_{i}\]</span></p>
<p>The i-th instance’s outcome is a weighted sum of its <span class="math inline">\(p\)</span> features. The <span class="math inline">\(\beta_{j}\)</span> represent the learned feature weights or coefficients. The <span class="math inline">\(\epsilon_{i}\)</span> is the error we are still making, i.e. the difference between the predicted outcome and the actual outcome. These errors are assumed to follow a Gaussian distribution, which means we make errors in both negative and positive directions and make many small errors and few large errors.</p>
<p>Different methods can be used to estimate the optimal weight vector <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>. The ordinary least squares method is commonly used to find the weights that minimise the squared difference between the actual and the estimated outcome:</p>
<p><span class="math display">\[\hat{\boldsymbol{\beta}}=\arg\!\min_{\beta_0,\ldots,\beta_p}\sum_{i=1}^n\left(y_i-\left(\beta_0+\sum_{j=1}^p\beta_jx_{ij}\right)\right)^{2}\]</span></p>
<p>We won’t go into detail about how the optimal weights can be found, but if you are interested you can read Chapter 3.2 of the book “Elements of Statistical Learning” (Hastie, Tibshirani, and Friedman 2009)<a href="#fn15" class="footnoteRef" id="fnref15"><sup>15</sup></a> or one of the other zillions of sources about linear regression models.</p>
<p>The biggest advantage of linear regression models is their linearity: It makes the estimation procedure straightforward and, most importantly, these linear equations have an easy to understand interpretation on a modular level (i.e. the weights). That is one of the main reasons why the linear model and all similar models are so widespread in academic fields like medicine, sociology, psychology, and many more quantitative research fields. In these areas it is important to not only predict, e.g., the clinical outcome of a patient, but also to quantify the influence of the medication while at the same time accounting for things like gender, age, and other features in an interpretable manner. Estimates of coefficients or weights also come with confidence intervals. A confidence interval is a range for the weight estimate that covers the ‘true’ parameter with a certain confidence. For example, a 95% confidence interval for a weight of 2 could range from 1 to 3 and its interpretation would be: If we repeated the estimation 100 times with newly sampled data, the confidence interval would cover the true parameter in 95 out of 100 cases.</p>
<p>Linear regression models also come with some assumptions that make them easy to use and interpret but which are often not satisfied in reality. The assumptions are: Linearity, normality, homoscedasticity, independence, fixed features, and absence of multicollinearity.</p>
<ul>
<li><strong>Linearity</strong>: Linear regression models force the estimated response to be a linear combination of the features, which is both their greatest strength and biggest limitation. Linearity leads to interpretable models: linear effects are simple to quantify and describe (see also next chapter) and are additive, so it is easy to separate the effects. If you suspect interactions of features or a non-linear association of a feature with the target value, then you can add interaction terms and use techniques like regression splines to estimate non-linear effects.</li>
<li><strong>Normality</strong>: The target outcome given the features are assumed to follow a normal distribution. If this assumption is violated, then the estimated confidence intervals of the feature weights are not valid. Consequently, any interpretation of the features p-values is not valid.</li>
<li><strong>Homoscedasticity</strong> (constant variance): The variance of the error terms <span class="math inline">\(\epsilon_{i}\)</span> is assumed to be constant over the whole feature space. Let’s say you want to predict the value of a house given the living area in square meters. You estimate a linear model, which assumes that no matter how big the house, the error terms around the predicted response have the same variance. This assumption is often violated in reality. In the house example it is plausible that the variance of error terms around the predicted price is higher for bigger houses, since also the prices are higher and there is more room for prices to vary.</li>
<li><strong>Independence</strong>: Each instance is assumed to be independent from the next one. If you have repeated measurements, like multiple records per patient, the data points are not independent from each other and there are special linear model classes to deal with these cases, like mixed effect models or GEEs.</li>
<li><strong>Fixed features</strong>: The input features are seen as ‘fixed’, carrying no errors or variation, which, of course, is very unrealistic and only makes sense in controlled experimental settings. But not assuming fixed features would mean that you have to fit very complex measurement error models that account for the measurement errors of your input features. And usually you don’t want to do that.</li>
<li><strong>Absence of multicollinearity</strong>: Basically you don’t want features to be highly correlated, because this messes up the estimation of the weights. In a situation where two features are highly correlated (something like correlation &gt; 0.9) it will become problematic to estimate the weights, since the feature effects are additive and it becomes indeterminable to which of the correlated features to attribute the effects.</li>
</ul>
<div id="interpretation" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Interpretation</h3>
<p>The interpretation of a weight in the linear model depends on the type of the corresponding feature:</p>
<ul>
<li>Numerical feature: For an increase of the numerical feature <span class="math inline">\(x_{j}\)</span> by one unit, the estimated outcome changes by <span class="math inline">\(\beta_{j}\)</span>. An example of a numerical feature is the size of a house.</li>
<li>Binary feature: A feature, that for each instance takes on one of two possible values. An example is the feature “House comes with a garden”. One of the values counts as the reference level (in some programming languages coded with 0), like “No garden”. A change of the feature <span class="math inline">\(x_{j}\)</span> from the reference level to the other level changes the estimated outcome by <span class="math inline">\(\beta_{j}\)</span>.</li>
<li>Categorical feature with multiple levels: A feature with a fixed amount of possible values. An example is the feature “Flooring type”, with possible levels “carpet”, “laminate” and “parquet”. One solution to deal with many levels is to one-hot-encode them, meaning each level gets its own binary column. From a categorical feature with <span class="math inline">\(l\)</span> levels, you only need <span class="math inline">\(l-1\)</span> columns, otherwise the coding is overparameterised. The interpretation for each level is then according to the binary features. Some languages, like R, allow you to code categorical features in different ways, <a href="limo.html#cat-code">described here</a>.</li>
<li>Intercept <span class="math inline">\(\beta_{0}\)</span>: The intercept is the feature weight for the constant feature, which is always 1 for all instances. Most software packages automatically add this feature for estimating the intercept. The interpretation is: Given all numerical features are zero and the categorical features are at the reference level, the estimated outcome of <span class="math inline">\(y_{i}\)</span> is <span class="math inline">\(\beta_{0}\)</span>. The interpretation of <span class="math inline">\(\beta_{0}\)</span> is usually not relevant, because instances with all features at zero often don’t make any sense, unless the features were standardised (mean of zero, standard deviation of one), where the intercept <span class="math inline">\(\beta_0\)</span> reflects the predicted outcome of an instance where all features are at their mean.</li>
</ul>
<p>The interpretation of the features in the linear model can be automated by using following text templates.</p>
<p><strong>Interpretation of a Numerical Feature</strong></p>
<p>An increase of <span class="math inline">\(x_{k}\)</span> by one unit increases the expectation for <span class="math inline">\(y\)</span> by <span class="math inline">\(\beta_k\)</span> units, given all other features stay the same.</p>
<p><strong>Interpretation of a Categorical Feature</strong></p>
<p>A change from <span class="math inline">\(x_{k}\)</span>’s reference level to the other category increases the expectation for <span class="math inline">\(y\)</span> by <span class="math inline">\(\beta_{k}\)</span>, given all other features stay the same.</p>
<p>Another important measurement for interpreting linear models is the <span class="math inline">\(R^2\)</span> measurement. <span class="math inline">\(R^2\)</span> tells you how much of the total variance of your target outcome is explained by the model. The higher <span class="math inline">\(R^2\)</span> the better your model explains the data. The formula to calculate <span class="math inline">\(R^2\)</span> is: <span class="math inline">\(R^2=1-SSE/SST\)</span>, where SSE is the squared sum of the error terms:</p>
<p><span class="math display">\[SSE=\sum_{i=1}^n(y_i-\hat{y}_i)^2\]</span></p>
<p>and SST is the squared sum of the data variance:</p>
<p><span class="math display">\[SST=\sum_{i=1}^n(y_i-\bar{y})^2\]</span></p>
<p>The SSE tells you how much variance remains after fitting the linear model, which is measured by looking at the squared differences between the predicted and actual target values. SST is the total variance of the target around the mean. So <span class="math inline">\(R^2\)</span> tells you how much of your variance can be explained by the linear model. <span class="math inline">\(R^2\)</span> ranges between 0 for models that explain nothing and 1 for models that explain all of the variance in your data.</p>
<p>There is a catch, because <span class="math inline">\(R^2\)</span> increases with the number of features in the model, even if they carry no information about the target value at all. So it is better to use the adjusted R-squared (<span class="math inline">\(\bar{R}^2\)</span>), which accounts for the number of features used in the model. Its calculation is</p>
<p><span class="math display">\[\bar{R}^2=R^2-(1-R^2)\frac{p}{n-p-1}\]</span></p>
<p>where <span class="math inline">\(p\)</span> is the number of features and <span class="math inline">\(n\)</span> the number of instances.</p>
<p>It isn’t helpful to do interpretation on a model with very low <span class="math inline">\(R^2\)</span> or <span class="math inline">\(\bar{R}^2\)</span>, because basically the model is not explaining much of the variance, so any interpretation of the weights are not meaningful.</p>
<p><strong>Feature Importance</strong></p>
<p>The importance of a feature in a linear regression model can be measured by the absolute value of its t-statistic. The t-statistic is the estimated weight scaled with it’s standard error.</p>
<p><span class="math display">\[t_{\hat{\beta}}=\frac{\hat{\beta}}{SE(\hat{\beta})}\]</span></p>
<p>The importance of a feature increases as its weight increases. This makes sense. The more variance the estimated weight has (= the less certain we are about the correct value), the less important the feature is. This also makes sense.</p>
</div>
<div id="example" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Example</h3>
<p>In this example we use the linear model to predict the <a href="bike-data.html#bike-data">number of rented bikes</a> on a day, given weather and calendrical information. For the interpretation we examine the estimated regression weights. The features are a mix of numerical and categorical features. The table shows for each feature the estimated weight, the standard error of the estimation and the absolute value of the t-statistic (feature importance).</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Weight estimate</th>
<th align="right">Std. Error</th>
<th align="right">abs(t)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>(Intercept)</td>
<td align="right">2399.4</td>
<td align="right">238.3</td>
<td align="right">10.1</td>
</tr>
<tr class="even">
<td>seasonSUMMER</td>
<td align="right">899.3</td>
<td align="right">122.3</td>
<td align="right">7.4</td>
</tr>
<tr class="odd">
<td>seasonFALL</td>
<td align="right">138.2</td>
<td align="right">161.7</td>
<td align="right">0.9</td>
</tr>
<tr class="even">
<td>seasonWINTER</td>
<td align="right">425.6</td>
<td align="right">110.8</td>
<td align="right">3.8</td>
</tr>
<tr class="odd">
<td>holidayHOLIDAY</td>
<td align="right">-686.1</td>
<td align="right">203.3</td>
<td align="right">3.4</td>
</tr>
<tr class="even">
<td>workingdayWORKING DAY</td>
<td align="right">124.9</td>
<td align="right">73.3</td>
<td align="right">1.7</td>
</tr>
<tr class="odd">
<td>weathersitMISTY</td>
<td align="right">-379.4</td>
<td align="right">87.6</td>
<td align="right">4.3</td>
</tr>
<tr class="even">
<td>weathersitRAIN/SNOW/STORM</td>
<td align="right">-1901.5</td>
<td align="right">223.6</td>
<td align="right">8.5</td>
</tr>
<tr class="odd">
<td>temp</td>
<td align="right">110.7</td>
<td align="right">7.0</td>
<td align="right">15.7</td>
</tr>
<tr class="even">
<td>hum</td>
<td align="right">-17.4</td>
<td align="right">3.2</td>
<td align="right">5.5</td>
</tr>
<tr class="odd">
<td>windspeed</td>
<td align="right">-42.5</td>
<td align="right">6.9</td>
<td align="right">6.2</td>
</tr>
<tr class="even">
<td>days_since_2011</td>
<td align="right">4.9</td>
<td align="right">0.2</td>
<td align="right">28.5</td>
</tr>
</tbody>
</table>
<p>Interpretation of a numerical feature (‘Temperature’): An increase of the temperature by 1 degree Celsius increases the expected number of bikes by 110.7, given all other features stay the same.</p>
<p>Interpretation of a categorical feature (‘weathersituation’)): The estimated number of bikes is -1901.5 lower when it is rainy, snowing or stormy, compared to good weather, given that all other features stay the same. Also if the weather was misty, the expected number of bikes was -379.4 lower, compared to good weather, given all other features stay the same.</p>
<p>As you can see in the interpretation examples, the interpretations always come with the footnote that ‘all other features stay the same’. That’s because of the nature of linear models: The target is a linear combination of the weighted features. The estimated linear equation spans a hyperplane in the feature/target space (a simple line in the case of a single feature). The <span class="math inline">\(\beta\)</span> (weight) values specify the slope (gradient) of the hyperplane in each direction. The good side is that it isolates the interpretation. If you think of the features as knobs that you can turn up or down, it is nice to see what happens when you would just turn the knob for one feature. On the bad side of things, the interpretation ignores the joint distribution with other features. Increasing one feature, but not changing others, might create unrealistic, or at least unlikely, data points.</p>
</div>
<div id="visual-interpretation" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Visual Interpretation</h3>
<p>Different visualisations make the linear model outcomes easy and quick to grasp for humans.</p>
<div id="weight-plot" class="section level4">
<h4><span class="header-section-number">4.1.3.1</span> Weight Plot</h4>
<p>The information of the weights table (weight estimates and variance) can be visualised in a weight plot (showing the results from the linear model fitted before):</p>
<div class="figure"><span id="fig:linear-weights-plot"></span>
<img src="images/linear-weights-plot-1.png" alt="Each row in the plot represents one feature weight. The weights are displayed as points and the 0.95 confidence intervals with a line around the points. A 0.95 confidence interval means that if the linear model would be estimated 100 times on similar data, in 95 out of 100 times, the confidence interval would cover the true weight, under the linear model assumptions (linearity, normality, homoscedasticity, independence, fixed features, absence of multicolinearity)." width="1050" />
<p class="caption">
FIGURE 4.1: Each row in the plot represents one feature weight. The weights are displayed as points and the 0.95 confidence intervals with a line around the points. A 0.95 confidence interval means that if the linear model would be estimated 100 times on similar data, in 95 out of 100 times, the confidence interval would cover the true weight, under the linear model assumptions (linearity, normality, homoscedasticity, independence, fixed features, absence of multicolinearity).
</p>
</div>
<p>The weight plot makes clear that rainy/snowy/stormy weather has a strong negative effect on the expected number of bikes. The working day feature’s weight is close to zero and the zero is included in the 95% interval, meaning it is not influencing the prediction significantly. Some confidence intervals are very short and the estimates are close to zero, yet the features were important. Temperature is such a candidate. The problem about the weight plot is that the features are measured on different scales. While for weather situation feature the estimated <span class="math inline">\(\beta\)</span> signifies the difference between good and rainy/storm/snowy weather, for temperature it signifies only an increase of 1 degree Celsius. You can improve the comparison by scaling the features to zero mean and unit standard deviation before fitting the linear model, to make the estimated weights comparable.</p>
</div>
<div id="effect-plot" class="section level4">
<h4><span class="header-section-number">4.1.3.2</span> Effect Plot</h4>
<p>The weights of the linear model can be analysed more meaningfully when multiplied by the actual feature values. The weights depend on the scale of the features and will be different if you have a feature measuring some height and you switch from meters to centimetres. The weight will change, but the actual relationships in your data will not. It is also important to know the distribution of your feature in the data, because if you have a very low variance, it means that almost all instances will get a similar contribution from this feature. The effect plot can help to understand how much the combination of a weight and a feature contributes to the predictions in your data. Start with the computation of the effects, which is the weight per feature times the feature of an instance: <span class="math inline">\(\text{effect}_{i,j}=w_{j}x_{i,j}\)</span>. The resulting effects are visualised with boxplots: A box in a boxplot contains the effect range for half of your data (25% to 75% effect quantiles). The vertical line in the box is the median effect, i.e. 50% of the instances have a lower and the other half a higher effect on the prediction than the median value. The horizontal lines extend to<span class="math inline">\(\pm1.58\text{IQR}/\sqrt{n}\)</span>, with IQR being the inter quartile range (<span class="math inline">\(q_{0.75}-q_{0.25}\)</span>). The points are outliers. The categorical feature effects can be aggregated into one boxplot, compared to the weight plot, where each weight gets a row.</p>
<div class="figure"><span id="fig:linear-effects"></span>
<img src="images/linear-effects-1.png" alt="The feature effect plot shows the distribution of the effects (= feature value times feature weight) over the dataset for each feature." width="1050" />
<p class="caption">
FIGURE 4.2: The feature effect plot shows the distribution of the effects (= feature value times feature weight) over the dataset for each feature.
</p>
</div>
<p>The largest contributions to the expected number of rented bikes comes from temperature and from the days feature, which captures the trend that the bike rental became more popular over time. The temperature has a broad contribution distribution. The day trend feature goes from zero to large positive contribution, because the first day in the dataset (01.01.2011) gets a very low day effect, and the estimated weight with this feature is positive (4.93), so the effect increases with every day and is highest for the latest day in the dataset (31.12.2012). Note that for effects from a feature with a negative weight, the instances with a positive effect are the ones that have a negative feature value, so days with a high negative effect of windspeed on the bike count have the highest windspeeds.</p>
</div>
</div>
<div id="explaining-individual-predictions" class="section level3">
<h3><span class="header-section-number">4.1.4</span> Explaining Individual Predictions</h3>
<p>How much did each feature of an instance contribute towards the prediction? This can, again, be answered by bringing together the weights and feature values of this instance and computing the effects. An interpretation of instance specific effects is only meaningful in comparison with the distribution of each feature’s effects. We want to explain the prediction of the linear model for the 6-th instance from the bicycle dataset. The instance has the following feature values.</p>
<table>
<thead>
<tr class="header">
<th align="left">Feature</th>
<th align="left">Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">season</td>
<td align="left">SPRING</td>
</tr>
<tr class="even">
<td align="left">yr</td>
<td align="left">2011</td>
</tr>
<tr class="odd">
<td align="left">mnth</td>
<td align="left">JAN</td>
</tr>
<tr class="even">
<td align="left">holiday</td>
<td align="left">NO HOLIDAY</td>
</tr>
<tr class="odd">
<td align="left">weekday</td>
<td align="left">THU</td>
</tr>
<tr class="even">
<td align="left">workingday</td>
<td align="left">WORKING DAY</td>
</tr>
<tr class="odd">
<td align="left">weathersit</td>
<td align="left">GOOD</td>
</tr>
<tr class="even">
<td align="left">temp</td>
<td align="left">1.604356</td>
</tr>
<tr class="odd">
<td align="left">hum</td>
<td align="left">51.8261</td>
</tr>
<tr class="even">
<td align="left">windspeed</td>
<td align="left">6.000868</td>
</tr>
<tr class="odd">
<td align="left">cnt</td>
<td align="left">1606</td>
</tr>
<tr class="even">
<td align="left">days_since_2011</td>
<td align="left">5</td>
</tr>
</tbody>
</table>
<p>To obtain the feature effects of this instance, we have to multiply its features values by the corresponding weights from the linear regression model. For example, for the value WORKING DAY of feature workingday, the effect is 124.9209381. For the value 1.604356 of feature temp, the effect is 177.6175815. We insert these individual effects as points in the effect plot, which shows us the distribution of effects in the data. This allows us to compare the individual effects with the distribution of effects in the data.</p>
<div class="figure"><span id="fig:linear-effects-single"></span>
<img src="images/linear-effects-single-1.png" alt="The effect for one instance shows the effect distribution while highlighting the effects of the instance of interest." width="1050" />
<p class="caption">
FIGURE 4.3: The effect for one instance shows the effect distribution while highlighting the effects of the instance of interest.
</p>
</div>
<p>When we average the predictions for the training data instances, we get a mean value of 4504 (). In comparison, the prediction of the 6-th instance is small with only 1571 predicted bicycles. The effect plot reveals the reason. The boxplots show the distributions of the effects for all instances of the dataset, the red markers show the effects for the 6-th instance. The 6-th instance has a low temperature effect because on this day the temperature was 2 degrees, which is low compared to most other days (and remember that the weight of the temperature feature is positive). Also, the effect of the trend feature “days_since_2011” is small compared to the other data instances because this instance is from early 2011 (5 days) and the trend feature also has a positive weight.</p>
</div>
<div id="cat-code" class="section level3">
<h3><span class="header-section-number">4.1.5</span> Coding Categorical Features</h3>
<p>There are several ways to encode a categorical feature and the choice influences the interpretation of the <span class="math inline">\(\beta\)</span>-weights.</p>
<p>The standard in linear regression models is the treatment coding, which is sufficient in most cases. Using different codings boils down to creating different matrices (=design matrix) from your one column with the categorical feature. This section presents three different codings, but there are many more. The example used has six instances and one categorical feature with 3 levels. For the first two instances, the feature takes on category A, for instances three and four category B and for the last two instances category C.</p>
<p><strong>Treatment coding</strong>:</p>
<p>The <span class="math inline">\(\beta\)</span> per level is the estimated difference in <span class="math inline">\(y\)</span> compared to the reference level. The intercept of the linear model is the mean of the reference group (given all other features stay the same). The first column of the design matrix is the intercept, which is always 1. Column two is an indicator whether instance <span class="math inline">\(i\)</span> is in category B, column three is an indicator for category C. There is no need for a column for category A, because then the linear equation would be overspecified and no unique solution (= unique <span class="math inline">\(\beta\)</span>’s) can be found. Knowing that an instance is neither in category B or C is enough.</p>
<p>Feature matrix: <span class="math display">\[\begin{pmatrix}1&amp;0&amp;0\\1&amp;0&amp;0\\1&amp;1&amp;0\\1&amp;1&amp;0\\1&amp;0&amp;1\\1&amp;0&amp;1\\\end{pmatrix}\]</span></p>
<p><strong>Effect coding</strong>:</p>
<p>The <span class="math inline">\(\beta\)</span> per level is the estimated <span class="math inline">\(y\)</span>-difference from the level to the overall mean (again, given all other features are zero or the reference level). The first column is again used to estimate the intercept. The weight <span class="math inline">\(\beta_{0}\)</span> which is associated with the intercept represents the overall mean and <span class="math inline">\(\beta_{1}\)</span>, the weight for column two is the difference between the overall mean and category B. The overall effect of category B is <span class="math inline">\(\beta_{0}+\beta_{1}\)</span>. The interpretation for category C is equivalent. For the reference category A, <span class="math inline">\(-(\beta_{1}+\beta_{2})\)</span> is the difference to the overall mean and <span class="math inline">\(\beta_{0}-(\beta_{1}+\beta_{2})\)</span> the overall effect.</p>
<p>Feature matrix: <span class="math display">\[\begin{pmatrix}1&amp;-1&amp;-1\\1&amp;-1&amp;-1\\1&amp;1&amp;0\\1&amp;1&amp;0\\1&amp;0&amp;1\\1&amp;0&amp;1\\\end{pmatrix}\]</span></p>
<p><strong>Dummy coding</strong>:</p>
<p>The <span class="math inline">\(\beta\)</span> per level is the estimated mean of <span class="math inline">\(y\)</span> for each level (given all feature are at value zero or reference level). Note that the intercept was dropped here, so that a unique solution for the linear model weights can be found.</p>
<p>Feature matrix: <span class="math display">\[\begin{pmatrix}1&amp;0&amp;0\\1&amp;0&amp;0\\0&amp;1&amp;0\\0&amp;1&amp;0\\0&amp;0&amp;1\\0&amp;0&amp;1\\\end{pmatrix}\]</span></p>
<p>If you want to dive a bit deeper into different encodings of categorical features, checkout <a href="http://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/">this webpage</a> and <a href="http://heidiseibold.github.io/page7/">this blog post</a>.</p>
</div>
<div id="do-linear-models-create-good-explanations" class="section level3">
<h3><span class="header-section-number">4.1.6</span> Do Linear Models Create Good Explanations?</h3>
<p>Judging by the attributes that constitute a good explanation as presented <a href="explanation.html#good-explanation">in the Human-friendly Explanations chapter</a>, linear models don’t create the best explanations. They are contrastive, but the reference instance is a data point for which all continuous features are zero and the categorical features at their reference levels. This is usually an artificial, meaningless instance, which is unlikely to occur in your dataset. There is an exception: When all continuous features are mean centered (feature minus mean of feature) and all categorical features are effect coded, the reference instance is the data point for which each feature is at its mean. This might also be a non-existent data point, but it might be at least more likely or meaningful. In this case, the <span class="math inline">\(\beta\)</span>-values times the feature values (feature effects) explain the contribution to the predicted outcome contrastive to the reference mean-instance. Another aspect of a good explanation is selectivity, which can be achieved in linear models by using less features or by fitting sparse linear models. But by default, linear models don’t create selective explanations. Linear models create truthful explanations, as long as the linear equation can model the relationship between features and outcome. The more non-linearities and interactions exist, the less accurate the linear model becomes and the less truthful explanations it will produce. The linearity makes the explanations more general and simple. The linear nature of the model, I believe, is the main factor why people like linear models for explaining relationships.</p>
</div>
<div id="sparse-linear" class="section level3">
<h3><span class="header-section-number">4.1.7</span> Sparse Linear Models</h3>
<p>The examples for the linear models that I chose look all nice and tidy, right? But in reality you might not have just a handful of features, but hundreds or thousands. And your normal linear models? Interpretability goes downriver. You might even get into a situation with more features than instances and you can’t fit a standard linear model at all. The good news is that there are ways to introduce sparsity (= only keeping a few features) into linear models.</p>
<div id="lasso" class="section level4">
<h4><span class="header-section-number">4.1.7.1</span> Lasso</h4>
<p>The most automatic and convenient way to introduce sparsity is to use the Lasso method. Lasso stands for “least absolute shrinkage and selection operator” and when added to a linear model, it performs feature selection and regularisation of the selected feature weights. Let’s review the minimization problem, the <span class="math inline">\(\beta\)</span>s optimise:</p>
<p><span class="math display">\[min_{\boldsymbol{\beta}}\left(\frac{1}{n}\sum_{i=1}^n(y_i-x_i^T\boldsymbol{\beta})^2\right)\]</span></p>
<p>Lasso adds a term to this optimisation problem:</p>
<p><span class="math display">\[min_{\boldsymbol{\beta}}\left(\frac{1}{n}\sum_{i=1}^n(y_i-x_i^T\boldsymbol{\beta})^2+\lambda||\boldsymbol{\beta}||_1\right)\]</span></p>
<p>The term <span class="math inline">\(||\boldsymbol{\beta}||_1\)</span>, the L1-norm of the feature vector, leads to a penalisation of large <span class="math inline">\(\boldsymbol{\beta}\)</span>-values. Since the L1-norm is used, many of the weights for the features will get an estimate of 0 and the others are shrunk. The parameter <span class="math inline">\(\lambda\)</span> controls the strength of the regularising effect and is usually tuned by doing cross-validation. Especially when <span class="math inline">\(\lambda\)</span> is large, many weights become 0.</p>
<p>The feature weights as a function of the penalty term lambda can be visualized as a curve per feature weight as shown in the following figure.</p>
<div class="figure"><span id="fig:llasso-path"></span>
<img src="images/llasso-path-1.png" alt="With increasing penalty of the weights, fewer and fewer features receive a non-zero weight estimate. These curves are also called regularization paths." width="1050" />
<p class="caption">
FIGURE 4.4: With increasing penalty of the weights, fewer and fewer features receive a non-zero weight estimate. These curves are also called regularization paths.
</p>
</div>
<p>What value should we choose for <span class="math inline">\(\lambda\)</span>? If you see the regularization parameter as a tuning parameter, then you can use cross-validation to find the optimal <span class="math inline">\(\lambda\)</span> that minimizes the model error. You can also consider <span class="math inline">\(\lambda\)</span> as a parameter to adjust model interpretability. The higher the parameter, the fewer features are in the model (because their weight is zero) and the better the model can be interpreted.</p>
<p><strong>Example with LASSO</strong></p>
<p>We will predict bike rentals with LASSO. We determine the number of features we want to have in the L1 regularized model.</p>
<p>Let’s first set the number to 2 features:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>seasonSPRING</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>seasonSUMMER</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>seasonFALL</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>seasonWINTER</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>holidayHOLIDAY</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>workingdayWORKING DAY</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>weathersitMISTY</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>weathersitRAIN/SNOW/STORM</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>temp</td>
<td align="right">52.33</td>
</tr>
<tr class="even">
<td>hum</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>windspeed</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>days_since_2011</td>
<td align="right">2.15</td>
</tr>
</tbody>
</table>
<p>The first two features with non-zero weights in the lasso path are temperature (“temp”) and the time trend (“days_since_2011”).</p>
<p>Now, let’s select 5 features:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th align="right">Weight</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>seasonSPRING</td>
<td align="right">-389.99</td>
</tr>
<tr class="even">
<td>seasonSUMMER</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>seasonFALL</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>seasonWINTER</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>holidayHOLIDAY</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>workingdayWORKING DAY</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td>weathersitMISTY</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>weathersitRAIN/SNOW/STORM</td>
<td align="right">-862.27</td>
</tr>
<tr class="odd">
<td>temp</td>
<td align="right">85.58</td>
</tr>
<tr class="even">
<td>hum</td>
<td align="right">-3.04</td>
</tr>
<tr class="odd">
<td>windspeed</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td>days_since_2011</td>
<td align="right">3.82</td>
</tr>
</tbody>
</table>
<p>Note that the weights for “temp” and “days_since_2011” differ from the model with two features. The reason for this is that by decreasing <span class="math inline">\(\lambda\)</span> even features that are already “in” the model are less penalized and possibly get a larger absolute weight. The interpretation of the LASSO weights corresponds to the interpretation of weights in the linear regression model. You only have to be careful whether the features are standardized or not, because this affects the weights. In this example, the features were standardized by the software, but the weights were automatically re-transformed to match the original feature scales.</p>
<p><strong>Other Methods for Sparsity in Linear Models</strong></p>
<p>A big spectrum of methods can be used to reduce the number of features in a linear model.</p>
<p>Methods that include a pre-processing step:</p>
<ul>
<li>Hand selected features: You can always use expert knowledge to choose and discard some features. The big drawback is, that it can’t be automated and you might not be an expert.</li>
<li>Use some measures to pre-select features: An example is the correlation coefficient. You only take features into account that exceed some chosen threshold of correlation between the feature and the target. Disadvantage is that it only looks at the features one at a time. Some features might only show correlation after the linear model has accounted for some other features. Those you will miss with this approach.</li>
</ul>
<p>Step-wise procedures:</p>
<ul>
<li>Forward selection: Fit the linear model with one feature. Do that with each feature. Choose the model that works best (for example decided by the highest R squared). Now again, for the remaining features, fit different versions of your model by adding each feature to your chosen model. Pick the one that performs best. Continue until some criterion is reached, like the maximum number of features in the model.</li>
<li>Backward selection: Same as forward selection, but instead of adding features, start with the model that includes all features and try out which feature you have to remove to get the highest performance increase. Repeat until some stopping criterion is reached.</li>
</ul>
<p>I recommend using Lasso, because it can be automated, looks at all features at the same time and can be controlled via <span class="math inline">\(\lambda\)</span>. It also works for the <a href="logistic.html#logistic">logistic regression model</a> for classification.</p>
</div>
</div>
<div id="advantages" class="section level3">
<h3><span class="header-section-number">4.1.8</span> Advantages</h3>
<p>The modeling of the predictions as a <strong>weighted sum</strong> makes it transparent how predictions are produced. And with LASSO we can ensure that the number of summands remains small.</p>
<p>Many people use linear regression models. This means that in many places it’s <strong>accepted</strong> for predictive modeling and doing inference. There is a <strong>high level of collective experience and expertise</strong>, including teaching materials on linear regression models and software implementations. Linear regression can be found in R, Python, Java, Julia, Scala, Javascript, …</p>
<p>Mathematically, it’s straightforward to estimate the weights and you have a <strong>guarantee to find optimal weights</strong> (given all assumptions of the linear regression model are met by the data).</p>
<p>Together with the weights you get confidence intervals, tests, a very solid statistical theory. There are also many extensions of the linear regression model (see <a href="extend-lm.html#extend-lm">chapter Linear Model 2.0 - GLMs, GAMs and more</a>).</p>
</div>
<div id="disadvantages" class="section level3">
<h3><span class="header-section-number">4.1.9</span> Disadvantages</h3>
<p>Linear models can only represent linear relationships, i.e. a weighted sum of the input features. Each <strong>non-linearity or interaction has to be hand-crafted</strong> and explicitly given to the model as an input feature.</p>
<p>Linear models are also often <strong>not that good regarding predictive performance</strong>, because the relationships that can be learned are so restricted and usually oversimplifies how complex reality is.</p>
<p>The interpretation of a weight <strong>can be unintuitive</strong> because it depends on all other features. A feature with high positive correlation with the outcome <span class="math inline">\(y\)</span> and another feature might get a negative weight in the linear model, because, given the other correlated feature, it is negatively correlated with <span class="math inline">\(y\)</span> in the high-dimensional space. Completely correlated features make it even impossible to find a unique solution for the linear equation. An example: You have a model to predict the value of a house and have features like number of rooms and area of the house. House area and number of rooms are highly correlated: the bigger a house is, the more rooms it has. If you now take both features into a linear model, it might happen, that the area of the house is the better predictor and get’s a large positive weight. The number of rooms might end up getting a negative weight, because either, given that a house has the same size, increasing the number of rooms could make it less valuable or the linear equation becomes less stable, when the correlation is too strong.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="15">
<li id="fn15"><p>Hastie, T, R Tibshirani, and J Friedman. 2009. The elements of statistical learning. <a href="http://link.springer.com/content/pdf/10.1007/978-0-387-84858-7.pdf" class="uri">http://link.springer.com/content/pdf/10.1007/978-0-387-84858-7.pdf</a>.<a href="limo.html#fnref15">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="simple.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="logistic.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/04.2-interpretable-linear.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
