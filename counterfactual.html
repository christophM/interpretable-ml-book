<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>15&nbsp; Counterfactual Explanations – Interpretable Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./anchors.html" rel="next">
<link href="./lime.html" rel="prev">
<link href="./images/favicon.jpg" rel="icon" type="image/jpeg">
<script src="site_libs/cookie-consent/cookie-consent.js"></script>
<link href="site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-5e169a3c071d6ad0320cbd7522dabfb3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script src="site_libs/quarto-contrib/glightbox/glightbox.min.js"></script>
<link href="site_libs/quarto-contrib/glightbox/glightbox.min.css" rel="stylesheet">
<link href="site_libs/quarto-contrib/glightbox/lightbox.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-V7RTNZBGE2"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-V7RTNZBGE2', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"en"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>
<!-- Add this to your header.html -->
<style>
.book-purchase-links {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1.5rem;
    background: linear-gradient(to bottom right, #ffffff, #f8f9fa);
    border-radius: 12px;
    margin: 1.5rem 0;
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    border: double 1px transparent;
    background-image: linear-gradient(to bottom right, #ffffff, #f8f9fa),
                     linear-gradient(to bottom right, #3b82f6, #60a5fa);
    background-origin: border-box;
    background-clip: padding-box, border-box;
}

.purchase-header {
    text-align: center;
    margin-bottom: -1rem;
    margin-top: -1rem;
    color: #2b3442;
}

.purchase-header h3 {
    margin: 0 0 0.5rem 0;
    font-size: 1.5rem;
    font-weight: 700;
}

.purchase-header p {
    margin: 0;
    font-size: 0.9rem;
    color: #6c757d;
}

.book-cover {
    width: 80%;
    height: auto;
    border-radius: 8px;
    margin: 0 auto 1rem auto;
    transition: transform 0.3s ease;
}

.book-cover:hover {
    transform: scale(1.1);
}

.purchase-link {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem 1rem;
    text-decoration: none;
    color: #2b3442;
    border-radius: 8px;
    transition: all 0.2s ease;
    background: white;
    border: 1px solid #e9ecef;
    font-weight: 500;
}

.purchase-link:hover {
    background-color: #f8f9fa;
    transform: translateY(-2px);
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
    text-decoration: none;
}

.purchase-link.primary {
    background-color: #0066cc;
    color: white;
    border: none;
}

.purchase-link.primary:hover {
    background-color: #0052a3;
}

.purchase-link svg {
    width: 20px;
    height: 20px;
    flex-shrink: 0;
}

.price-tag {
    margin-left: auto;
    font-weight: 600;
    color: inherit;
}

.social-proof {
    text-align: center;
    font-size: 0.85rem;
    color: #6c757d;
    margin-top: 0.5rem;
}

.limited-offer {
    background: #fff3cd;
    color: #856404;
    padding: 0.5rem;
    border-radius: 6px;
    font-size: 0.85rem;
    text-align: center;
    margin-bottom: 1rem;
}

@media (max-width: 768px) {
    .book-purchase-links {
        padding: 1rem;
    }
    
    .book-cover {
        width: 60%;
    }
}
</style>

<script>
document.addEventListener('DOMContentLoaded', function() {
    const purchaseLinksContainer = document.getElementById('book-purchase-links');
    if (!purchaseLinksContainer) return;

    const purchaseOptions = [
        {
            type: 'Paperback',
            primary: true,
            url: 'https://bookgoodies.com/a/3911578032',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path></svg>'
        },
        {
            type: 'E-Book & PDF',
            url: 'https://leanpub.com/interpretable-machine-learning',
            icon: '<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 19.5A2.5 2.5 0 0 1 6.5 17H20"></path><path d="M6.5 2H20v20H6.5A2.5 2.5 0 0 1 4 19.5v-15A2.5 2.5 0 0 1 6.5 2z"></path><path d="M12 6v8"></path><path d="M8 10h8"></path></svg>'
        }
    ];

    // Create header section
    const header = document.createElement('div');
    header.className = 'purchase-header';
    header.innerHTML = `
        <h3>Buy Book</h3>
    `;
    purchaseLinksContainer.appendChild(header);

    // Create limited time offer banner
    // const limitedOffer = document.createElement('div');
    // limitedOffer.className = 'limited-offer';
    // limitedOffer.textContent = '🎉 Special Launch Price - Limited Time Only!';
    // purchaseLinksContainer.appendChild(limitedOffer);

    // Create and append book cover
    const bookCover = document.createElement('img');
    //bookCover.src = 'images/mockup-floating.png';
    bookCover.src = './images/cover-sidepanel.jpg';
    bookCover.alt = 'Book Cover';
    bookCover.className = 'book-cover';
    purchaseLinksContainer.appendChild(bookCover);

    // Create and append purchase links
    purchaseOptions.forEach(option => {
        const link = document.createElement('a');
        link.href = option.url;
        link.className = `purchase-link ${option.primary ? 'primary' : ''}`;
        link.innerHTML = `
            ${option.icon}
            ${option.type}
        `;
        purchaseLinksContainer.appendChild(link);
    });

    // Add social proof
    // const socialProof = document.createElement('div');
    // socialProof.className = 'social-proof';
    // socialProof.textContent = '👥 Join thousands of satisfied readers!';
    // purchaseLinksContainer.appendChild(socialProof);
});
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ceteris-paribus.html">Local Model-Agnostic Methods</a></li><li class="breadcrumb-item"><a href="./counterfactual.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Interpretable Machine Learning</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/christophM/interpretable-ml-book" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">About the Book</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interpretability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./goals.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Goals of Interpretability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./overview.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Methods Overview</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Data and Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Interpretable Models</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./limo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Linear Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./extend-lm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">GLM, GAM and more</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Decision Tree</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rules.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Decision Rules</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rulefit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">RuleFit</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Local Model-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ceteris-paribus.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Ceteris Paribus Plots</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ice.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Individual Conditional Expectation (ICE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LIME</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./counterfactual.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./anchors.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Scoped Rules (Anchors)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shapley.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Shapley Values</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./shap.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">SHAP</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Global Model-Agnostic Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pdp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Partial Dependence Plot (PDP)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ale.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Accumulated Local Effects (ALE)</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./interaction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Feature Interaction</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Functional Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./feature-importance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Permutation Feature Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lofo.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Leave One Feature Out (LOFO) Importance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./global.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Surrogate Models</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./proto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Prototypes and Criticisms</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Neural Network Interpretation</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cnn-features.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Learned Features</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pixel-attribution.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Saliency Maps</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./detecting-concepts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Detecting Concepts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./adversarial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Adversarial Examples</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./influential.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Influential Instances</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Beyond the Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">Evaluation of Interpretability Methods</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./storytime.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Story Time</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./future.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">The Future of Interpretability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./translations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Translations</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cite.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Citing this Book</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./acknowledgements.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Acknowledgments</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./what-is-machine-learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Machine Learning Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./math-terms.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Math Terms</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r-packages.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">R packages used</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#generating-counterfactual-explanations" id="toc-generating-counterfactual-explanations" class="nav-link active" data-scroll-target="#generating-counterfactual-explanations">Generating counterfactual explanations</a>
  <ul class="collapse">
  <li><a href="#method-by-wachter-et-al." id="toc-method-by-wachter-et-al." class="nav-link" data-scroll-target="#method-by-wachter-et-al.">Method by Wachter et al.</a></li>
  <li><a href="#method-by-dandl-et-al." id="toc-method-by-dandl-et-al." class="nav-link" data-scroll-target="#method-by-dandl-et-al.">Method by Dandl et al.</a></li>
  </ul></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example">Example</a></li>
  <li><a href="#strengths" id="toc-strengths" class="nav-link" data-scroll-target="#strengths">Strengths</a></li>
  <li><a href="#limitations" id="toc-limitations" class="nav-link" data-scroll-target="#limitations">Limitations</a></li>
  <li><a href="#example-software" id="toc-example-software" class="nav-link" data-scroll-target="#example-software">Software and alternatives</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/counterfactual.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    <div class="quarto-margin-footer"><div class="margin-footer-item">
<div id="book-purchase-links" class="book-purchase-links">

</div>
</div></div></div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ceteris-paribus.html">Local Model-Agnostic Methods</a></li><li class="breadcrumb-item"><a href="./counterfactual.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="counterfactual" class="quarto-section-identifier"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Counterfactual Explanations</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em>Authors: Susanne Dandl &amp; Christoph Molnar</em></p>
<p>A counterfactual explanation describes a causal situation in the form: “If X had not occurred, Y would not have occurred.” For example: “If I hadn’t taken a sip of this hot coffee, I wouldn’t have burned my tongue.” Event Y is that I burned my tongue; cause X is that I had a hot coffee. Thinking in counterfactuals requires imagining a hypothetical reality that contradicts the observed facts (for example, a world in which I’ve not drunk the hot coffee), hence the name “counterfactual.” The ability to think in counterfactuals makes us humans so smart compared to other animals.</p>
<p>In interpretable machine learning, counterfactual explanations can be used to explain predictions of individual instances.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Displayed as a graph (<a href="#fig-ml-graph-cf" class="quarto-xref">Figure&nbsp;<span>15.1</span></a>), the relationship between the inputs and the prediction is very simple: The feature values cause the prediction. Even if in reality the relationship between the inputs and the outcome to be predicted might not be causal, we can see the inputs of a model as the cause of the prediction.</p>
<div id="fig-ml-graph-cf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ml-graph-cf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="images/graph.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-1" title="Figure&nbsp;15.1: The causal relationships between inputs of a machine learning model and the predictions, when the model is merely seen as a black box. The inputs cause the prediction (not necessarily reflecting the real causal relation of the data)."><img src="images/graph.jpg" class="img-fluid figure-img" style="width:80.0%"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ml-graph-cf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.1: The causal relationships between inputs of a machine learning model and the predictions, when the model is merely seen as a black box. The inputs cause the prediction (not necessarily reflecting the real causal relation of the data).
</figcaption>
</figure>
</div>
<p>Given this simple graph, it’s easy to see how we can simulate counterfactuals for predictions of machine learning models: We simply change the feature values of an instance before making the predictions and we analyze how the prediction changes. We’re interested in scenarios in which the prediction changes in a relevant way, like a flip in predicted class (for example, credit application accepted or rejected), or in which the prediction reaches a certain threshold (for example, the probability for cancer reaches 10%). <strong>A counterfactual explanation of a prediction describes the smallest change to the feature values that changes the prediction to a predefined output.</strong></p>
<p>There are both model-agnostic and model-specific counterfactual explanation methods, but in this chapter we focus on model-agnostic methods that only work with the model inputs and outputs (and not the internal structure of specific models).</p>
<p>Before discussing how to create counterfactuals, I would like to discuss some use cases for counterfactuals and how a good counterfactual explanation looks like.</p>
<p>In this first example, Peter applies for a loan and gets rejected by the (machine learning-powered) banking software. He wonders why his application was rejected and how he might improve his chances to get a loan. The question of “why” can be formulated as a counterfactual: What’s the smallest change to the features (income, number of credit cards, age, …) that would change the prediction from rejected to approved? One possible answer could be: If Peter would earn 10,000 more per year, he would get the loan. Or if Peter had fewer credit cards and had not defaulted on a loan five years ago, he would get the loan. Peter will never know the reasons for the rejection, as the bank has no interest in transparency, but that is another story.</p>
<p>In our second example, we want to explain a model that predicts a continuous outcome with counterfactual explanations. Anna wants to rent out her apartment, but she is not sure how much to charge for it, so she decides to train a machine learning model to predict the rent. Of course, since Anna is a data scientist, that is how she solves her problems. After entering all the details about size, location, whether pets are allowed, and so on, the model tells her that she can charge 900 EUR. She expected 1000 EUR or more, but she trusts her model and decides to play with the feature values of the apartment to see how she can improve the value of the apartment. She finds out that the apartment could be rented out for over 1000 EUR if it were 15 m<sup>2</sup> larger. Interesting, but non-actionable knowledge, because she cannot enlarge her apartment. Finally, by tweaking only the feature values under her control (built-in kitchen yes/no, pets allowed yes/no, type of floor, etc.), she finds out that if she allows pets and installs windows with better insulation, she can charge 1000 EUR. Anna has intuitively worked with counterfactuals to change the outcome. Note that Anna worked with the rent prediction model and wasn’t necessarily interested in whether these factors are truly causal for higher rent in the “real world.”</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>By default, counterfactuals (the IML method) alone don’t support <strong>causal</strong> claims about the real world. This would require a causal model.</p>
</div>
</div>
<p>Counterfactuals are <a href="interpretability.html#good-explanation">human-friendly explanations</a> because they are contrastive to the current instance and because they are selective, meaning they usually focus on a small number of feature changes. But counterfactuals suffer from the ‘Rashomon effect.’ Rashomon is a Japanese movie in which the murder of a Samurai is told by different people. Each of the stories explains the outcome equally well, but the stories contradict each other. The same can also happen with counterfactuals, since there are usually multiple different counterfactual explanations. Each counterfactual tells a different “story” of how a certain outcome was reached. One counterfactual might say to change feature A, the other counterfactual might say to leave A the same but change feature B, which is a contradiction. This issue of multiple truths can be addressed either by reporting all counterfactual explanations or by having a criterion to evaluate counterfactuals and select the best one.</p>
<p>Speaking of criteria, how do we define a good counterfactual explanation? First, the user of a counterfactual explanation defines a relevant change in the prediction of an instance (the alternative reality). An obvious first requirement is that <strong>a counterfactual instance produces the predefined prediction as closely as possible</strong>. It’s not always possible to find a counterfactual with the predefined prediction. For example, in a classification setting with two classes, a rare class and a frequent class, the model might always classify an instance as the frequent class. Changing the feature values so that the predicted label would flip from the frequent class to the rare class might be impossible. We therefore want to relax the requirement that the prediction of the counterfactual must match the predefined outcome exactly. In the classification example, we could look for a counterfactual where the predicted probability of the rare class is increased to 10% instead of the current 2%. The question then is, what are the minimal changes in the features so that the predicted probability changes from 2% to 10% (or close to 10%)?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Use probabilities
</div>
</div>
<div class="callout-body-container callout-body">
<p>For classification tasks, it’s better to define the counterfactual in terms of predicted probabilities than class outcomes.</p>
</div>
</div>
<p>Another quality criterion is that <strong>a counterfactual should be as similar as possible to the instance regarding feature values</strong>. The distance between two instances can be measured, for example, with the Manhattan distance or the Gower distance if we have both discrete and continuous features. The counterfactual should not only be close to the original instance, but should also <strong>change as few features as possible</strong>. To measure how good a counterfactual explanation is in this metric, we can simply count the number of changed features or, in fancy mathematical terms, measure the <span class="math inline">\(L_0\)</span> norm between the counterfactual and actual instance.</p>
<p>Third, it is often desirable to generate <strong>multiple diverse counterfactual explanations</strong> so that the decision subject gets access to multiple viable ways of generating a different outcome. For instance, continuing our loan example, one counterfactual explanation might suggest only doubling the income to get a loan, while another counterfactual might suggest shifting to a nearby city and increasing the income by a small amount to get a loan. It could be noted that while the first counterfactual might be possible for some, the latter might be more actionable for others. Thus, besides providing a decision subject with different ways to get the desired outcome, diversity also enables “diverse” individuals to alter the features that are convenient for them.</p>
<p>The last requirement is that <strong>a counterfactual instance should have feature values that are likely</strong>. It would not make sense to generate a counterfactual explanation for the rent example where the size of an apartment is negative or the number of rooms is set to 200. It’s even better when the counterfactual is likely according to the joint distribution of the data; for example, an apartment with 10 rooms and 20 m<sup>2</sup> should not be regarded as a counterfactual explanation. Ideally, if the number of square meters is increased, an increase in the number of rooms should also be proposed.</p>
<section id="generating-counterfactual-explanations" class="level2">
<h2 class="anchored" data-anchor-id="generating-counterfactual-explanations">Generating counterfactual explanations</h2>
<p>A simple and naive approach to generating counterfactual explanations is searching by trial and error. This approach involves randomly changing feature values of the instance of interest and stopping when the desired output is predicted. Like the example where Anna tried to find a version of her apartment for which she could charge more rent. But there are better approaches than trial and error. First, we define a loss function based on the criteria mentioned above. This loss takes as input the instance of interest, a counterfactual, and the desired (counterfactual) outcome. Then, we can find the counterfactual explanation that minimizes this loss using an optimization algorithm. Many methods proceed in this way, but differ in their definition of the loss function and optimization method.</p>
<p>In the following, we focus on two of them: first, the one by <span class="citation" data-cites="wachter2018counterfactual">Wachter, Mittelstadt, and Russell (<a href="references.html#ref-wachter2018counterfactual" role="doc-biblioref">2018</a>)</span>, who introduced counterfactual explanation as an interpretation method and, second, the one by <span class="citation" data-cites="dandl2020multiobjective">Dandl et al. (<a href="references.html#ref-dandl2020multiobjective" role="doc-biblioref">2020</a>)</span> that takes into account all four criteria mentioned above.</p>
<section id="method-by-wachter-et-al." class="level3">
<h3 class="anchored" data-anchor-id="method-by-wachter-et-al.">Method by Wachter et al.</h3>
<p>Wachter et al.&nbsp;suggest minimizing the following loss:</p>
<p><span class="math display">\[L(\mathbf{x}, \mathbf{x}^{\prime}, y^{\prime}, \lambda) = \lambda \cdot (\hat{f}(\mathbf{x}^{\prime}) - y^{\prime})^2 + d(\mathbf{x}, \mathbf{x}^{\prime})\]</span></p>
<p>The first term is the quadratic distance between the model prediction for the counterfactual <span class="math inline">\(\mathbf{x}^{\prime}\)</span> and the desired outcome <span class="math inline">\(y^{\prime}\)</span>, which the user must define in advance. The second term is the distance <span class="math inline">\(d\)</span> between the instance <span class="math inline">\(\mathbf{x}\)</span> to be explained and the counterfactual <span class="math inline">\(\mathbf{x}^{\prime}\)</span>. The loss measures how far the predicted outcome of the counterfactual is from the predefined outcome and how far the counterfactual is from the instance of interest. The distance function <span class="math inline">\(d\)</span> is defined as the Manhattan distance weighted with the inverse median absolute deviation (MAD) of each feature.</p>
<p><span class="math display">\[d(x,x^\prime)=\sum_{j=1}^p\frac{|x_j-x^\prime_j|}{MAD_j}\]</span></p>
<p>The total distance is the sum of all <span class="math inline">\(p\)</span> feature-wise distances, that is, the absolute differences of feature values between instance <span class="math inline">\(\mathbf{x}\)</span> and counterfactual <span class="math inline">\(\mathbf{x}'\)</span>. The feature-wise distances are scaled by the inverse of the median absolute deviation of feature <span class="math inline">\(j\)</span> over the dataset defined as:</p>
<p><span class="math display">\[MAD_j = \text{median}_{i \in \{1, \ldots, n\}} \left( |x^{(i)}_j - \text{median}_{l \in \{1, \ldots, n\}}(x^{(l)}_j)| \right)\]</span></p>
<p>The median of a vector is the value at which half of the vector values are greater and the other half smaller. The MAD is the equivalent of the variance of a feature, but instead of using the mean as the center and summing over the square distances, we use the median as the center and sum over the absolute distances. The proposed distance function has the advantage over the Euclidean distance that <!-- it introduces sparsity.
This means that two points are closer to each other when fewer features are different.
--> it is more robust to outliers. Scaling with the MAD is necessary to bring all the features to the same scale – it should not matter whether you measure the size of an apartment in square meters or square feet.</p>
<p>The parameter <span class="math inline">\(\lambda\)</span> balances the distance in prediction (first term) against the distance in feature values (second term). The loss is solved for a given <span class="math inline">\(\lambda\)</span> and returns a counterfactual <span class="math inline">\(\mathbf{x}^{\prime}\)</span>. A higher value of <span class="math inline">\(\lambda\)</span> means that we prefer counterfactuals with predictions close to the desired outcome <span class="math inline">\(y^{\prime}\)</span>, while a lower value means that we prefer counterfactuals <span class="math inline">\(\mathbf{x}^{\prime}\)</span> that are very similar to <span class="math inline">\(\mathbf{x}\)</span> in the feature values. If <span class="math inline">\(\lambda\)</span> is very large, the instance with the prediction closest to <span class="math inline">\(y^{\prime}\)</span> will be selected, regardless of how far it is from <span class="math inline">\(\mathbf{x}\)</span>. Ultimately, the user must decide how to balance the requirement that the prediction for the counterfactual matches the desired outcome with the requirement that the counterfactual is similar to <span class="math inline">\(\mathbf{x}\)</span>. The authors of the method suggest instead of selecting a value for <span class="math inline">\(\lambda\)</span>, to select a tolerance <span class="math inline">\(\epsilon\)</span> for how far away from <span class="math inline">\(y^{\prime}\)</span> the prediction of the counterfactual instance is allowed to be. This constraint can be written as:</p>
<p><span class="math display">\[|\hat{f}(\mathbf{x}^{\prime}) - y^{\prime}| \leq \epsilon\]</span></p>
<p>To minimize this loss function, any suitable optimization algorithm can be used, such as Nelder-Mead. If you have access to the gradients of the machine learning model, you can use gradient-based methods like ADAM. The instance <span class="math inline">\(\mathbf{x}\)</span> to be explained, the desired output <span class="math inline">\(y^{\prime}\)</span>, and the tolerance parameter <span class="math inline">\(\epsilon\)</span> must be set in advance. The loss function is minimized for <span class="math inline">\(\mathbf{x}^{\prime}\)</span> and the (locally) optimal counterfactual <span class="math inline">\(\mathbf{x}^{\prime}\)</span> returned while increasing <span class="math inline">\(\lambda\)</span> until a sufficiently close solution is found (= within the tolerance parameter):</p>
<p><span class="math display">\[\arg\min_{\mathbf{x}^{\prime}} \max_{\lambda} L(\mathbf{x}, \mathbf{x}^{\prime}, y^{\prime}, \lambda).\]</span></p>
<p>Overall, the recipe for producing the counterfactuals is simple:</p>
<ol type="1">
<li>Select an instance <span class="math inline">\(\mathbf{x}\)</span> to be explained, the desired outcome <span class="math inline">\(y^{\prime}\)</span>, a tolerance <span class="math inline">\(\epsilon\)</span>, and a (low) initial value for <span class="math inline">\(\lambda\)</span>.</li>
<li>Sample a random instance as initial counterfactual.</li>
<li>Optimize the loss with the initially sampled counterfactual as the starting point.</li>
<li>While <span class="math inline">\(|\hat{f}(\mathbf{x}^{\prime}) - y^{\prime}| &gt; \epsilon\)</span>:
<ul>
<li>Increase <span class="math inline">\(\lambda\)</span>.</li>
<li>Optimize the loss with the current counterfactual as the starting point.</li>
<li>Return the counterfactual that minimizes the loss.</li>
</ul></li>
<li>Repeat steps 2-4 and return the list of counterfactuals or the one that minimizes the loss.</li>
</ol>
<p>The proposed method has some disadvantages. It <strong>only takes the first and second criteria into account</strong>, not the last two (“produce counterfactuals with only a few feature changes and likely feature values”). <span class="math inline">\(d\)</span> does not prefer sparse solutions since increasing 10 features by 1 will give the same distance to <span class="math inline">\(\mathbf{x}\)</span> as increasing one feature by 10. Unrealistic feature combinations are not penalized.</p>
<p>The method does <strong>not handle categorical features</strong> with many different levels well. The authors of the method suggested running the method separately for each combination of feature values of the categorical features, but this will lead to a combinatorial explosion if you have multiple categorical features with many values. For example, six categorical features with ten unique levels would mean one million runs.</p>
<p>Let’s now have a look at another approach overcoming these issues.</p>
</section>
<section id="method-by-dandl-et-al." class="level3">
<h3 class="anchored" data-anchor-id="method-by-dandl-et-al.">Method by Dandl et al.</h3>
<p>Dandl et al.&nbsp;suggest simultaneously minimizing a four-objective loss:</p>
<p><span class="math display">\[L(\mathbf{x},\mathbf{x'},y',\mathbf{X}^{\text{obs}})=\big(o_1(\hat{f}(\mathbf{x'}),y'),o_2(\mathbf{x}, \mathbf{x'}),o_3(\mathbf{x},\mathbf{x'}),o_4(\mathbf{x'},\mathbf{X}^{\text{obs}})\big) \]</span></p>
<p>Each of the four objectives <span class="math inline">\(o_1\)</span> to <span class="math inline">\(o_4\)</span> corresponds to one of the four criteria mentioned above. The first objective <span class="math inline">\(o_1\)</span> reflects that the prediction of our counterfactual <span class="math inline">\(\mathbf{x'}\)</span> should be as close as possible to our desired prediction <span class="math inline">\(y'\)</span>. We therefore want to minimize the distance between <span class="math inline">\(\hat{f}(\mathbf{x'})\)</span> and <span class="math inline">\(y'\)</span>, here calculated by the Manhattan metric (<span class="math inline">\(L_1\)</span> norm):</p>
<p><span class="math display">\[
o_1(\hat{f}(\mathbf{x'}),y') =
\begin{cases}
0 &amp;\text{if $\hat{f}(\mathbf{x}^{\prime}) \in y^{\prime}$} \\
\inf\limits_{y^{\prime} \in y^{\prime}} | \hat{f}(\mathbf{x}^{\prime}) - y^{\prime} | &amp; \text{else}
\end{cases}
\]</span></p>
<p>The second objective <span class="math inline">\(o_2\)</span> reflects that our counterfactual should be as similar as possible to our instance <span class="math inline">\(\mathbf{x}\)</span>. It quantifies the distance between <span class="math inline">\(\mathbf{x'}\)</span> and <span class="math inline">\(\mathbf{x}\)</span> as the Gower distance:</p>
<p><span class="math display">\[o_2(\mathbf{x},\mathbf{x'})=\frac{1}{p}\sum_{j=1}^{p}\delta_G(x_j, x'_j)\]</span></p>
<p>with <span class="math inline">\(p\)</span> being the number of features. The value of <span class="math inline">\(\delta_G\)</span> depends on the feature type of <span class="math inline">\(x_j\)</span>:</p>
<p><span class="math display">\[\delta_G(x_j,x'_j)=\begin{cases}\frac{1}{\widehat{R}_j}|x_j-x'_j|&amp;\text{if $x_j$ numerical}\\\mathbb{I}_{x_j\neq{}x'_j}&amp;\text{if $x_j$ categorical}\end{cases}\]</span></p>
<p>Dividing the distance of a numeric feature <span class="math inline">\(j\)</span> by <span class="math inline">\(\widehat{R}_j\)</span>, the observed value range, scales <span class="math inline">\(\delta_G\)</span> for all features between 0 and 1.</p>
<p>The Gower distance can handle both numerical and categorical features, but does not count how many features were changed. Therefore, we count the number of features in a third objective <span class="math inline">\(o_3\)</span> using the <span class="math inline">\(L_0\)</span> norm:</p>
<p><span class="math display">\[o_3(\mathbf{x},\mathbf{x'})=||\mathbf{x}-\mathbf{x'}||_0=\sum_{j=1}^{p}I_{x'_j\neq x_j}.\]</span></p>
<p>By minimizing <span class="math inline">\(o_3\)</span> we aim for our third criterion – sparse feature changes.</p>
<p>The fourth objective <span class="math inline">\(o_4\)</span> reflects that our counterfactuals should have likely combinations of feature values. We can infer how “likely” a data point is using the training data or another dataset. We denote this dataset as <span class="math inline">\(\mathbf{X}^{\text{obs}}\)</span>. As an approximation for the likelihood, <span class="math inline">\(o_4\)</span> measures the average Gower distance between <span class="math inline">\(\mathbf{x'}\)</span> and the nearest observed data point <span class="math inline">\(x^{[1]}\in \mathbf{X}^{\text{obs}}\)</span>:</p>
<p><span class="math display">\[o_4(\mathbf{x'},\mathbf{X}^{\text{obs}})=\frac{1}{p}\sum_{j=1}^{p}\delta_G(x'_j,x^{[1]}_j)\]</span></p>
<p>Compared to Wachter et al., <span class="math inline">\(L(\mathbf{x},\mathbf{x}',y',\mathbf{X}^{\text{obs}})\)</span> has no balancing/weighting terms like <span class="math inline">\(\lambda\)</span>. We do not want to collapse the four objectives <span class="math inline">\(o_1\)</span>, <span class="math inline">\(o_2\)</span>, <span class="math inline">\(o_3\)</span>, and <span class="math inline">\(o_4\)</span> into a single objective by summing them up and weighting them, but we want to optimize all four terms simultaneously.</p>
<p>How can we do that? We use the <strong>Nondominated Sorting Genetic Algorithm</strong> <span class="citation" data-cites="deb2002fast">(<a href="references.html#ref-deb2002fast" role="doc-biblioref">Deb et al. 2002</a>)</span> or short NSGA-II. NSGA-II is a nature-inspired algorithm that applies Darwin’s law of the “survival of the fittest”. We denote the fitness of a counterfactual by its vector of objective values <span class="math inline">\((o_1,o_2,o_3,o_4)\)</span>. The lower the values of the objectives for a counterfactual, the “fitter” it is.</p>
<p>The algorithm consists of four steps that are repeated until a stopping criterion is met, for example, a maximum number of iterations/generations. <a href="#fig-nsgaII-cf" class="quarto-xref">Figure&nbsp;<span>15.2</span></a> visualizes the four steps of one generation.</p>
<div id="fig-nsgaII-cf" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-nsgaII-cf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<a href="./images/cfexp-nsgaII.jpg" class="lightbox" data-gallery="quarto-lightbox-gallery-2" title="Figure&nbsp;15.2: Visualization of one generation of the NSGA-II algorithm."><img src="./images/cfexp-nsgaII.jpg" class="img-fluid figure-img"></a>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-nsgaII-cf-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;15.2: Visualization of one generation of the NSGA-II algorithm.
</figcaption>
</figure>
</div>
<p>In the first generation, a group of counterfactual candidates is initialized by randomly changing some of the features compared to our instance <span class="math inline">\(\mathbf{x}\)</span> to be explained. Sticking with the above credit example, one counterfactual could suggest increasing the income by €30,000 while another one proposes to have no default in the last five years and a reduction in age by ten. All other feature values are equal to the values of <span class="math inline">\(\mathbf{x}\)</span>. Each candidate is then evaluated using the four objective functions above. Among them, we randomly select some candidates, where fitter candidates are more likely to be selected. The candidates are pairwise recombined to produce children that are similar to them by averaging their numerical feature values or by crossing over their categorical features. In addition, we slightly mutate the feature values of the children to explore the whole feature space.</p>
<p>From the two resulting groups, one with parents and one with children, we only want the best half using two sorting algorithms. The nondominated sorting algorithm sorts the candidates according to their objective values. If candidates are equally good, the crowding distance sorting algorithm sorts the candidates according to their diversity.</p>
<p>Given the ranking of the two sorting algorithms, we select the most promising and/or most diverse half of the candidates. We use this set for the next generation and start again with the selection, recombination, and mutation process. By repeating the steps over and over, we hopefully approach a diverse set of promising candidates with low objective values. From this set, we can choose those with which we are most satisfied, or we can give a summary of all counterfactuals by highlighting which and how often features have been changed.</p>
</section>
</section>
<section id="example" class="level2">
<h2 class="anchored" data-anchor-id="example">Example</h2>
<p>The following example is based on the credit dataset example in Dandl et al.&nbsp;(2020). The German Credit Risk dataset can be found on the machine learning challenges platform <a href="https://www.kaggle.com/uciml/german-credit">kaggle.com</a>. The authors trained a support vector machine (with radial basis kernel) to predict the probability that a customer has a good credit risk. The corresponding dataset has 522 complete observations and nine features containing credit and customer information.</p>
<p>The goal is to find counterfactual explanations for a customer with feature values in <a href="#tbl-customer" class="quarto-xref">Table&nbsp;<span>15.1</span></a>.</p>
<div id="tbl-customer" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-customer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;15.1: Feature values of a particular customer
</figcaption>
<div aria-describedby="tbl-customer-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>age</th>
<th>sex</th>
<th>job</th>
<th>housing</th>
<th>savings</th>
<th>amount</th>
<th>dur.</th>
<th>purpose</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>58</td>
<td>f</td>
<td>unskilled</td>
<td>free</td>
<td>little</td>
<td>6143</td>
<td>48</td>
<td>car</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The SVM predicts that the probability that the person has a good credit risk is 24.2%. The counterfactuals should answer how the input features need to be changed to get a predicted probability larger than 50%. <a href="#tbl-best-counterfactuals" class="quarto-xref">Table&nbsp;<span>15.2</span></a> shows the ten best counterfactuals. The first five columns contain the proposed feature changes (only altered features are displayed), the next three columns show the objective values (<span class="math inline">\(o_1\)</span> equals 0 in all cases), and the last column displays the predicted probability.</p>
<div id="tbl-best-counterfactuals" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-best-counterfactuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;15.2: The ten best counterfactuals found for the customer
</figcaption>
<div aria-describedby="tbl-best-counterfactuals-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>age</th>
<th>sex</th>
<th>job</th>
<th>amount</th>
<th>dur.</th>
<th>o<sub>2</sub></th>
<th>o<sub>3</sub></th>
<th>o<sub>4</sub></th>
<th>f(x’)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td>skilled</td>
<td></td>
<td>-20</td>
<td>0.108</td>
<td>2</td>
<td>0.036</td>
<td>0.501</td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td>skilled</td>
<td></td>
<td>-24</td>
<td>0.114</td>
<td>2</td>
<td>0.029</td>
<td>0.525</td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td>skilled</td>
<td></td>
<td>-22</td>
<td>0.111</td>
<td>2</td>
<td>0.033</td>
<td>0.513</td>
</tr>
<tr class="even">
<td>-6</td>
<td></td>
<td>skilled</td>
<td></td>
<td>-24</td>
<td>0.126</td>
<td>3</td>
<td>0.018</td>
<td>0.505</td>
</tr>
<tr class="odd">
<td>-3</td>
<td></td>
<td>skilled</td>
<td></td>
<td>-24</td>
<td>0.120</td>
<td>3</td>
<td>0.024</td>
<td>0.515</td>
</tr>
<tr class="even">
<td>-1</td>
<td></td>
<td>skilled</td>
<td></td>
<td>-24</td>
<td>0.116</td>
<td>3</td>
<td>0.027</td>
<td>0.522</td>
</tr>
<tr class="odd">
<td>-3</td>
<td>m</td>
<td></td>
<td></td>
<td>-24</td>
<td>0.195</td>
<td>3</td>
<td>0.012</td>
<td>0.501</td>
</tr>
<tr class="even">
<td>-6</td>
<td>m</td>
<td></td>
<td></td>
<td>-25</td>
<td>0.202</td>
<td>3</td>
<td>0.011</td>
<td>0.501</td>
</tr>
<tr class="odd">
<td>-30</td>
<td>m</td>
<td>skilled</td>
<td></td>
<td>-24</td>
<td>0.285</td>
<td>4</td>
<td>0.005</td>
<td>0.590</td>
</tr>
<tr class="even">
<td>-4</td>
<td>m</td>
<td></td>
<td>-1254</td>
<td>-24</td>
<td>0.204</td>
<td>4</td>
<td>0.002</td>
<td>0.506</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>All counterfactuals have predicted probabilities greater than 50% and do not dominate each other. Nondominated means that none of the counterfactuals has smaller values in all objectives than the other counterfactuals. We can think of our counterfactuals as a set of trade-off solutions.</p>
<p>They all suggest a reduction of the duration from 48 months to a minimum of 23 months, some of them propose that the woman should become skilled instead of unskilled. Some counterfactuals even suggest changing the gender from female to male, which shows a gender bias of the model. This change is always accompanied by a reduction in age between one and 30 years. We can also see that, although some counterfactuals suggest changes to four features, these counterfactuals are the ones that are closest to the training data.</p>
</section>
<section id="strengths" class="level2">
<h2 class="anchored" data-anchor-id="strengths">Strengths</h2>
<p><strong>The interpretation of counterfactual explanations is very clear</strong>. If the feature values of an instance are changed according to the counterfactual, the prediction changes to the predefined prediction. There are no additional assumptions and no magic in the background. This also means counterfactuals are not as dangerous as methods like <a href="lime.html">LIME</a>, where it is unclear how far we can extrapolate the local model for the interpretation.</p>
<p>The counterfactual method creates a new instance, but we can also summarize a counterfactual by reporting which feature values have changed. This gives us <strong>two options for reporting our results</strong>. You can either report the counterfactual instance or highlight which features have been changed between the instance of interest and the counterfactual instance.</p>
<p>The <strong>counterfactual method does not require access to the data or the model</strong>. It only requires access to the model’s prediction function, which would also work via a web API, for example. This is attractive for companies which are audited by third parties or which are offering explanations for users without disclosing the model or data. A company has an interest in protecting the model and data because of trade secrets or data protection reasons. Counterfactual explanations offer a balance between explaining model predictions and protecting the interests of the model owner.</p>
<p>The method <strong>works also with systems that do not use machine learning</strong>. We can create counterfactuals for any system that receives inputs and returns outputs. The system that predicts apartment rents could also consist of handwritten rules, and counterfactual explanations would still work.</p>
<p><strong>The counterfactual explanation method is relatively easy to implement</strong>, since it’s essentially a loss function (with a single or many objectives) that can be optimized with standard optimizer libraries. Some additional details must be taken into account, such as limiting feature values to meaningful ranges (e.g., only positive apartment sizes).</p>
<p>Counterfactuals are <strong>useful for the goal of justification</strong>, especially recourse, since they are truthful and simple. Compared to other interpretation methods, they are not just estimates of something, like Shapley values. But counterfactuals are just data newly created data instances for which we can report what the model predicts.</p>
</section>
<section id="limitations" class="level2">
<h2 class="anchored" data-anchor-id="limitations">Limitations</h2>
<p><strong>For each instance, you will usually find multiple counterfactual explanations (Rashomon effect).</strong> This is inconvenient – most people prefer simple explanations over the complexity of the real world. It’s also a practical challenge. Let’s say we generated 23 counterfactual explanations for one instance. Are we reporting them all? Only the best? What if they are all relatively “good,” but very different? These questions must be answered anew for each project. It can also be advantageous to have multiple counterfactual explanations because humans then can select the ones that correspond to their previous knowledge.</p>
<p>Counterfactuals are <strong>not as useful for model and data insights</strong>, since insights from counterfactual are specific to one instance and one counterfactual prediction. This is a very limited insight, even when compared to other local methods.</p>
</section>
<section id="example-software" class="level2">
<h2 class="anchored" data-anchor-id="example-software">Software and alternatives</h2>
<p>The multi-objective counterfactual explanation method by Dandl et al.&nbsp;is implemented in a <a href="https://github.com/susanne-207/moc/tree/master/counterfactuals">GitHub repository</a>.</p>
<p>In the Python package <a href="https://github.com/SeldonIO/alibi">Alibi</a>, authors implemented a <a href="https://docs.seldon.io/projects/alibi/en/stable/methods/CF.html">simple counterfactual method</a>, as well as an <a href="https://docs.seldon.io/projects/alibi/en/stable/methods/CFProto.html">extended method</a> that uses class prototypes to improve the interpretability and convergence of the algorithm outputs <span class="citation" data-cites="vanlooveren2021interpretable">(<a href="references.html#ref-vanlooveren2021interpretable" role="doc-biblioref">Van Looveren and Klaise 2021</a>)</span>.</p>
<p><span class="citation" data-cites="karimi2020modelagnostic">Karimi et al. (<a href="references.html#ref-karimi2020modelagnostic" role="doc-biblioref">2020</a>)</span> also provided a Python implementation of their algorithm MACE in a <a href="https://github.com/amirhk/mace">GitHub repository</a>. They translated necessary criteria for proper counterfactuals into logical formulae and used satisfiability solvers to find counterfactuals that satisfy them.</p>
<p><span class="citation" data-cites="mothilal2020explaining">Mothilal, Sharma, and Tan (<a href="references.html#ref-mothilal2020explaining" role="doc-biblioref">2020</a>)</span> developed <a href="https://github.com/interpretml/DiCE">DiCE (Diverse Counterfactual Explanation)</a> to generate a diverse set of counterfactual explanations based on determinantal point processes. DiCE implements both a model-agnostic and a gradient-based method.</p>
<p>Another way to search counterfactuals is the Growing Spheres algorithm by <span class="citation" data-cites="laugel2017inverse">Laugel et al. (<a href="references.html#ref-laugel2017inverse" role="doc-biblioref">2017</a>)</span>. They don’t use the word counterfactual in their paper, but the method is quite similar. They also define a loss function that favors counterfactuals with as few changes in the feature values as possible. Instead of directly optimizing the function, they suggest first drawing a sphere around the point of interest, sampling points within that sphere, and checking whether one of the sampled points yields the desired prediction. Then they contract or expand the sphere accordingly until a (sparse) counterfactual is found and finally returned.</p>
<p>Anchors by <span class="citation" data-cites="ribeiro2018anchors">Ribeiro, Singh, and Guestrin (<a href="references.html#ref-ribeiro2018anchors" role="doc-biblioref">2018</a>)</span> are the opposite of counterfactuals; see the chapter about <a href="anchors.html">Scoped Rules (Anchors)</a>.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-dandl2020multiobjective" class="csl-entry" role="listitem">
Dandl, Susanne, Christoph Molnar, Martin Binder, and Bernd Bischl. 2020. <span>“Multi-<span>Objective Counterfactual Explanations</span>.”</span> In <em>Parallel <span>Problem Solving</span> from <span>Nature</span> – <span>PPSN XVI</span></em>, edited by Thomas Bäck, Mike Preuss, André Deutz, Hao Wang, Carola Doerr, Michael Emmerich, and Heike Trautmann, 448–69. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-58112-1_31">https://doi.org/10.1007/978-3-030-58112-1_31</a>.
</div>
<div id="ref-deb2002fast" class="csl-entry" role="listitem">
Deb, K., A. Pratap, S. Agarwal, and T. Meyarivan. 2002. <span>“A Fast and Elitist Multiobjective Genetic Algorithm: <span>NSGA-II</span>.”</span> <em>IEEE Transactions on Evolutionary Computation</em> 6 (2): 182–97. <a href="https://doi.org/10.1109/4235.996017">https://doi.org/10.1109/4235.996017</a>.
</div>
<div id="ref-karimi2020modelagnostic" class="csl-entry" role="listitem">
Karimi, Amir-Hossein, Gilles Barthe, Borja Balle, and Isabel Valera. 2020. <span>“Model-<span>Agnostic Counterfactual Explanations</span> for <span>Consequential Decisions</span>.”</span> In <em>Proceedings of the <span>Twenty Third International Conference</span> on <span>Artificial Intelligence</span> and <span>Statistics</span></em>, 895–905. PMLR. <a href="https://proceedings.mlr.press/v108/karimi20a.html">https://proceedings.mlr.press/v108/karimi20a.html</a>.
</div>
<div id="ref-laugel2017inverse" class="csl-entry" role="listitem">
Laugel, Thibault, Marie-Jeanne Lesot, Christophe Marsala, Xavier Renard, and Marcin Detyniecki. 2017. <span>“Inverse <span>Classification</span> for <span class="nocase">Comparison-based Interpretability</span> in <span>Machine Learning</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.1712.08443">https://doi.org/10.48550/arXiv.1712.08443</a>.
</div>
<div id="ref-mothilal2020explaining" class="csl-entry" role="listitem">
Mothilal, Ramaravind K., Amit Sharma, and Chenhao Tan. 2020. <span>“Explaining Machine Learning Classifiers Through Diverse Counterfactual Explanations.”</span> In <em>Proceedings of the 2020 <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 607–17. <span>FAT</span>* ’20. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3351095.3372850">https://doi.org/10.1145/3351095.3372850</a>.
</div>
<div id="ref-ribeiro2018anchors" class="csl-entry" role="listitem">
Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2018. <span>“Anchors: <span>High-Precision Model-Agnostic Explanations</span>.”</span> <em>Proceedings of the AAAI Conference on Artificial Intelligence</em> 32 (1). <a href="https://doi.org/10.1609/aaai.v32i1.11491">https://doi.org/10.1609/aaai.v32i1.11491</a>.
</div>
<div id="ref-vanlooveren2021interpretable" class="csl-entry" role="listitem">
Van Looveren, Arnaud, and Janis Klaise. 2021. <span>“Interpretable <span>Counterfactual Explanations Guided</span> by <span>Prototypes</span>.”</span> In <em>Machine <span>Learning</span> and <span>Knowledge Discovery</span> in <span>Databases</span>. <span>Research Track</span></em>, edited by Nuria Oliver, Fernando Pérez-Cruz, Stefan Kramer, Jesse Read, and Jose A. Lozano, 650–65. Cham: Springer International Publishing. <a href="https://doi.org/10.1007/978-3-030-86520-7_40">https://doi.org/10.1007/978-3-030-86520-7_40</a>.
</div>
<div id="ref-wachter2018counterfactual" class="csl-entry" role="listitem">
Wachter, Sandra, Brent Mittelstadt, and Chris Russell. 2018. <span>“Counterfactual Explanations Without Opening the Black Box: Automated Decisions and the GDPR.”</span> <em>Harvard Journal of Law and Technology</em> 31 (2): 841–87.
</div>
</div>
</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>“Counterfactuals” is an overloaded term. In causal inference, they have a different meaning and are connected to hypothetical, causal interventions.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./lime.html" class="pagination-link" aria-label="LIME">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LIME</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./anchors.html" class="pagination-link" aria-label="Scoped Rules (Anchors)">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Scoped Rules (Anchors)</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p><a href="privacy-policy.html" target="_blank" style="font-size:11px;"> Privacy Policy </a> | <a href="https://christophmolnar.com/impressum" target="_blank" style="font-size:11px"> Impressum </a></p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/christophM/interpretable-ml-book/blob/main/counterfactual.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li><li><a href="https://github.com/christophM/interpretable-ml-book/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>
<script>var lightboxQuarto = GLightbox({"closeEffect":"zoom","descPosition":"bottom","loop":false,"openEffect":"zoom","selector":".lightbox"});
(function() {
  let previousOnload = window.onload;
  window.onload = () => {
    if (previousOnload) {
      previousOnload();
    }
    lightboxQuarto.on('slide_before_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      const href = trigger.getAttribute('href');
      if (href !== null) {
        const imgEl = window.document.querySelector(`a[href="${href}"] img`);
        if (imgEl !== null) {
          const srcAttr = imgEl.getAttribute("src");
          if (srcAttr && srcAttr.startsWith("data:")) {
            slideConfig.href = srcAttr;
          }
        }
      } 
    });
  
    lightboxQuarto.on('slide_after_load', (data) => {
      const { slideIndex, slideNode, slideConfig, player, trigger } = data;
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(slideNode);
      }
    });
  
  };
  
})();
          </script>




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>