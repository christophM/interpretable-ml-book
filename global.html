<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.6 Global Surrogate | Interpretable Machine Learning</title>
  <meta name="description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.6 Global Surrogate | Interpretable Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  <meta name="github-repo" content="christophM/interpretable-ml-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.6 Global Surrogate | Interpretable Machine Learning" />
  
  <meta name="twitter:description" content="Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable." />
  

<meta name="author" content="Christoph Molnar" />


<meta name="date" content="2021-09-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="feature-importance.html"/>
<link rel="next" href="proto.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-110543840-1', 'https://christophm.github.io/interpretable-ml-book/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>

<link rel="stylesheet" type="text/css" href="css/cookieconsent.min.css" />
<script src="javascript/cookieconsent.min.js"></script>
<script>
window.addEventListener("load", function(){
window.cookieconsent.initialise({
  "palette": {
    "popup": {
      "background": "#000"
    },
    "button": {
      "background": "#f1d600"
    }
  },
  "position": "bottom-right",
  "content": {
    "message": "This website uses cookies for Google Analytics so that I know how many people are reading the book and which chapters are the most popular. The book website doesn't collect any personal data."
  }
})});
</script>




<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpretable machine learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Summary</a></li>
<li class="chapter" data-level="" data-path="preface-by-the-author.html"><a href="preface-by-the-author.html"><i class="fa fa-check"></i>Preface by the Author</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="storytime.html"><a href="storytime.html"><i class="fa fa-check"></i><b>1.1</b> Story Time</a><ul>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#lightning-never-strikes-twice"><i class="fa fa-check"></i>Lightning Never Strikes Twice</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#trust-fall"><i class="fa fa-check"></i>Trust Fall</a></li>
<li class="chapter" data-level="" data-path="storytime.html"><a href="storytime.html#fermis-paperclips"><i class="fa fa-check"></i>Fermi’s Paperclips</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="what-is-machine-learning.html"><a href="what-is-machine-learning.html"><i class="fa fa-check"></i><b>1.2</b> What Is Machine Learning?</a></li>
<li class="chapter" data-level="1.3" data-path="terminology.html"><a href="terminology.html"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="interpretability.html"><a href="interpretability.html"><i class="fa fa-check"></i><b>2</b> Interpretability</a><ul>
<li class="chapter" data-level="2.1" data-path="interpretability-importance.html"><a href="interpretability-importance.html"><i class="fa fa-check"></i><b>2.1</b> Importance of Interpretability</a></li>
<li class="chapter" data-level="2.2" data-path="taxonomy-of-interpretability-methods.html"><a href="taxonomy-of-interpretability-methods.html"><i class="fa fa-check"></i><b>2.2</b> Taxonomy of Interpretability Methods</a></li>
<li class="chapter" data-level="2.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html"><i class="fa fa-check"></i><b>2.3</b> Scope of Interpretability</a><ul>
<li class="chapter" data-level="2.3.1" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#algorithm-transparency"><i class="fa fa-check"></i><b>2.3.1</b> Algorithm Transparency</a></li>
<li class="chapter" data-level="2.3.2" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-holistic-model-interpretability"><i class="fa fa-check"></i><b>2.3.2</b> Global, Holistic Model Interpretability</a></li>
<li class="chapter" data-level="2.3.3" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#global-model-interpretability-on-a-modular-level"><i class="fa fa-check"></i><b>2.3.3</b> Global Model Interpretability on a Modular Level</a></li>
<li class="chapter" data-level="2.3.4" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-single-prediction"><i class="fa fa-check"></i><b>2.3.4</b> Local Interpretability for a Single Prediction</a></li>
<li class="chapter" data-level="2.3.5" data-path="scope-of-interpretability.html"><a href="scope-of-interpretability.html#local-interpretability-for-a-group-of-predictions"><i class="fa fa-check"></i><b>2.3.5</b> Local Interpretability for a Group of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="evaluation-of-interpretability.html"><a href="evaluation-of-interpretability.html"><i class="fa fa-check"></i><b>2.4</b> Evaluation of Interpretability</a></li>
<li class="chapter" data-level="2.5" data-path="properties.html"><a href="properties.html"><i class="fa fa-check"></i><b>2.5</b> Properties of Explanations</a></li>
<li class="chapter" data-level="2.6" data-path="explanation.html"><a href="explanation.html"><i class="fa fa-check"></i><b>2.6</b> Human-friendly Explanations</a><ul>
<li class="chapter" data-level="2.6.1" data-path="explanation.html"><a href="explanation.html#what-is-an-explanation"><i class="fa fa-check"></i><b>2.6.1</b> What Is an Explanation?</a></li>
<li class="chapter" data-level="2.6.2" data-path="explanation.html"><a href="explanation.html#good-explanation"><i class="fa fa-check"></i><b>2.6.2</b> What Is a Good Explanation?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>3</b> Datasets</a><ul>
<li class="chapter" data-level="3.1" data-path="bike-data.html"><a href="bike-data.html"><i class="fa fa-check"></i><b>3.1</b> Bike Rentals (Regression)</a></li>
<li class="chapter" data-level="3.2" data-path="spam-data.html"><a href="spam-data.html"><i class="fa fa-check"></i><b>3.2</b> YouTube Spam Comments (Text Classification)</a></li>
<li class="chapter" data-level="3.3" data-path="cervical.html"><a href="cervical.html"><i class="fa fa-check"></i><b>3.3</b> Risk Factors for Cervical Cancer (Classification)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple.html"><a href="simple.html"><i class="fa fa-check"></i><b>4</b> Interpretable Models</a><ul>
<li class="chapter" data-level="4.1" data-path="limo.html"><a href="limo.html"><i class="fa fa-check"></i><b>4.1</b> Linear Regression</a><ul>
<li class="chapter" data-level="4.1.1" data-path="limo.html"><a href="limo.html#interpretation"><i class="fa fa-check"></i><b>4.1.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.1.2" data-path="limo.html"><a href="limo.html#example"><i class="fa fa-check"></i><b>4.1.2</b> Example</a></li>
<li class="chapter" data-level="4.1.3" data-path="limo.html"><a href="limo.html#visual-interpretation"><i class="fa fa-check"></i><b>4.1.3</b> Visual Interpretation</a></li>
<li class="chapter" data-level="4.1.4" data-path="limo.html"><a href="limo.html#explain-individual-predictions"><i class="fa fa-check"></i><b>4.1.4</b> Explain Individual Predictions</a></li>
<li class="chapter" data-level="4.1.5" data-path="limo.html"><a href="limo.html#cat-code"><i class="fa fa-check"></i><b>4.1.5</b> Encoding of Categorical Features</a></li>
<li class="chapter" data-level="4.1.6" data-path="limo.html"><a href="limo.html#do-linear-models-create-good-explanations"><i class="fa fa-check"></i><b>4.1.6</b> Do Linear Models Create Good Explanations?</a></li>
<li class="chapter" data-level="4.1.7" data-path="limo.html"><a href="limo.html#sparse-linear"><i class="fa fa-check"></i><b>4.1.7</b> Sparse Linear Models</a></li>
<li class="chapter" data-level="4.1.8" data-path="limo.html"><a href="limo.html#advantages"><i class="fa fa-check"></i><b>4.1.8</b> Advantages</a></li>
<li class="chapter" data-level="4.1.9" data-path="limo.html"><a href="limo.html#disadvantages"><i class="fa fa-check"></i><b>4.1.9</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>4.2</b> Logistic Regression</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic.html"><a href="logistic.html#what-is-wrong-with-linear-regression-for-classification"><i class="fa fa-check"></i><b>4.2.1</b> What is Wrong with Linear Regression for Classification?</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic.html"><a href="logistic.html#theory"><i class="fa fa-check"></i><b>4.2.2</b> Theory</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic.html"><a href="logistic.html#interpretation-1"><i class="fa fa-check"></i><b>4.2.3</b> Interpretation</a></li>
<li class="chapter" data-level="4.2.4" data-path="logistic.html"><a href="logistic.html#example-1"><i class="fa fa-check"></i><b>4.2.4</b> Example</a></li>
<li class="chapter" data-level="4.2.5" data-path="logistic.html"><a href="logistic.html#advantages-and-disadvantages"><i class="fa fa-check"></i><b>4.2.5</b> Advantages and Disadvantages</a></li>
<li class="chapter" data-level="4.2.6" data-path="logistic.html"><a href="logistic.html#software"><i class="fa fa-check"></i><b>4.2.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="extend-lm.html"><a href="extend-lm.html"><i class="fa fa-check"></i><b>4.3</b> GLM, GAM and more</a><ul>
<li class="chapter" data-level="4.3.1" data-path="extend-lm.html"><a href="extend-lm.html#glm"><i class="fa fa-check"></i><b>4.3.1</b> Non-Gaussian Outcomes - GLMs</a></li>
<li class="chapter" data-level="4.3.2" data-path="extend-lm.html"><a href="extend-lm.html#lm-interact"><i class="fa fa-check"></i><b>4.3.2</b> Interactions</a></li>
<li class="chapter" data-level="4.3.3" data-path="extend-lm.html"><a href="extend-lm.html#gam"><i class="fa fa-check"></i><b>4.3.3</b> Nonlinear Effects - GAMs</a></li>
<li class="chapter" data-level="4.3.4" data-path="extend-lm.html"><a href="extend-lm.html#advantages-1"><i class="fa fa-check"></i><b>4.3.4</b> Advantages</a></li>
<li class="chapter" data-level="4.3.5" data-path="extend-lm.html"><a href="extend-lm.html#disadvantages-1"><i class="fa fa-check"></i><b>4.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.3.6" data-path="extend-lm.html"><a href="extend-lm.html#software-1"><i class="fa fa-check"></i><b>4.3.6</b> Software</a></li>
<li class="chapter" data-level="4.3.7" data-path="extend-lm.html"><a href="extend-lm.html#more-lm-extension"><i class="fa fa-check"></i><b>4.3.7</b> Further Extensions</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tree.html"><a href="tree.html"><i class="fa fa-check"></i><b>4.4</b> Decision Tree</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tree.html"><a href="tree.html#interpretation-2"><i class="fa fa-check"></i><b>4.4.1</b> Interpretation</a></li>
<li class="chapter" data-level="4.4.2" data-path="tree.html"><a href="tree.html#example-2"><i class="fa fa-check"></i><b>4.4.2</b> Example</a></li>
<li class="chapter" data-level="4.4.3" data-path="tree.html"><a href="tree.html#advantages-2"><i class="fa fa-check"></i><b>4.4.3</b> Advantages</a></li>
<li class="chapter" data-level="4.4.4" data-path="tree.html"><a href="tree.html#disadvantages-2"><i class="fa fa-check"></i><b>4.4.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.4.5" data-path="tree.html"><a href="tree.html#software-2"><i class="fa fa-check"></i><b>4.4.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="rules.html"><a href="rules.html"><i class="fa fa-check"></i><b>4.5</b> Decision Rules</a><ul>
<li class="chapter" data-level="4.5.1" data-path="rules.html"><a href="rules.html#learn-rules-from-a-single-feature-oner"><i class="fa fa-check"></i><b>4.5.1</b> Learn Rules from a Single Feature (OneR)</a></li>
<li class="chapter" data-level="4.5.2" data-path="rules.html"><a href="rules.html#sequential-covering"><i class="fa fa-check"></i><b>4.5.2</b> Sequential Covering</a></li>
<li class="chapter" data-level="4.5.3" data-path="rules.html"><a href="rules.html#bayesian-rule-lists"><i class="fa fa-check"></i><b>4.5.3</b> Bayesian Rule Lists</a></li>
<li class="chapter" data-level="4.5.4" data-path="rules.html"><a href="rules.html#advantages-3"><i class="fa fa-check"></i><b>4.5.4</b> Advantages</a></li>
<li class="chapter" data-level="4.5.5" data-path="rules.html"><a href="rules.html#disadvantages-3"><i class="fa fa-check"></i><b>4.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="4.5.6" data-path="rules.html"><a href="rules.html#software-and-alternatives"><i class="fa fa-check"></i><b>4.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="rulefit.html"><a href="rulefit.html"><i class="fa fa-check"></i><b>4.6</b> RuleFit</a><ul>
<li class="chapter" data-level="4.6.1" data-path="rulefit.html"><a href="rulefit.html#interpretation-and-example"><i class="fa fa-check"></i><b>4.6.1</b> Interpretation and Example</a></li>
<li class="chapter" data-level="4.6.2" data-path="rulefit.html"><a href="rulefit.html#theory-1"><i class="fa fa-check"></i><b>4.6.2</b> Theory</a></li>
<li class="chapter" data-level="4.6.3" data-path="rulefit.html"><a href="rulefit.html#advantages-4"><i class="fa fa-check"></i><b>4.6.3</b> Advantages</a></li>
<li class="chapter" data-level="4.6.4" data-path="rulefit.html"><a href="rulefit.html#disadvantages-4"><i class="fa fa-check"></i><b>4.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="4.6.5" data-path="rulefit.html"><a href="rulefit.html#software-and-alternative"><i class="fa fa-check"></i><b>4.6.5</b> Software and Alternative</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="other-interpretable.html"><a href="other-interpretable.html"><i class="fa fa-check"></i><b>4.7</b> Other Interpretable Models</a><ul>
<li class="chapter" data-level="4.7.1" data-path="other-interpretable.html"><a href="other-interpretable.html#naive-bayes-classifier"><i class="fa fa-check"></i><b>4.7.1</b> Naive Bayes Classifier</a></li>
<li class="chapter" data-level="4.7.2" data-path="other-interpretable.html"><a href="other-interpretable.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>4.7.2</b> K-Nearest Neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="agnostic.html"><a href="agnostic.html"><i class="fa fa-check"></i><b>5</b> Model-Agnostic Methods</a></li>
<li class="chapter" data-level="6" data-path="example-based.html"><a href="example-based.html"><i class="fa fa-check"></i><b>6</b> Example-Based Explanations</a></li>
<li class="chapter" data-level="7" data-path="global-methods.html"><a href="global-methods.html"><i class="fa fa-check"></i><b>7</b> Global Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="7.1" data-path="pdp.html"><a href="pdp.html"><i class="fa fa-check"></i><b>7.1</b> Partial Dependence Plot (PDP)</a><ul>
<li class="chapter" data-level="7.1.1" data-path="pdp.html"><a href="pdp.html#pdp-based-feature-importance"><i class="fa fa-check"></i><b>7.1.1</b> PDP-based Feature Importance</a></li>
<li class="chapter" data-level="7.1.2" data-path="pdp.html"><a href="pdp.html#examples"><i class="fa fa-check"></i><b>7.1.2</b> Examples</a></li>
<li class="chapter" data-level="7.1.3" data-path="pdp.html"><a href="pdp.html#advantages-5"><i class="fa fa-check"></i><b>7.1.3</b> Advantages</a></li>
<li class="chapter" data-level="7.1.4" data-path="pdp.html"><a href="pdp.html#disadvantages-5"><i class="fa fa-check"></i><b>7.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.1.5" data-path="pdp.html"><a href="pdp.html#software-and-alternatives-1"><i class="fa fa-check"></i><b>7.1.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="ale.html"><a href="ale.html"><i class="fa fa-check"></i><b>7.2</b> Accumulated Local Effects (ALE) Plot</a><ul>
<li class="chapter" data-level="7.2.1" data-path="ale.html"><a href="ale.html#motivation-and-intuition"><i class="fa fa-check"></i><b>7.2.1</b> Motivation and Intuition</a></li>
<li class="chapter" data-level="7.2.2" data-path="ale.html"><a href="ale.html#theory-2"><i class="fa fa-check"></i><b>7.2.2</b> Theory</a></li>
<li class="chapter" data-level="7.2.3" data-path="ale.html"><a href="ale.html#estimation"><i class="fa fa-check"></i><b>7.2.3</b> Estimation</a></li>
<li class="chapter" data-level="7.2.4" data-path="ale.html"><a href="ale.html#examples-1"><i class="fa fa-check"></i><b>7.2.4</b> Examples</a></li>
<li class="chapter" data-level="7.2.5" data-path="ale.html"><a href="ale.html#advantages-6"><i class="fa fa-check"></i><b>7.2.5</b> Advantages</a></li>
<li class="chapter" data-level="7.2.6" data-path="ale.html"><a href="ale.html#disadvantages-6"><i class="fa fa-check"></i><b>7.2.6</b> Disadvantages</a></li>
<li class="chapter" data-level="7.2.7" data-path="ale.html"><a href="ale.html#implementation-and-alternatives"><i class="fa fa-check"></i><b>7.2.7</b> Implementation and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="interaction.html"><a href="interaction.html"><i class="fa fa-check"></i><b>7.3</b> Feature Interaction</a><ul>
<li class="chapter" data-level="7.3.1" data-path="interaction.html"><a href="interaction.html#feature-interaction"><i class="fa fa-check"></i><b>7.3.1</b> Feature Interaction?</a></li>
<li class="chapter" data-level="7.3.2" data-path="interaction.html"><a href="interaction.html#theory-friedmans-h-statistic"><i class="fa fa-check"></i><b>7.3.2</b> Theory: Friedman’s H-statistic</a></li>
<li class="chapter" data-level="7.3.3" data-path="interaction.html"><a href="interaction.html#examples-2"><i class="fa fa-check"></i><b>7.3.3</b> Examples</a></li>
<li class="chapter" data-level="7.3.4" data-path="interaction.html"><a href="interaction.html#advantages-7"><i class="fa fa-check"></i><b>7.3.4</b> Advantages</a></li>
<li class="chapter" data-level="7.3.5" data-path="interaction.html"><a href="interaction.html#disadvantages-7"><i class="fa fa-check"></i><b>7.3.5</b> Disadvantages</a></li>
<li class="chapter" data-level="7.3.6" data-path="interaction.html"><a href="interaction.html#implementations"><i class="fa fa-check"></i><b>7.3.6</b> Implementations</a></li>
<li class="chapter" data-level="7.3.7" data-path="interaction.html"><a href="interaction.html#alternatives"><i class="fa fa-check"></i><b>7.3.7</b> Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="decomposition.html"><a href="decomposition.html"><i class="fa fa-check"></i><b>7.4</b> Functional Decompositon</a><ul>
<li class="chapter" data-level="7.4.1" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-i"><i class="fa fa-check"></i><b>7.4.1</b> How not to Compute the Components I</a></li>
<li class="chapter" data-level="7.4.2" data-path="decomposition.html"><a href="decomposition.html#functional-decomposition"><i class="fa fa-check"></i><b>7.4.2</b> Functional Decomposition</a></li>
<li class="chapter" data-level="7.4.3" data-path="decomposition.html"><a href="decomposition.html#how-not-to-compute-the-components-ii"><i class="fa fa-check"></i><b>7.4.3</b> How not to Compute the Components II</a></li>
<li class="chapter" data-level="7.4.4" data-path="decomposition.html"><a href="decomposition.html#functional-anova"><i class="fa fa-check"></i><b>7.4.4</b> Functional ANOVA</a></li>
<li class="chapter" data-level="7.4.5" data-path="decomposition.html"><a href="decomposition.html#generalized-functional-anova-for-dependent-features"><i class="fa fa-check"></i><b>7.4.5</b> Generalized Functional ANOVA for Dependent Features</a></li>
<li class="chapter" data-level="7.4.6" data-path="decomposition.html"><a href="decomposition.html#accumulated-local-effect-plots"><i class="fa fa-check"></i><b>7.4.6</b> Accumulated Local Effect Plots</a></li>
<li class="chapter" data-level="7.4.7" data-path="decomposition.html"><a href="decomposition.html#statistical-regression-models"><i class="fa fa-check"></i><b>7.4.7</b> Statistical Regression Models</a></li>
<li class="chapter" data-level="7.4.8" data-path="decomposition.html"><a href="decomposition.html#bonus-partial-dependence-plot"><i class="fa fa-check"></i><b>7.4.8</b> Bonus: Partial Dependence Plot</a></li>
<li class="chapter" data-level="7.4.9" data-path="decomposition.html"><a href="decomposition.html#advantages-8"><i class="fa fa-check"></i><b>7.4.9</b> Advantages</a></li>
<li class="chapter" data-level="7.4.10" data-path="decomposition.html"><a href="decomposition.html#disadvantages-8"><i class="fa fa-check"></i><b>7.4.10</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="feature-importance.html"><a href="feature-importance.html"><i class="fa fa-check"></i><b>7.5</b> Permutation Feature Importance</a><ul>
<li class="chapter" data-level="7.5.1" data-path="feature-importance.html"><a href="feature-importance.html#theory-3"><i class="fa fa-check"></i><b>7.5.1</b> Theory</a></li>
<li class="chapter" data-level="7.5.2" data-path="feature-importance.html"><a href="feature-importance.html#feature-importance-data"><i class="fa fa-check"></i><b>7.5.2</b> Should I Compute Importance on Training or Test Data?</a></li>
<li class="chapter" data-level="7.5.3" data-path="feature-importance.html"><a href="feature-importance.html#example-and-interpretation"><i class="fa fa-check"></i><b>7.5.3</b> Example and Interpretation</a></li>
<li class="chapter" data-level="7.5.4" data-path="feature-importance.html"><a href="feature-importance.html#advantages-9"><i class="fa fa-check"></i><b>7.5.4</b> Advantages</a></li>
<li class="chapter" data-level="7.5.5" data-path="feature-importance.html"><a href="feature-importance.html#disadvantages-9"><i class="fa fa-check"></i><b>7.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="7.5.6" data-path="feature-importance.html"><a href="feature-importance.html#software-and-alternatives-2"><i class="fa fa-check"></i><b>7.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="global.html"><a href="global.html"><i class="fa fa-check"></i><b>7.6</b> Global Surrogate</a><ul>
<li class="chapter" data-level="7.6.1" data-path="global.html"><a href="global.html#theory-4"><i class="fa fa-check"></i><b>7.6.1</b> Theory</a></li>
<li class="chapter" data-level="7.6.2" data-path="global.html"><a href="global.html#example-3"><i class="fa fa-check"></i><b>7.6.2</b> Example</a></li>
<li class="chapter" data-level="7.6.3" data-path="global.html"><a href="global.html#advantages-10"><i class="fa fa-check"></i><b>7.6.3</b> Advantages</a></li>
<li class="chapter" data-level="7.6.4" data-path="global.html"><a href="global.html#disadvantages-10"><i class="fa fa-check"></i><b>7.6.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.6.5" data-path="global.html"><a href="global.html#software-3"><i class="fa fa-check"></i><b>7.6.5</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="proto.html"><a href="proto.html"><i class="fa fa-check"></i><b>7.7</b> Prototypes and Criticisms</a><ul>
<li class="chapter" data-level="7.7.1" data-path="proto.html"><a href="proto.html#theory-5"><i class="fa fa-check"></i><b>7.7.1</b> Theory</a></li>
<li class="chapter" data-level="7.7.2" data-path="proto.html"><a href="proto.html#examples-3"><i class="fa fa-check"></i><b>7.7.2</b> Examples</a></li>
<li class="chapter" data-level="7.7.3" data-path="proto.html"><a href="proto.html#advantages-11"><i class="fa fa-check"></i><b>7.7.3</b> Advantages</a></li>
<li class="chapter" data-level="7.7.4" data-path="proto.html"><a href="proto.html#disadvantages-11"><i class="fa fa-check"></i><b>7.7.4</b> Disadvantages</a></li>
<li class="chapter" data-level="7.7.5" data-path="proto.html"><a href="proto.html#code-and-alternatives"><i class="fa fa-check"></i><b>7.7.5</b> Code and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="local-methods.html"><a href="local-methods.html"><i class="fa fa-check"></i><b>8</b> Local Model-Agnostic Methods</a><ul>
<li class="chapter" data-level="8.1" data-path="ice.html"><a href="ice.html"><i class="fa fa-check"></i><b>8.1</b> Individual Conditional Expectation (ICE)</a><ul>
<li class="chapter" data-level="8.1.1" data-path="ice.html"><a href="ice.html#examples-4"><i class="fa fa-check"></i><b>8.1.1</b> Examples</a></li>
<li class="chapter" data-level="8.1.2" data-path="ice.html"><a href="ice.html#advantages-12"><i class="fa fa-check"></i><b>8.1.2</b> Advantages</a></li>
<li class="chapter" data-level="8.1.3" data-path="ice.html"><a href="ice.html#disadvantages-12"><i class="fa fa-check"></i><b>8.1.3</b> Disadvantages</a></li>
<li class="chapter" data-level="8.1.4" data-path="ice.html"><a href="ice.html#software-and-alternatives-3"><i class="fa fa-check"></i><b>8.1.4</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="lime.html"><a href="lime.html"><i class="fa fa-check"></i><b>8.2</b> Local Surrogate (LIME)</a><ul>
<li class="chapter" data-level="8.2.1" data-path="lime.html"><a href="lime.html#lime-for-tabular-data"><i class="fa fa-check"></i><b>8.2.1</b> LIME for Tabular Data</a></li>
<li class="chapter" data-level="8.2.2" data-path="lime.html"><a href="lime.html#lime-for-text"><i class="fa fa-check"></i><b>8.2.2</b> LIME for Text</a></li>
<li class="chapter" data-level="8.2.3" data-path="lime.html"><a href="lime.html#images-lime"><i class="fa fa-check"></i><b>8.2.3</b> LIME for Images</a></li>
<li class="chapter" data-level="8.2.4" data-path="lime.html"><a href="lime.html#advantages-13"><i class="fa fa-check"></i><b>8.2.4</b> Advantages</a></li>
<li class="chapter" data-level="8.2.5" data-path="lime.html"><a href="lime.html#disadvantages-13"><i class="fa fa-check"></i><b>8.2.5</b> Disadvantages</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="counterfactual.html"><a href="counterfactual.html"><i class="fa fa-check"></i><b>8.3</b> Counterfactual Explanations</a><ul>
<li class="chapter" data-level="8.3.1" data-path="counterfactual.html"><a href="counterfactual.html#generating-counterfactual-explanations"><i class="fa fa-check"></i><b>8.3.1</b> Generating Counterfactual Explanations</a></li>
<li class="chapter" data-level="8.3.2" data-path="counterfactual.html"><a href="counterfactual.html#example-8"><i class="fa fa-check"></i><b>8.3.2</b> Example</a></li>
<li class="chapter" data-level="8.3.3" data-path="counterfactual.html"><a href="counterfactual.html#advantages-14"><i class="fa fa-check"></i><b>8.3.3</b> Advantages</a></li>
<li class="chapter" data-level="8.3.4" data-path="counterfactual.html"><a href="counterfactual.html#disadvantages-14"><i class="fa fa-check"></i><b>8.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="8.3.5" data-path="counterfactual.html"><a href="counterfactual.html#example-software"><i class="fa fa-check"></i><b>8.3.5</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="anchors.html"><a href="anchors.html"><i class="fa fa-check"></i><b>8.4</b> Scoped Rules (Anchors)</a><ul>
<li class="chapter" data-level="8.4.1" data-path="anchors.html"><a href="anchors.html#finding-anchors"><i class="fa fa-check"></i><b>8.4.1</b> Finding Anchors</a></li>
<li class="chapter" data-level="8.4.2" data-path="anchors.html"><a href="anchors.html#complexity-and-runtime"><i class="fa fa-check"></i><b>8.4.2</b> Complexity and Runtime</a></li>
<li class="chapter" data-level="8.4.3" data-path="anchors.html"><a href="anchors.html#tabular-data-example"><i class="fa fa-check"></i><b>8.4.3</b> Tabular Data Example</a></li>
<li class="chapter" data-level="8.4.4" data-path="anchors.html"><a href="anchors.html#advantages-15"><i class="fa fa-check"></i><b>8.4.4</b> Advantages</a></li>
<li class="chapter" data-level="8.4.5" data-path="anchors.html"><a href="anchors.html#disadvantages-15"><i class="fa fa-check"></i><b>8.4.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.4.6" data-path="anchors.html"><a href="anchors.html#software-and-alternatives-4"><i class="fa fa-check"></i><b>8.4.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>8.5</b> Shapley Values</a><ul>
<li class="chapter" data-level="8.5.1" data-path="shapley.html"><a href="shapley.html#general-idea"><i class="fa fa-check"></i><b>8.5.1</b> General Idea</a></li>
<li class="chapter" data-level="8.5.2" data-path="shapley.html"><a href="shapley.html#examples-and-interpretation"><i class="fa fa-check"></i><b>8.5.2</b> Examples and Interpretation</a></li>
<li class="chapter" data-level="8.5.3" data-path="shapley.html"><a href="shapley.html#the-shapley-value-in-detail"><i class="fa fa-check"></i><b>8.5.3</b> The Shapley Value in Detail</a></li>
<li class="chapter" data-level="8.5.4" data-path="shapley.html"><a href="shapley.html#advantages-16"><i class="fa fa-check"></i><b>8.5.4</b> Advantages</a></li>
<li class="chapter" data-level="8.5.5" data-path="shapley.html"><a href="shapley.html#disadvantages-16"><i class="fa fa-check"></i><b>8.5.5</b> Disadvantages</a></li>
<li class="chapter" data-level="8.5.6" data-path="shapley.html"><a href="shapley.html#software-and-alternatives-5"><i class="fa fa-check"></i><b>8.5.6</b> Software and Alternatives</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="shap.html"><a href="shap.html"><i class="fa fa-check"></i><b>8.6</b> SHAP (SHapley Additive exPlanations)</a><ul>
<li class="chapter" data-level="8.6.1" data-path="shap.html"><a href="shap.html#definition"><i class="fa fa-check"></i><b>8.6.1</b> Definition</a></li>
<li class="chapter" data-level="8.6.2" data-path="shap.html"><a href="shap.html#kernelshap"><i class="fa fa-check"></i><b>8.6.2</b> KernelSHAP</a></li>
<li class="chapter" data-level="8.6.3" data-path="shap.html"><a href="shap.html#treeshap"><i class="fa fa-check"></i><b>8.6.3</b> TreeSHAP</a></li>
<li class="chapter" data-level="8.6.4" data-path="shap.html"><a href="shap.html#examples-5"><i class="fa fa-check"></i><b>8.6.4</b> Examples</a></li>
<li class="chapter" data-level="8.6.5" data-path="shap.html"><a href="shap.html#shap-feature-importance"><i class="fa fa-check"></i><b>8.6.5</b> SHAP Feature Importance</a></li>
<li class="chapter" data-level="8.6.6" data-path="shap.html"><a href="shap.html#shap-summary-plot"><i class="fa fa-check"></i><b>8.6.6</b> SHAP Summary Plot</a></li>
<li class="chapter" data-level="8.6.7" data-path="shap.html"><a href="shap.html#shap-dependence-plot"><i class="fa fa-check"></i><b>8.6.7</b> SHAP Dependence Plot</a></li>
<li class="chapter" data-level="8.6.8" data-path="shap.html"><a href="shap.html#shap-interaction-values"><i class="fa fa-check"></i><b>8.6.8</b> SHAP Interaction Values</a></li>
<li class="chapter" data-level="8.6.9" data-path="shap.html"><a href="shap.html#clustering-shap-values"><i class="fa fa-check"></i><b>8.6.9</b> Clustering SHAP values</a></li>
<li class="chapter" data-level="8.6.10" data-path="shap.html"><a href="shap.html#advantages-17"><i class="fa fa-check"></i><b>8.6.10</b> Advantages</a></li>
<li class="chapter" data-level="8.6.11" data-path="shap.html"><a href="shap.html#disadvantages-17"><i class="fa fa-check"></i><b>8.6.11</b> Disadvantages</a></li>
<li class="chapter" data-level="8.6.12" data-path="shap.html"><a href="shap.html#software-4"><i class="fa fa-check"></i><b>8.6.12</b> Software</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>9</b> Neural Network Interpretation</a><ul>
<li class="chapter" data-level="9.1" data-path="cnn-features.html"><a href="cnn-features.html"><i class="fa fa-check"></i><b>9.1</b> Learned Features</a><ul>
<li class="chapter" data-level="9.1.1" data-path="cnn-features.html"><a href="cnn-features.html#feature-visualization"><i class="fa fa-check"></i><b>9.1.1</b> Feature Visualization</a></li>
<li class="chapter" data-level="9.1.2" data-path="cnn-features.html"><a href="cnn-features.html#network-dissection"><i class="fa fa-check"></i><b>9.1.2</b> Network Dissection</a></li>
<li class="chapter" data-level="9.1.3" data-path="cnn-features.html"><a href="cnn-features.html#advantages-18"><i class="fa fa-check"></i><b>9.1.3</b> Advantages</a></li>
<li class="chapter" data-level="9.1.4" data-path="cnn-features.html"><a href="cnn-features.html#disadvantages-18"><i class="fa fa-check"></i><b>9.1.4</b> Disadvantages</a></li>
<li class="chapter" data-level="9.1.5" data-path="cnn-features.html"><a href="cnn-features.html#software-and-further-material"><i class="fa fa-check"></i><b>9.1.5</b> Software and Further Material</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html"><i class="fa fa-check"></i><b>9.2</b> Pixel Attribution (Saliency Maps)</a><ul>
<li class="chapter" data-level="9.2.1" data-path="pixel-attribution.html"><a href="pixel-attribution.html#vanilla-gradient-saliency-maps"><i class="fa fa-check"></i><b>9.2.1</b> Vanilla Gradient (Saliency Maps)</a></li>
<li class="chapter" data-level="9.2.2" data-path="pixel-attribution.html"><a href="pixel-attribution.html#deconvnet"><i class="fa fa-check"></i><b>9.2.2</b> DeconvNet</a></li>
<li class="chapter" data-level="9.2.3" data-path="pixel-attribution.html"><a href="pixel-attribution.html#grad-cam"><i class="fa fa-check"></i><b>9.2.3</b> Grad-CAM</a></li>
<li class="chapter" data-level="9.2.4" data-path="pixel-attribution.html"><a href="pixel-attribution.html#guided-grad-cam"><i class="fa fa-check"></i><b>9.2.4</b> Guided Grad-CAM</a></li>
<li class="chapter" data-level="9.2.5" data-path="pixel-attribution.html"><a href="pixel-attribution.html#smoothgrad"><i class="fa fa-check"></i><b>9.2.5</b> SmoothGrad</a></li>
<li class="chapter" data-level="9.2.6" data-path="pixel-attribution.html"><a href="pixel-attribution.html#examples-6"><i class="fa fa-check"></i><b>9.2.6</b> Examples</a></li>
<li class="chapter" data-level="9.2.7" data-path="pixel-attribution.html"><a href="pixel-attribution.html#advantages-19"><i class="fa fa-check"></i><b>9.2.7</b> Advantages</a></li>
<li class="chapter" data-level="9.2.8" data-path="pixel-attribution.html"><a href="pixel-attribution.html#disadvantages-19"><i class="fa fa-check"></i><b>9.2.8</b> Disadvantages</a></li>
<li class="chapter" data-level="9.2.9" data-path="pixel-attribution.html"><a href="pixel-attribution.html#software-5"><i class="fa fa-check"></i><b>9.2.9</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html"><i class="fa fa-check"></i><b>9.3</b> Detecting Concepts</a><ul>
<li class="chapter" data-level="9.3.1" data-path="detecting-concepts.html"><a href="detecting-concepts.html#tcav-testing-with-concept-activation-vectors"><i class="fa fa-check"></i><b>9.3.1</b> TCAV: Testing with Concept Activation Vectors</a></li>
<li class="chapter" data-level="9.3.2" data-path="detecting-concepts.html"><a href="detecting-concepts.html#example-9"><i class="fa fa-check"></i><b>9.3.2</b> Example</a></li>
<li class="chapter" data-level="9.3.3" data-path="detecting-concepts.html"><a href="detecting-concepts.html#advantages-20"><i class="fa fa-check"></i><b>9.3.3</b> Advantages</a></li>
<li class="chapter" data-level="9.3.4" data-path="detecting-concepts.html"><a href="detecting-concepts.html#disadvantages-20"><i class="fa fa-check"></i><b>9.3.4</b> Disadvantages</a></li>
<li class="chapter" data-level="9.3.5" data-path="detecting-concepts.html"><a href="detecting-concepts.html#bonus-other-concept-based-approaches"><i class="fa fa-check"></i><b>9.3.5</b> Bonus: Other Concept-based Approaches</a></li>
<li class="chapter" data-level="9.3.6" data-path="detecting-concepts.html"><a href="detecting-concepts.html#software-6"><i class="fa fa-check"></i><b>9.3.6</b> Software</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="adversarial.html"><a href="adversarial.html"><i class="fa fa-check"></i><b>9.4</b> Adversarial Examples</a><ul>
<li class="chapter" data-level="9.4.1" data-path="adversarial.html"><a href="adversarial.html#methods-and-examples"><i class="fa fa-check"></i><b>9.4.1</b> Methods and Examples</a></li>
<li class="chapter" data-level="9.4.2" data-path="adversarial.html"><a href="adversarial.html#the-cybersecurity-perspective"><i class="fa fa-check"></i><b>9.4.2</b> The Cybersecurity Perspective</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="influential.html"><a href="influential.html"><i class="fa fa-check"></i><b>9.5</b> Influential Instances</a><ul>
<li class="chapter" data-level="9.5.1" data-path="influential.html"><a href="influential.html#deletion-diagnostics"><i class="fa fa-check"></i><b>9.5.1</b> Deletion Diagnostics</a></li>
<li class="chapter" data-level="9.5.2" data-path="influential.html"><a href="influential.html#influence-functions"><i class="fa fa-check"></i><b>9.5.2</b> Influence Functions</a></li>
<li class="chapter" data-level="9.5.3" data-path="influential.html"><a href="influential.html#advantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>9.5.3</b> Advantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="9.5.4" data-path="influential.html"><a href="influential.html#disadvantages-of-identifying-influential-instances"><i class="fa fa-check"></i><b>9.5.4</b> Disadvantages of Identifying Influential Instances</a></li>
<li class="chapter" data-level="9.5.5" data-path="influential.html"><a href="influential.html#software-and-alternatives-6"><i class="fa fa-check"></i><b>9.5.5</b> Software and Alternatives</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="future.html"><a href="future.html"><i class="fa fa-check"></i><b>10</b> A Look into the Crystal Ball</a><ul>
<li class="chapter" data-level="10.1" data-path="the-future-of-machine-learning.html"><a href="the-future-of-machine-learning.html"><i class="fa fa-check"></i><b>10.1</b> The Future of Machine Learning</a></li>
<li class="chapter" data-level="10.2" data-path="the-future-of-interpretability.html"><a href="the-future-of-interpretability.html"><i class="fa fa-check"></i><b>10.2</b> The Future of Interpretability</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="contribute.html"><a href="contribute.html"><i class="fa fa-check"></i><b>11</b> Contribute to the Book</a></li>
<li class="chapter" data-level="12" data-path="cite.html"><a href="cite.html"><i class="fa fa-check"></i><b>12</b> Citing this Book</a></li>
<li class="chapter" data-level="13" data-path="translations.html"><a href="translations.html"><i class="fa fa-check"></i><b>13</b> Translations</a></li>
<li class="chapter" data-level="14" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>14</b> Acknowledgements</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a><ul>
<li class="chapter" data-level="" data-path="r-packages-used.html"><a href="r-packages-used.html"><i class="fa fa-check"></i>R Packages Used</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpretable Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="global" class="section level2">
<h2><span class="header-section-number">7.6</span> Global Surrogate</h2>
<p>A global surrogate model is an interpretable model that is trained to approximate the predictions of a black box model.
We can draw conclusions about the black box model by interpreting the surrogate model.
Solving machine learning interpretability by using more machine learning!</p>
<div id="theory-4" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Theory</h3>
<p>Surrogate models are also used in engineering:
If an outcome of interest is expensive, time-consuming or otherwise difficult to measure (e.g. because it comes from a complex computer simulation), a cheap and fast surrogate model of the outcome can be used instead.
The difference between the surrogate models used in engineering and in interpretable machine learning is that the underlying model is a machine learning model (not a simulation) and that the surrogate model must be interpretable.
The purpose of (interpretable) surrogate models is to approximate the predictions of the underlying model as accurately as possible and to be interpretable at the same time.
The idea of surrogate models can be found under different names:
Approximation model, metamodel, response surface model, emulator, …</p>
<p>About the theory:
There is actually not much theory needed to understand surrogate models.
We want to approximate our black box prediction function f as closely as possible with the surrogate model prediction function g, under the constraint that g is interpretable.
For the function g any interpretable model – for example from the <a href="simple.html#simple">interpretable models chapter</a> – can be used.</p>
<p>For example a linear model:</p>
<p><span class="math display">\[g(x)=\beta_0+\beta_1{}x_1{}+\ldots+\beta_p{}x_p\]</span></p>
<p>Or a decision tree:</p>
<p><span class="math display">\[g(x)=\sum_{m=1}^Mc_m{}I\{x\in{}R_m\}\]</span></p>
<p>Training a surrogate model is a model-agnostic method, since it does not require any information about the inner workings of the black box model, only access to data and the prediction function is necessary.
If the underlying machine learning model was replaced with another, you could still use the surrogate method.
The choice of the black box model type and of the surrogate model type is decoupled.</p>
<p>Perform the following steps to obtain a surrogate model:</p>
<ol style="list-style-type: decimal">
<li>Select a dataset X.
This can be the same dataset that was used for training the black box model or a new dataset from the same distribution.
You could even select a subset of the data or a grid of points, depending on your application.</li>
<li>For the selected dataset X, get the predictions of the black box model.</li>
<li>Select an interpretable model type (linear model, decision tree, …).</li>
<li>Train the interpretable model on the dataset X and its predictions.</li>
<li>Congratulations! You now have a surrogate model.</li>
<li>Measure how well the surrogate model replicates the predictions of the black box model.</li>
<li>Interpret the surrogate model.</li>
</ol>
<p>You may find approaches for surrogate models that have some extra steps or differ a little, but the general idea is usually as described here.</p>
<p>One way to measure how well the surrogate replicates the black box model is the R-squared measure:</p>
<p><span class="math display">\[R^2=1-\frac{SSE}{SST}=1-\frac{\sum_{i=1}^n(\hat{y}_*^{(i)}-\hat{y}^{(i)})^2}{\sum_{i=1}^n(\hat{y}^{(i)}-\bar{\hat{y}})^2}\]</span></p>
<p>where <span class="math inline">\(\hat{y}_*^{(i)}\)</span> is the prediction for the i-th instance of the surrogate model, <span class="math inline">\(\hat{y}^{(i)}\)</span> the prediction of the black box model and <span class="math inline">\(\bar{\hat{y}}\)</span> the mean of the black box model predictions.
SSE stands for sum of squares error and SST for sum of squares total.
The R-squared measure can be interpreted as the percentage of variance that is captured by the surrogate model.
If R-squared is close to 1 (= low SSE), then the interpretable model approximates the behavior of the black box model very well.
If the interpretable model is very close, you might want to replace the complex model with the interpretable model.
If the R-squared is close to 0 (= high SSE), then the interpretable model fails to explain the black box model.</p>
<p>Note that we have not talked about the model performance of the underlying black box model, i.e. how good or bad it performs in predicting the actual outcome.
The performance of the black box model does not play a role in training the surrogate model.
The interpretation of the surrogate model is still valid because it makes statements about the model and not about the real world.
But of course the interpretation of the surrogate model becomes irrelevant if the black box model is bad, because then the black box model itself is irrelevant.</p>
<!-- More ideas-->
<p>We could also build a surrogate model based on a subset of the original data or reweight the instances.
In this way, we change the distribution of the surrogate model’s input, which changes the focus of the interpretation (then it is no longer really global).
If we weight the data locally by a specific instance of the data (the closer the instances to the selected instance, the higher their weight), we get a local surrogate model that can explain the individual prediction of the instance.
Read more about local models in the <a href="lime.html#lime">following chapter</a>.</p>
</div>
<div id="example-3" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Example</h3>
<p>To demonstrate the surrogate models, we consider a regression and a classification example.</p>
<p>First, we train a support vector machine to predict the <a href="bike-data.html#bike-data">daily number of rented bikes</a> given weather and calendar information.
The support vector machine is not very interpretable, so we train a surrogate with a CART decision tree as interpretable model to approximate the behavior of the support vector machine.</p>
<div class="figure"><span style="display:block;" id="fig:surrogate-bike"></span>
<img src="images/surrogate-bike-1.png" alt="The terminal nodes of a surrogate tree that approximates the predictions of a support vector machine trained on the bike rental dataset. The distributions in the nodes show that the surrogate tree predicts a higher number of rented bikes when temperature is above 13 degrees Celsius and when the day was later in the 2 year period (cut point at 435 days)." width="1050" />
<p class="caption">
FIGURE 7.28: The terminal nodes of a surrogate tree that approximates the predictions of a support vector machine trained on the bike rental dataset. The distributions in the nodes show that the surrogate tree predicts a higher number of rented bikes when temperature is above 13 degrees Celsius and when the day was later in the 2 year period (cut point at 435 days).
</p>
</div>
<p>The surrogate model has a R-squared (variance explained) of 0.77 which means it approximates the underlying black box behavior quite well, but not perfectly.
If the fit were perfect, we could throw away the support vector machine and use the tree instead.</p>
<p>In our second example, we predict the probability of <a href="cervical.html#cervical">cervical cancer</a> with a random forest.
Again we train a decision tree with the original dataset, but with the prediction of the random forest as outcome, instead of the real classes (healthy vs. cancer) from the data.</p>
<div class="figure"><span style="display:block;" id="fig:surrogate-cervical"></span>
<img src="images/surrogate-cervical-1.png" alt="The terminal nodes of a surrogate tree that approximates the predictions of a random forest trained on the cervical cancer dataset. The counts in the nodes show the frequency of the black box models classifications in the nodes." width="1050" />
<p class="caption">
FIGURE 7.29: The terminal nodes of a surrogate tree that approximates the predictions of a random forest trained on the cervical cancer dataset. The counts in the nodes show the frequency of the black box models classifications in the nodes.
</p>
</div>
<p>The surrogate model has an R-squared (variance explained) of 0.19, which means it does not approximate the random forest well and we should not overinterpret the tree when drawing conclusions about the complex model.</p>
</div>
<div id="advantages-10" class="section level3">
<h3><span class="header-section-number">7.6.3</span> Advantages</h3>
<p>The surrogate model method is <strong>flexible</strong>:
Any model from the <a href="simple.html#simple">interpretable models chapter</a> can be used.
This also means that you can exchange not only the interpretable model, but also the underlying black box model.
Suppose you create some complex model and explain it to different teams in your company.
One team is familiar with linear models, the other team can understand decision trees.
You can train two surrogate models (linear model and decision tree) for the original black box model and offer two kinds of explanations.
If you find a better performing black box model, you do not have to change your method of interpretation, because you can use the same class of surrogate models.</p>
<p>I would argue that the approach is very <strong>intuitive</strong> and straightforward.
This means it is easy to implement, but also easy to explain to people not familiar with data science or machine learning.</p>
<p>With the <strong>R-squared measure</strong>, we can easily measure how good our surrogate models are in approximating the black box predictions.</p>
</div>
<div id="disadvantages-10" class="section level3">
<h3><span class="header-section-number">7.6.4</span> Disadvantages</h3>
<p>You have to be aware that you draw <strong>conclusions about the model and not about the data</strong>, since the surrogate model never sees the real outcome.</p>
<p>It is not clear what the best <strong>cut-off for R-squared</strong> is in order to be confident that the surrogate model is close enough to the black box model.
80% of variance explained? 50%? 99%?</p>
<p>We can measure how close the surrogate model is to the black box model.
Let us assume we are not very close, but close enough.
It could happen that the interpretable model is very <strong>close for one subset of the dataset, but widely divergent for another subset</strong>.
In this case the interpretation for the simple model would not be equally good for all data points.</p>
<p>The interpretable model you choose as a surrogate <strong>comes with all its advantages and disadvantages</strong>.</p>
<p>Some people argue that there are, in general, <strong>no intrinsically interpretable models</strong> (including even linear models and decision trees) and that it would even be dangerous to have an illusion of interpretability.
If you share this opinion, then of course this method is not for you.</p>
</div>
<div id="software-3" class="section level3">
<h3><span class="header-section-number">7.6.5</span> Software</h3>
<p>I used the <code>iml</code> R package for the examples.
If you can train a machine learning model, then you should be able to implement surrogate models yourself.
Simply train an interpretable model to predict the predictions of the black box model.</p>

<!--{pagebreak}-->
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="feature-importance.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="proto.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/christophM/interpretable-ml-book/edit/master/manuscript/05.7-agnostic-global-surrogate.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
